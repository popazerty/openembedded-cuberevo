From b2238c81565f86202e5d7776a714af0b53425abf Mon Sep 17 00:00:00 2001
From: Giuseppe CAVALLARO <peppe.cavallaro@st.com>
Date: Fri, 7 Nov 2008 11:21:30 +0100
Subject: [PATCH] stmmac: new version of the network device driver

This is a new version of the embedded MAC 10/100/1000.
Main changes:
o First Jumbo frame support for the GMAC.
o Timer irq function looks at if there is pending work to do before
  scheduling processes.
o New modules parameters; these have the same names used for command line.

Signed-off-by: Giuseppe Cavallaro <peppe.cavallaro@st.com>
Signed-off-by: Stuart Menefy <stuart.menefy@st.com>
---
 drivers/net/stmmac/common.h         |  131 +++--
 drivers/net/stmmac/descs.h          |    4 +-
 drivers/net/stmmac/gmac.c           |  346 ++++++-----
 drivers/net/stmmac/gmac.h           |   48 +-
 drivers/net/stmmac/mac100.c         |  125 ++--
 drivers/net/stmmac/mac100.h         |    2 -
 drivers/net/stmmac/stmmac.h         |   70 ++-
 drivers/net/stmmac/stmmac_ethtool.c |  104 ++--
 drivers/net/stmmac/stmmac_main.c    | 1254 ++++++++++++++++++++---------------
 drivers/net/stmmac/stmmac_mdio.c    |   49 +-
 drivers/net/stmmac/stmmac_timer.c   |   67 +-
 11 files changed, 1215 insertions(+), 985 deletions(-)

diff --git a/drivers/net/stmmac/common.h b/drivers/net/stmmac/common.h
index d03c6d4..bba4869 100644
--- a/drivers/net/stmmac/common.h
+++ b/drivers/net/stmmac/common.h
@@ -31,7 +31,8 @@
 #define DMA_INTR_ENA_RIE 0x00000040	/* Receive Interrupt */
 #define DMA_INTR_ENA_ERE 0x00004000	/* Early Receive */
 
-#define DMA_INTR_NORMAL	(DMA_INTR_ENA_NIE | DMA_INTR_ENA_RIE | DMA_INTR_ENA_TIE \
+#define DMA_INTR_NORMAL	(DMA_INTR_ENA_NIE | DMA_INTR_ENA_RIE | \
+			DMA_INTR_ENA_TIE \
 			/*| DMA_INTR_ENA_ERE | DMA_INTR_ENA_TUE*/)
 
 /**** ABNORMAL INTERRUPT ****/
@@ -46,7 +47,8 @@
 #define DMA_INTR_ENA_TJE 0x00000008	/* Transmit Jabber */
 #define DMA_INTR_ENA_TSE 0x00000002	/* Transmit Stopped */
 
-#define DMA_INTR_ABNORMAL	DMA_INTR_ENA_AIE | DMA_INTR_ENA_FBE /*| DMA_INTR_ENA_UNE*/
+#define DMA_INTR_ABNORMAL	(DMA_INTR_ENA_AIE | DMA_INTR_ENA_FBE | \
+				DMA_INTR_ENA_UNE)
 
 /* DMA default interrupt mask */
 #define DMA_INTR_DEFAULT_MASK	(DMA_INTR_NORMAL | DMA_INTR_ABNORMAL)
@@ -95,9 +97,17 @@
 #define FLOW_TX		2
 #define FLOW_AUTO	(FLOW_TX | FLOW_RX)
 
-/* HW csum */
+/* DMA STORE-AND-FORWARD Operation Mode */
+#define SF_DMA_MODE 1
+
+#define HW_CSUM 1
 #define NO_HW_CSUM 0
-#define HAS_HW_CSUM 1
+
+/* GMAC TX FIFO is 8K, Rx FIFO is 16K */
+#define BUF_SIZE_16KiB 16384
+#define BUF_SIZE_8KiB 8192
+#define BUF_SIZE_4KiB 4096
+#define BUF_SIZE_2KiB 2048
 
 /* Power Down and WOL */
 #define PMT_NOT_SUPPORTED 0
@@ -156,85 +166,110 @@ struct stmmac_extra_stats {
 	unsigned long tx_early_irq;
 	unsigned long fatal_bus_error_irq;
 	unsigned long rx_poll_n;
+	unsigned long tx_task_n;
 	unsigned long tx_payload_error;
 	unsigned long tx_ip_header_error;
 	unsigned long rx_missed_cntr;
 	unsigned long rx_overflow_cntr;
 };
-#define EXTRA_STATS 40
+#define EXTRA_STATS 41
+
+/* In case of GMAC, the device can compute the HW checksums and
+ * found if the frame is corrupted. It can also decide to let the
+ * upper layer to compute the Csum in Sw. */
+enum rx_frame_status {
+	good_frame = 0,
+	discard_frame = 1,
+	csum_none = 2,
+};
 
 /* Specific device structure VFP in order to mark the
  * difference between mac and gmac in terms of registers, descriptors etc.
  */
 struct device_ops {
-	/* MAC core */
+	/* MAC core initialization */
 	void (*core_init) (unsigned long ioaddr);
-	void (*dump_mac_regs) (unsigned long ioaddr);
-
-	/* DMA core */
+	/* DMA core initialization */
 	int (*dma_init) (unsigned long ioaddr, int pbl, u32 dma_tx, u32 dma_rx);
+	/* Dump MAC registers */
+	void (*dump_mac_regs) (unsigned long ioaddr);
+	/* Dump DMA registers */
 	void (*dump_dma_regs) (unsigned long ioaddr);
-	void (*dma_operation_mode) (unsigned long ioaddr, int threshold);
+	/* Set tx/rx threshold in the csr6 register
+	 * An invalid value enables the store-and-forward mode */
+	void (*dma_mode) (unsigned long ioaddr, int txmode, int rxmode);
+	/* To track extra statistic (if supported) */
 	void (*dma_diagnostic_fr) (void *data, struct stmmac_extra_stats *x,
-					unsigned long ioaddr);
-
-
-	/* Descriptors */
-	void (*init_rx_desc) (dma_desc * p, unsigned int ring_size,
-			      int rx_irq_threshol);
-	void (*init_tx_desc) (dma_desc * p, unsigned int ring_size);
-	int (*set_buf_size) (unsigned int len);
-	int (*read_tx_ls) (void);
-	int (*read_tx_owner) (dma_desc * p);
-	int (*read_rx_owner) (dma_desc * p);
-	void (*release_tx_desc) (dma_desc * p);
-	void (*prepare_tx_desc) (dma_desc * p, int is_fs, int len, 
-				unsigned int csum_flags);
-	void (*set_tx_ic) (dma_desc * p, int value);
-	void (*set_tx_ls) (dma_desc * p);
-	int (*get_tx_ls) (dma_desc * p);
-	void (*set_tx_owner) (dma_desc * p);
-	void (*set_rx_owner) (dma_desc * p);
-	int (*get_rx_frame_len) (dma_desc * p);
-
-	/* driver functions */
-	int (*tx_status) (void *data, struct stmmac_extra_stats * x,
-			  dma_desc * p, unsigned long ioaddr);
-	int (*rx_status) (void *data, struct stmmac_extra_stats * x,
-			  dma_desc * p);
-	int (*get_tx_len) (dma_desc * p); /* Get the frm len */
-	void (*tx_checksum) (struct sk_buff * skb, dma_desc * p);
-	int (*rx_checksum) (dma_desc * p);
+				   unsigned long ioaddr);
+	/* RX descriptor ring initialization */
+	void (*init_rx_desc) (struct dma_desc *p, unsigned int ring_size);
+	/* TX descriptor ring initialization */
+	void (*init_tx_desc) (struct dma_desc *p, unsigned int ring_size);
+	/* Invoked by the xmit function to prepare the tx descriptor */
+	void (*prepare_tx_desc) (struct dma_desc *p, int is_fs, int len,
+				 int csum_flag);
+	/* Invoked by the xmit function to close the tx descriptor */
+	void (*close_tx_desc) (struct dma_desc *p);
+	/* Clean the tx descriptor as soon as the tx irq is received */
+	void (*release_tx_desc) (struct dma_desc *p);
+	/* Clear interrupt on tx frame completion. When this bit is
+	 * set an interrupt happens as soon as the frame is transmitted */
+	void (*clear_tx_ic) (struct dma_desc *p);
+	/* Interrupt after this number of packets have arrived. */
+	void (*disable_rx_ic) (struct dma_desc *p, unsigned int ring_size,
+			       int disable_ic);
+	/* Last tx segment reports the transmit status */
+	int (*get_tx_ls) (struct dma_desc *p);
+	/* Set/get the owner of the descriptor */
+	int (*get_tx_owner) (struct dma_desc *p);
+	int (*get_rx_owner) (struct dma_desc *p);
+	void (*set_tx_owner) (struct dma_desc *p);
+	void (*set_rx_owner) (struct dma_desc *p);
+	/* Get the receive frame size */
+	int (*get_rx_frame_len) (struct dma_desc *p);
+	/* Return the transmit status looking at the TDES1 */
+	int (*tx_status) (void *data, struct stmmac_extra_stats *x,
+			  struct dma_desc *p, unsigned long ioaddr);
+	/* Return the reception status looking at the RDES1 */
+	int (*rx_status) (void *data, struct stmmac_extra_stats *x,
+			  struct dma_desc *p);
+	/* Get the buffer size from the descriptor */
+	int (*get_tx_len) (struct dma_desc *p);
+	/* Multicast filter setting */
 	void (*set_filter) (struct net_device * dev);
+	/* Flow control setting */
 	void (*flow_ctrl) (unsigned long ioaddr, unsigned int duplex,
 			   unsigned int fc, unsigned int pause_time);
+	/* Set power management mode (e.g. magic frame) */
 	void (*pmt) (unsigned long ioaddr, unsigned long mode);
+	/* Handle extra events on specific interrupts hw dependent */
 	void (*host_irq_status) (unsigned long ioaddr);
 };
 
-struct mac_link_t {
+struct mac_link {
 	int port;
 	int duplex;
 	int speed;
 };
 
-struct mii_regs_t {
+struct mii_regs {
 	unsigned int addr;	/* MII Address */
 	unsigned int data;	/* MII Data */
 };
 
-struct hw_cap_t {
+struct hw_cap {
 	unsigned int addr_high;	/* Multicast Hash Table High */
 	unsigned int addr_low;	/* Multicast Hash Table Low */
 	unsigned int version;	/* Core Version register (GMAC) */
 	unsigned int pmt;	/* Power-Down mode (GMAC) */
-	unsigned int csum;	/* Checksum Offload */
-	unsigned int buf_size;	/* Buffer size */
-	struct mac_link_t link;
-	struct mii_regs_t mii;
+	struct mac_link link;
+	struct mii_regs mii;
 };
 
-struct device_info_t {
-	struct hw_cap_t hw;
+struct mac_device_info {
+	struct hw_cap hw;
 	struct device_ops *ops;
 };
+
+struct mac_device_info *gmac_setup(unsigned long addr);
+struct mac_device_info *mac100_setup(unsigned long addr);
diff --git a/drivers/net/stmmac/descs.h b/drivers/net/stmmac/descs.h
index 76d01bf..80543f4 100644
--- a/drivers/net/stmmac/descs.h
+++ b/drivers/net/stmmac/descs.h
@@ -1,4 +1,4 @@
-struct dma_desc_t {
+struct dma_desc {
 	/* Receive descriptor */
 	union {
 		struct {
@@ -131,8 +131,6 @@ struct dma_desc_t {
 	unsigned int des3;
 };
 
-typedef struct dma_desc_t dma_desc;
-
 /* Transmit checksum insertion control */
 enum tdes_csum_insertion {
 	cic_disabled = 0,	/* Checksum Insertion Control */
diff --git a/drivers/net/stmmac/gmac.c b/drivers/net/stmmac/gmac.c
index 700830f..1f3ad7c 100644
--- a/drivers/net/stmmac/gmac.c
+++ b/drivers/net/stmmac/gmac.c
@@ -25,6 +25,7 @@
 
 #undef GMAC_DEBUG
 /*#define GMAC_DEBUG*/
+#undef FRAME_FILTER_DEBUG
 #ifdef GMAC_DEBUG
 #define DBG(fmt,args...)  printk(fmt, ## args)
 #else
@@ -44,24 +45,18 @@ static void gmac_dump_regs(unsigned long ioaddr)
 		printk("\tReg No. %d (offset 0x%x): 0x%08x\n", i,
 		       offset, readl(ioaddr + offset));
 	}
-	printk("\tSTBus brigde: reg: 0x%x, 0x%08x\n",
-	       (unsigned int)(ioaddr + STBUS_BRIDGE_OFFSET),
-	       readl(ioaddr + STBUS_BRIDGE_OFFSET));
 	return;
 }
 
 static int gmac_dma_init(unsigned long ioaddr, int pbl, u32 dma_tx, u32 dma_rx)
 {
-	unsigned int value;
-
+	u32 value = readl(ioaddr + DMA_BUS_MODE);
 	/* DMA SW reset */
-	value = (unsigned int)readl(ioaddr + DMA_BUS_MODE);
 	value |= DMA_BUS_MODE_SFT_RESET;
 	writel(value, ioaddr + DMA_BUS_MODE);
 	while ((readl(ioaddr + DMA_BUS_MODE) & DMA_BUS_MODE_SFT_RESET)) {
 	}
 
-	/* Enable Application Access by writing to DMA CSR0 */
 	value = /* DMA_BUS_MODE_FB | */ DMA_BUS_MODE_4PBL |
 	    ((pbl << DMA_BUS_MODE_PBL_SHIFT) |
 	     (pbl << DMA_BUS_MODE_RPBL_SHIFT));
@@ -85,57 +80,60 @@ static int gmac_dma_init(unsigned long ioaddr, int pbl, u32 dma_tx, u32 dma_rx)
 /* Transmit FIFO flush operation */
 static void gmac_flush_tx_fifo(unsigned long ioaddr)
 {
-	unsigned int csr6;
-
-	csr6 = (unsigned int)readl(ioaddr + DMA_CONTROL);
+	u32 csr6 = readl(ioaddr + DMA_CONTROL);
 	writel((csr6 | DMA_CONTROL_FTF), ioaddr + DMA_CONTROL);
 
 	while ((readl(ioaddr + DMA_CONTROL) & DMA_CONTROL_FTF)) {
 	}
 }
 
-static void gmac_dma_operation_mode(unsigned long ioaddr, int threshold)
+static void gmac_dma_operation_mode(unsigned long ioaddr, int txmode,
+				    int rxmode)
 {
-	unsigned int csr6;
-
-	csr6 = (unsigned int)readl(ioaddr + DMA_CONTROL);
-
-#ifdef GMAC_TX_STORE_AND_FORWARD
-	csr6 |= DMA_CONTROL_TSF;
-#else
-	if (threshold <= 32)
-		csr6 |= DMA_CONTROL_TTC_32;
-	else if (threshold <= 64)
-		csr6 |= DMA_CONTROL_TTC_64;
-	else if (threshold <= 128)
-		csr6 |= DMA_CONTROL_TTC_128;
-	else if (threshold <= 192)
-		csr6 |= DMA_CONTROL_TTC_192;
-	else
-		csr6 |= DMA_CONTROL_TTC_256;
-#endif
+	u32 csr6 = readl(ioaddr + DMA_CONTROL);
+
+	if (txmode == SF_DMA_MODE) {
+		/* Transmit COE type 2 cannot be done in cut-through mode. */
+		csr6 |= DMA_CONTROL_TSF;
+		/* Operating on second frame increase the performance
+		 * especially when transmit store-and-forward is used.*/
+		csr6 |= DMA_CONTROL_OSF;
+	} else {
+		csr6 &= ~DMA_CONTROL_TSF;
+		/* Set the transmit threashold */
+		if (txmode <= 32) {
+			csr6 |= DMA_CONTROL_TTC_32;
+		} else if (txmode <= 64) {
+			csr6 |= DMA_CONTROL_TTC_64;
+		} else if (txmode <= 128) {
+			csr6 |= DMA_CONTROL_TTC_128;
+		} else if (txmode <= 192) {
+			csr6 |= DMA_CONTROL_TTC_192;
+		} else {
+			csr6 |= DMA_CONTROL_TTC_256;
+		}
+	}
 
-#ifdef GMAC_RX_STORE_AND_FORWARD
-	csr6 |= DMA_CONTROL_RSF;
-#else
-	if (threshold <= 32)
-		csr6 |= DMA_CONTROL_RTC_32;
-	else if (threshold <= 64)
-		csr6 |= DMA_CONTROL_RTC_64;
-	else if (threshold <= 96)
-		csr6 |= DMA_CONTROL_RTC_96;
-	else
-		csr6 |= DMA_CONTROL_RTC_128;
-#endif
-	/* Operating on second frame increase the performance 
-	 * especially when transmit store-and-forward is used.*/
-	csr6 |= DMA_CONTROL_OSF;
+	if (rxmode == SF_DMA_MODE) {
+		csr6 |= DMA_CONTROL_RSF;
+	} else {
+		csr6 &= ~DMA_CONTROL_RSF;
+		if (rxmode <= 32) {
+			csr6 |= DMA_CONTROL_RTC_32;
+		} else if (rxmode <= 64) {
+			csr6 |= DMA_CONTROL_RTC_64;
+		} else if (rxmode <= 96) {
+			csr6 |= DMA_CONTROL_RTC_96;
+		} else {
+			csr6 |= DMA_CONTROL_RTC_128;
+		}
+	}
 
 	writel(csr6, ioaddr + DMA_CONTROL);
 	return;
 }
 
-/* Not yet implemented --- RMON */
+/* Not yet implemented --- no RMON module */
 static void gmac_dma_diagnostic_fr(void *data, struct stmmac_extra_stats *x,
 				   unsigned long ioaddr)
 {
@@ -159,134 +157,190 @@ static void gmac_dump_dma_regs(unsigned long ioaddr)
 }
 
 static int gmac_get_tx_frame_status(void *data, struct stmmac_extra_stats *x,
-				    dma_desc * p, unsigned long ioaddr)
+				    struct dma_desc *p, unsigned long ioaddr)
 {
 	int ret = 0;
 	struct net_device_stats *stats = (struct net_device_stats *)data;
 
 	if (unlikely(p->des01.etx.error_summary)) {
-
+		DBG(KERN_ERR "GMAC TX error... 0x%08x\n", p->des01.etx);
 		if (unlikely(p->des01.etx.jabber_timeout)) {
-			DBG(KERN_ERR "GMAC TX: jabber_timeout error\n");
+			DBG(KERN_ERR "\tjabber_timeout error\n");
 			x->tx_jabber++;
 		}
 
 		if (unlikely(p->des01.etx.frame_flushed)) {
-			DBG(KERN_ERR "GMAC TX: frame_flushed error\n");
+			DBG(KERN_ERR "\tframe_flushed error\n");
 			x->tx_frame_flushed++;
 			gmac_flush_tx_fifo(ioaddr);
 		}
 
 		if (unlikely(p->des01.etx.loss_carrier)) {
-			DBG(KERN_ERR "GMAC TX: loss_carrier error\n");
+			DBG(KERN_ERR "\tloss_carrier error\n");
 			x->tx_losscarrier++;
 			stats->tx_carrier_errors++;
 		}
 		if (unlikely(p->des01.etx.no_carrier)) {
-			DBG(KERN_ERR "GMAC TX: no_carrier error\n");
+			DBG(KERN_ERR "\tno_carrier error\n");
 			x->tx_carrier++;
 			stats->tx_carrier_errors++;
 		}
 		if (unlikely(p->des01.etx.late_collision)) {
-			DBG(KERN_ERR "GMAC TX: late_collision error\n");
+			DBG(KERN_ERR "\tlate_collision error\n");
 			stats->collisions += p->des01.etx.collision_count;
 		}
 		if (unlikely(p->des01.etx.excessive_collisions)) {
-			DBG(KERN_ERR "GMAC TX: excessive_collisions\n");
+			DBG(KERN_ERR "\texcessive_collisions\n");
 			stats->collisions += p->des01.etx.collision_count;
 		}
-		if (unlikely(p->des01.etx.excessive_deferral))
+		if (unlikely(p->des01.etx.excessive_deferral)) {
+			DBG(KERN_INFO "\texcessive tx_deferral\n");
 			x->tx_deferred++;
+		}
 
 		if (unlikely(p->des01.etx.underflow_error)) {
-			DBG(KERN_ERR "GMAC TX: underflow error\n");
+			DBG(KERN_ERR "\tunderflow error\n");
 			gmac_flush_tx_fifo(ioaddr);
 			x->tx_underflow++;
 		}
-		ret = -1;
-	}
 
-	if (unlikely(p->des01.etx.payload_error)) {
-		DBG(KERN_ERR "%s: TX Addr/Payload csum error\n", __FUNCTION__);
-		x->tx_payload_error++;
-		gmac_flush_tx_fifo(ioaddr);
-		ret = -1;
-	}
+		if (unlikely(p->des01.etx.ip_header_error)) {
+			DBG(KERN_ERR "\tTX IP header csum error\n");
+			x->tx_ip_header_error++;
+		}
+
+		if (unlikely(p->des01.etx.payload_error)) {
+			DBG(KERN_ERR "\tAddr/Payload csum error\n");
+			x->tx_payload_error++;
+			gmac_flush_tx_fifo(ioaddr);
+		}
 
-	if (unlikely(p->des01.etx.ip_header_error)) {
-		DBG(KERN_ERR "%s: TX IP header csum error\n", __FUNCTION__);
-		x->tx_ip_header_error++;
 		ret = -1;
 	}
 
 	if (unlikely(p->des01.etx.deferred)) {
+		DBG(KERN_INFO "GMAC TX status: tx deferred\n");
 		x->tx_deferred++;
-		ret = -1;
 	}
 	if (p->des01.etx.vlan_frame) {
-		DBG(KERN_INFO "GMAC TX: VLAN frame\n");
+		DBG(KERN_INFO "GMAC TX status: VLAN frame\n");
 		x->tx_vlan++;
 	}
 
 	return (ret);
 }
 
-static int gmac_get_tx_len(dma_desc * p)
+static int gmac_get_tx_len(struct dma_desc *p)
 {
 	return (p->des01.etx.buffer1_size);
 }
 
+static int gmac_coe_rdes0(int ipc_err, int type, int payload_err)
+{
+	int ret = good_frame;
+	u32 status = (type << 2 | ipc_err << 1 | payload_err) & 0x7;
+
+	/* bits 5 7 0 | Frame status
+	 * ----------------------------------------------------------
+	 *      0 0 0 | IEEE 802.3 Type frame (lenght < 1536 octects)
+	 *      1 0 0 | IPv4/6 No CSUM errorS.
+	 *      1 0 1 | IPv4/6 CSUM PAYLOAD error
+	 *      1 1 0 | IPv4/6 CSUM IP HR error
+	 *      1 1 1 | IPv4/6 IP PAYLOAD AND HEADER errorS
+	 *      0 0 1 | IPv4/6 unsupported IP PAYLOAD
+	 *      0 1 1 | COE bypassed.. no IPv4/6 frame
+	 *      0 1 0 | Reserved.
+	 */
+	if (status == 0x0) {
+		DBG(KERN_INFO "RX Des0 status: IEEE 802.3 Type frame.\n");
+		ret = good_frame;
+	} else if (status == 0x4) {
+		DBG(KERN_INFO "RX Des0 status: IPv4/6 No CSUM errorS.\n");
+		ret = good_frame;
+	} else if (status == 0x5) {
+		DBG(KERN_ERR "RX Des0 status: IPv4/6 Payload Error.\n");
+		ret = csum_none;
+	} else if (status == 0x6) {
+		DBG(KERN_ERR "RX Des0 status: IPv4/6 Header Error.\n");
+		ret = csum_none;
+	} else if (status == 0x7) {
+		DBG(KERN_ERR
+		    "RX Des0 status: IPv4/6 Header and Payload Error.\n");
+		ret = csum_none;
+	} else if (status == 0x1) {
+		DBG(KERN_ERR
+		    "RX Des0 status: IPv4/6 unsupported IP PAYLOAD.\n");
+		ret = discard_frame;
+	} else if (status == 0x3) {
+		DBG(KERN_ERR "RX Des0 status: No IPv4, IPv6 frame.\n");
+		ret = discard_frame;
+	}
+	return ret;
+}
+
 static int gmac_get_rx_frame_status(void *data, struct stmmac_extra_stats *x,
-				    dma_desc * p)
+				    struct dma_desc *p)
 {
-	int ret = 0;
+	int ret = good_frame;
 	struct net_device_stats *stats = (struct net_device_stats *)data;
 
 	if (unlikely(p->des01.erx.error_summary)) {
+		DBG(KERN_ERR "GMAC RX Error Summary... 0x%08x\n", p->des01.erx);
 		if (unlikely(p->des01.erx.descriptor_error)) {
-			/* frame doesn't fit within the current descriptor. */
-			DBG(KERN_ERR "GMAC RX: descriptor error\n");
+			DBG(KERN_ERR "\tdescriptor error\n");
 			x->rx_desc++;
 			stats->rx_length_errors++;
 		}
 		if (unlikely(p->des01.erx.overflow_error)) {
-			DBG(KERN_ERR "GMAC RX: Overflow error\n");
+			DBG(KERN_ERR "\toverflow error\n");
 			x->rx_gmac_overflow++;
 		}
+
+		if (unlikely(p->des01.erx.ipc_csum_error))
+			DBG(KERN_ERR "\tIPC Csum Error/Giant frame\n");
+
 		if (unlikely(p->des01.erx.late_collision)) {
-			DBG(KERN_ERR "GMAC RX: late_collision\n");
+			DBG(KERN_ERR "\tlate_collision error\n");
 			stats->collisions++;
 			stats->collisions++;
 		}
 		if (unlikely(p->des01.erx.receive_watchdog)) {
-			DBG(KERN_ERR "GMAC RX: receive_watchdog error\n");
+			DBG(KERN_ERR "\treceive_watchdog error\n");
 			x->rx_watchdog++;
 		}
 		if (unlikely(p->des01.erx.error_gmii)) {
-			DBG(KERN_ERR "GMAC RX: GMII error\n");
+			DBG(KERN_ERR "\tReceive Error\n");
 			x->rx_mii++;
 		}
 		if (unlikely(p->des01.erx.crc_error)) {
-			DBG(KERN_ERR "GMAC RX: CRC error\n");
+			DBG(KERN_ERR "\tCRC error\n");
 			x->rx_crc++;
 			stats->rx_crc_errors++;
 		}
-		ret = -1;
+		ret = discard_frame;
 	}
 
+	/* It seems, if there is a payload csum error, the ES bit is set.
+	 * It doesn't match with the information reported into the databook.
+	 * At any rate, we need to understand if the CSUM hw computation is ok
+	 * and report this info to the upper layers.  */
+	ret =
+	    gmac_coe_rdes0(p->des01.erx.ipc_csum_error, p->des01.erx.frame_type,
+			   p->des01.erx.payload_csum_error);
+
 	if (unlikely(p->des01.erx.dribbling)) {
-		DBG(KERN_ERR "GMAC RX:  dribbling error\n");
-		ret = -1;
+		DBG(KERN_ERR "GMAC RX: dribbling error\n");
+		ret = discard_frame;
 	}
 	if (unlikely(p->des01.erx.filtering_fail)) {
-		DBG(KERN_ERR "GMAC RX: filtering_fail error\n");
+		DBG(KERN_ERR "GMAC RX : filtering_fail error\n");
 		x->rx_filter++;
-		ret = -1;
+		ret = discard_frame;
 	}
 	if (unlikely(p->des01.erx.length_error)) {
 		DBG(KERN_ERR "GMAC RX: length_error error\n");
 		x->rx_lenght++;
-		ret = -1;
+		ret = discard_frame;
 	}
 	return (ret);
 }
@@ -294,9 +348,7 @@ static int gmac_get_rx_frame_status(void *data, struct stmmac_extra_stats *x,
 /* It is necessary to handle other events (e.g.  power management interrupt) */
 static void gmac_irq_status(unsigned long ioaddr)
 {
-	unsigned int intr_status;
-
-	intr_status = (unsigned int)readl(ioaddr + GMAC_INT_STATUS);
+	u32 intr_status = readl(ioaddr + GMAC_INT_STATUS);
 
 	/* Do not handle all the events, e.g. MMC interrupts 
 	 * (not used by default). Indeed, to "clear" these events
@@ -323,29 +375,9 @@ static void gmac_irq_status(unsigned long ioaddr)
 	return;
 }
 
-static int gmac_rx_checksum(dma_desc * p)
-{
-	int ret = 0;
-	/* Full COE type 2 is supported */
-	if (unlikely((p->des01.erx.ipc_csum_error == 1)) ||
-	    (p->des01.erx.payload_csum_error == 1)) {
-
-		if (p->des01.erx.payload_csum_error)
-			DBG(KERN_WARNING "%s: IPC csum error\n", __FUNCTION__);
-		if (p->des01.erx.payload_csum_error)
-			DBG(KERN_WARNING "(Address/Payload csum error.)\n");
-
-		ret = -1;
-	}
-	return ret;
-}
-
 static void gmac_core_init(unsigned long ioaddr)
 {
-	unsigned int value = 0;
-
-	/* Set the GMAC control register with our default value */
-	value = (unsigned int)readl(ioaddr + GMAC_CONTROL);
+	u32 value = readl(ioaddr + GMAC_CONTROL);
 	value |= GMAC_CORE_INIT;
 	writel(value, ioaddr + GMAC_CONTROL);
 
@@ -353,7 +385,8 @@ static void gmac_core_init(unsigned long ioaddr)
 	writel(ETH_P_8021Q, ioaddr + GMAC_VLAN);
 #endif
 	/* STBus Bridge Configuration */
-	writel(STBUS_BRIDGE_MAGIC, ioaddr + STBUS_BRIDGE_OFFSET);
+	/*writel(0xc5608, ioaddr + 0x00007000);*/
+
 	/* Freeze MMC counters */
 	writel(0x8, ioaddr + GMAC_MMC_CTRL);
 	/* Mask GMAC interrupts */
@@ -371,7 +404,7 @@ static void gmac_set_filter(struct net_device *dev)
 		value = GMAC_FRAME_FILTER_PR;
 	} else if ((dev->mc_count > HASH_TABLE_SIZE)
 		   || (dev->flags & IFF_ALLMULTI)) {
-		value = GMAC_FRAME_FILTER_PM;	/// pass all multi
+		value = GMAC_FRAME_FILTER_PM;	/* pass all multi */
 		writel(0xffffffff, ioaddr + GMAC_HASH_HIGH);
 		writel(0xffffffff, ioaddr + GMAC_HASH_LOW);
 	} else if (dev->mc_count == 0) {
@@ -401,7 +434,7 @@ static void gmac_set_filter(struct net_device *dev)
 		writel(mc_filter[1], ioaddr + GMAC_HASH_HIGH);
 	}
 
-#ifdef GMAC_DEBUG
+#ifdef FRAME_FILTER_DEBUG
 	/* Receive all mode enabled. Useful for debugging 
 	   filtering_fail errors. */
 	value |= GMAC_FRAME_FILTER_RA;
@@ -455,15 +488,14 @@ static void gmac_pmt(unsigned long ioaddr, unsigned long mode)
 	return;
 }
 
-static void gmac_init_rx_desc(dma_desc * p, unsigned int ring_size,
-			      int rx_irq_threshold)
+static void gmac_init_rx_desc(struct dma_desc *p, unsigned int ring_size)
 {
 	int i;
 	for (i = 0; i < ring_size; i++) {
 		p->des01.erx.own = 1;
-		p->des01.erx.buffer1_size = DMA_BUFFER_SIZE - 1;
-		if (i % rx_irq_threshold)
-			p->des01.erx.disable_ic = 1;
+		p->des01.erx.buffer1_size = BUF_SIZE_8KiB - 1;
+		/* in case we use jumbo frames */
+		p->des01.erx.buffer2_size = BUF_SIZE_8KiB - 1;
 		if (i == ring_size - 1)
 			p->des01.erx.end_ring = 1;
 		p++;
@@ -471,7 +503,19 @@ static void gmac_init_rx_desc(dma_desc * p, unsigned int ring_size,
 	return;
 }
 
-static void gmac_init_tx_desc(dma_desc * p, unsigned int ring_size)
+static void gmac_disable_rx_ic(struct dma_desc *p, unsigned int ring_size,
+			       int disable_ic)
+{
+	int i;
+	for (i = 0; i < ring_size; i++) {
+		if (i % disable_ic)
+			p->des01.erx.disable_ic = 1;
+		p++;
+	}
+	return;
+}
+
+static void gmac_init_tx_desc(struct dma_desc *p, unsigned int ring_size)
 {
 	int i;
 
@@ -485,62 +529,67 @@ static void gmac_init_tx_desc(dma_desc * p, unsigned int ring_size)
 	return;
 }
 
-static int gmac_read_tx_owner(dma_desc * p)
+static int gmac_get_tx_owner(struct dma_desc *p)
 {
 	return p->des01.etx.own;
 }
 
-static int gmac_read_rx_owner(dma_desc * p)
+static int gmac_get_rx_owner(struct dma_desc *p)
 {
 	return p->des01.erx.own;
 }
 
-static void gmac_set_tx_owner(dma_desc * p)
+static void gmac_set_tx_owner(struct dma_desc *p)
 {
 	p->des01.etx.own = 1;
 }
 
-static void gmac_set_rx_owner(dma_desc * p)
+static void gmac_set_rx_owner(struct dma_desc *p)
 {
 	p->des01.erx.own = 1;
 }
 
-static int gmac_get_tx_ls(dma_desc * p)
+static int gmac_get_tx_ls(struct dma_desc *p)
 {
 	return p->des01.etx.last_segment;
 }
 
-static void gmac_release_tx_desc(dma_desc * p)
+static void gmac_release_tx_desc(struct dma_desc *p)
 {
 	int ter = p->des01.etx.end_ring;
 
-	memset(p, 0, sizeof(dma_desc));
+	memset(p, 0, sizeof(struct dma_desc));
 	p->des01.etx.end_ring = ter;
 
 	return;
 }
 
-static void gmac_prepare_tx_desc(dma_desc * p, int is_fs, int len,
-				 unsigned int csum_flags)
+static void gmac_prepare_tx_desc(struct dma_desc *p, int is_fs, int len,
+				 int csum_flag)
 {
 	p->des01.etx.first_segment = is_fs;
-	p->des01.etx.buffer1_size = len;
-	if (csum_flags)
+	if (unlikely(len > BUF_SIZE_4KiB)) {
+		p->des01.etx.buffer1_size = BUF_SIZE_4KiB;
+		p->des01.etx.buffer2_size = len - BUF_SIZE_4KiB;
+	} else {
+		p->des01.etx.buffer1_size = len;
+	}
+	if (likely(csum_flag))
 		p->des01.etx.checksum_insertion = cic_full;
-	/*p->des01.etx.checksum_insertion = cic_no_pseudoheader; */
 }
 
-static void gmac_set_tx_ic(dma_desc * p, int value)
+static void gmac_clear_tx_ic(struct dma_desc *p)
 {
-	p->des01.etx.interrupt = value;
+	p->des01.etx.interrupt = 0;
 }
 
-static void gmac_set_tx_ls(dma_desc * p)
+static void gmac_close_tx_desc(struct dma_desc *p)
 {
 	p->des01.etx.last_segment = 1;
+	p->des01.etx.interrupt = 1;
 }
 
-static int gmac_get_rx_frame_len(dma_desc * p)
+static int gmac_get_rx_frame_len(struct dma_desc *p)
 {
 	return p->des01.erx.frame_length;
 }
@@ -550,50 +599,43 @@ struct device_ops gmac_driver = {
 	.dump_mac_regs = gmac_dump_regs,
 	.dma_init = gmac_dma_init,
 	.dump_dma_regs = gmac_dump_dma_regs,
-	.dma_operation_mode = gmac_dma_operation_mode,
+	.dma_mode = gmac_dma_operation_mode,
 	.dma_diagnostic_fr = gmac_dma_diagnostic_fr,
 	.tx_status = gmac_get_tx_frame_status,
 	.rx_status = gmac_get_rx_frame_status,
 	.get_tx_len = gmac_get_tx_len,
-	.rx_checksum = gmac_rx_checksum,
 	.set_filter = gmac_set_filter,
 	.flow_ctrl = gmac_flow_ctrl,
 	.pmt = gmac_pmt,
 	.init_rx_desc = gmac_init_rx_desc,
 	.init_tx_desc = gmac_init_tx_desc,
-	.read_tx_owner = gmac_read_tx_owner,
-	.read_rx_owner = gmac_read_rx_owner,
+	.get_tx_owner = gmac_get_tx_owner,
+	.get_rx_owner = gmac_get_rx_owner,
 	.release_tx_desc = gmac_release_tx_desc,
 	.prepare_tx_desc = gmac_prepare_tx_desc,
-	.set_tx_ic = gmac_set_tx_ic,
-	.set_tx_ls = gmac_set_tx_ls,
+	.clear_tx_ic = gmac_clear_tx_ic,
+	.close_tx_desc = gmac_close_tx_desc,
 	.get_tx_ls = gmac_get_tx_ls,
 	.set_tx_owner = gmac_set_tx_owner,
 	.set_rx_owner = gmac_set_rx_owner,
 	.get_rx_frame_len = gmac_get_rx_frame_len,
 	.host_irq_status = gmac_irq_status,
+	.disable_rx_ic = gmac_disable_rx_ic,
 };
 
-struct device_info_t *gmac_setup(unsigned long ioaddr)
+struct mac_device_info *gmac_setup(unsigned long ioaddr)
 {
-	struct device_info_t *mac;
-	unsigned int id;
-	id = (unsigned int)readl(ioaddr + GMAC_VERSION);
+	struct mac_device_info *mac;
+	u32 uid = readl(ioaddr + GMAC_VERSION);
 
 	printk(KERN_INFO "\tGMAC - user ID: 0x%x, Synopsys ID: 0x%x\n",
-	       ((id & 0x0000ff00) >> 8), (id & 0x000000ff));
+	       ((uid & 0x0000ff00) >> 8), (uid & 0x000000ff));
 
-	mac = kmalloc(sizeof(const struct device_info_t), GFP_KERNEL);
-	memset(mac, 0, sizeof(struct device_info_t));
+	mac = kmalloc(sizeof(const struct mac_device_info), GFP_KERNEL);
+	memset(mac, 0, sizeof(struct mac_device_info));
 
 	mac->ops = &gmac_driver;
 	mac->hw.pmt = PMT_SUPPORTED;
-#ifdef GMAC_TX_STORE_AND_FORWARD
-	mac->hw.csum = HAS_HW_CSUM;
-#else
-	mac->hw.csum = NO_HW_CSUM;
-#endif
-	mac->hw.buf_size = DMA_BUFFER_SIZE;
 	mac->hw.addr_high = GMAC_ADDR_HIGH;
 	mac->hw.addr_low = GMAC_ADDR_LOW;
 	mac->hw.link.port = GMAC_CONTROL_PS;
diff --git a/drivers/net/stmmac/gmac.h b/drivers/net/stmmac/gmac.h
index 338cad2..873ece4 100644
--- a/drivers/net/stmmac/gmac.h
+++ b/drivers/net/stmmac/gmac.h
@@ -16,31 +16,31 @@
 /* GMAC ID */
 #define GMAC_VERSION	0x00000020	/* GMAC CORE Version */
 #define GMAC_INT_STATUS	0x00000038	/* interrupt status register */
-enum gmac_irq_status{
-        time_stamp_irq = 0x0200,
-        mmc_rx_csum_offload_irq = 0x0080,
-        mmc_tx_irq = 0x0040,
-        mmc_rx_irq= 0x0020,
-        mmc_irq= 0x0010,
-        pmt_irq= 0x0008,
-        pcs_ane_irq= 0x0004,
-        pcs_link_irq= 0x0002,
-        rgmii_irq= 0x0001,
+enum gmac_irq_status {
+	time_stamp_irq = 0x0200,
+	mmc_rx_csum_offload_irq = 0x0080,
+	mmc_tx_irq = 0x0040,
+	mmc_rx_irq = 0x0020,
+	mmc_irq = 0x0010,
+	pmt_irq = 0x0008,
+	pcs_ane_irq = 0x0004,
+	pcs_link_irq = 0x0002,
+	rgmii_irq = 0x0001,
 };
 #define GMAC_INT_MASK	0x0000003c	/* interrupt mask register */
 
-#define GMAC_WAKEUP_FILTER       0x00000028      /* Wake-up Frame Filter */
+#define GMAC_WAKEUP_FILTER       0x00000028	/* Wake-up Frame Filter */
 
 /* PMT Control and Status */
 #define GMAC_PMT                 0x0000002c
-enum power_event{
-	pointer_reset  = 0x80000000,
+enum power_event {
+	pointer_reset = 0x80000000,
 	global_unicast = 0x00000200,
-	wake_up_rx_frame  = 0x00000040,
-	magic_frame    = 0x00000020,
+	wake_up_rx_frame = 0x00000040,
+	magic_frame = 0x00000020,
 	wake_up_frame_en = 0x00000004,
-	magic_pkt_en	 = 0x00000002,
-	power_down	 = 0x00000001,
+	magic_pkt_en = 0x00000002,
+	power_down = 0x00000001,
 };
 
 /* GMAC HW ADDR regs */
@@ -82,7 +82,8 @@ enum inter_frame_gap {
 #define GMAC_CONTROL_TE		0x00000008	/* Transmitter Enable */
 #define GMAC_CONTROL_RE		0x00000004	/* Receiver Enable */
 
-#define GMAC_CORE_INIT (GMAC_CONTROL_JD | GMAC_CONTROL_PS | GMAC_CONTROL_ACS | GMAC_CONTROL_IPC)
+#define GMAC_CORE_INIT (GMAC_CONTROL_JD | GMAC_CONTROL_PS | GMAC_CONTROL_ACS | \
+			GMAC_CONTROL_IPC | GMAC_CONTROL_JE | GMAC_CONTROL_BE)
 
 /* GMAC Frame Filter defines */
 #define GMAC_FRAME_FILTER_PR	0x00000001	/* Promiscuous Mode */
@@ -183,14 +184,3 @@ enum rtc_control {
 #define GMAC_MMC_RX_INTR   0x104
 #define GMAC_MMC_TX_INTR   0x108
 #define GMAC_MMC_RX_CSUM_OFFLOAD   0x208
-
-/* Transmit COE type 2 cannot be done in cut-through mode */
-#undef GMAC_TX_STORE_AND_FORWARD
-#define GMAC_TX_STORE_AND_FORWARD
-#undef GMAC_RX_STORE_AND_FORWARD
-/*#define GMAC_RX_STORE_AND_FORWARD*/
-
-#define STBUS_BRIDGE_OFFSET	0x00007000
-#define STBUS_BRIDGE_MAGIC	0x25C608 /* from validation */
-
-#define DMA_BUFFER_SIZE	8192 /* To support Jumbo */
diff --git a/drivers/net/stmmac/mac100.c b/drivers/net/stmmac/mac100.c
index 6cc009f..8032508 100644
--- a/drivers/net/stmmac/mac100.c
+++ b/drivers/net/stmmac/mac100.c
@@ -32,10 +32,7 @@
 #endif
 static void mac100_core_init(unsigned long ioaddr)
 {
-	unsigned int value = 0;
-
-	/* Set the MAC control register with our default value */
-	value = (unsigned int)readl(ioaddr + MAC_CONTROL);
+	u32 value = readl(ioaddr + MAC_CONTROL);
 	writel((value | MAC_CORE_INIT), ioaddr + MAC_CONTROL);
 
 #if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)
@@ -85,10 +82,8 @@ static void mac100_dump_mac_regs(unsigned long ioaddr)
 static int mac100_dma_init(unsigned long ioaddr, int pbl, u32 dma_tx,
 			   u32 dma_rx)
 {
-	unsigned int value;
-
+	u32 value = readl(ioaddr + DMA_BUS_MODE);
 	/* DMA SW reset */
-	value = (unsigned int)readl(ioaddr + DMA_BUS_MODE);
 	value |= DMA_BUS_MODE_SFT_RESET;
 	writel(value, ioaddr + DMA_BUS_MODE);
 	while ((readl(ioaddr + DMA_BUS_MODE) & DMA_BUS_MODE_SFT_RESET)) {
@@ -109,16 +104,17 @@ static int mac100_dma_init(unsigned long ioaddr, int pbl, u32 dma_tx,
 	return 0;
 }
 
-/* Store and Forward capability is not used.
+/* Store and Forward capability is not used at all..
  * The transmit threshold can be programmed by
  * setting the TTC bits in the DMA control register.*/
-static void mac100_dma_operation_mode(unsigned long ioaddr, int ttc)
+static void mac100_dma_operation_mode(unsigned long ioaddr, int txmode,
+				      int rxmode)
 {
-	unsigned int csr6 = (unsigned int)readl(ioaddr + DMA_CONTROL);
+	u32 csr6 = readl(ioaddr + DMA_CONTROL);
 
-	if (ttc <= 32)
+	if (txmode <= 32)
 		csr6 |= DMA_CONTROL_TTC_32;
-	else if (ttc <= 64)
+	else if (txmode <= 64)
 		csr6 |= DMA_CONTROL_TTC_64;
 	else
 		csr6 |= DMA_CONTROL_TTC_128;
@@ -150,10 +146,8 @@ static void mac100_dump_dma_regs(unsigned long ioaddr)
 static void mac100_dma_diagnostic_fr(void *data, struct stmmac_extra_stats *x,
 				     unsigned long ioaddr)
 {
-	unsigned long csr8;
 	struct net_device_stats *stats = (struct net_device_stats *)data;
-
-	csr8 = readl(ioaddr + DMA_MISSED_FRAME_CTR);
+	u32 csr8 = readl(ioaddr + DMA_MISSED_FRAME_CTR);
 
 	if (unlikely(csr8)) {
 		if (csr8 & DMA_MISSED_FRAME_OVE) {
@@ -179,7 +173,7 @@ static void mac100_dma_diagnostic_fr(void *data, struct stmmac_extra_stats *x,
 }
 
 static int mac100_get_tx_frame_status(void *data, struct stmmac_extra_stats *x,
-				      dma_desc * p, unsigned long ioaddr)
+				      struct dma_desc *p, unsigned long ioaddr)
 {
 	int ret = 0;
 	struct net_device_stats *stats = (struct net_device_stats *)data;
@@ -211,30 +205,31 @@ static int mac100_get_tx_frame_status(void *data, struct stmmac_extra_stats *x,
 	}
 	if (unlikely(p->des01.tx.deferred)) {
 		x->tx_deferred++;
-		ret = -1;
 	}
 
 	return (ret);
 }
 
-static int mac100_get_tx_len(dma_desc * p)
+static int mac100_get_tx_len(struct dma_desc *p)
 {
 	return (p->des01.tx.buffer1_size);
 }
 
 /* This function verifies if the incoming frame has some errors 
- * and, if required, updates the multicast statistics. */
+ * and, if required, updates the multicast statistics.
+ * In case of success, it returns  csum_none becasue the device
+ * is not able to compute the csum in HW. */
 static int mac100_get_rx_frame_status(void *data, struct stmmac_extra_stats *x,
-				      dma_desc * p)
+				      struct dma_desc *p)
 {
-	int ret = 0;
+	int ret = csum_none;
 	struct net_device_stats *stats = (struct net_device_stats *)data;
 
 	if (unlikely(p->des01.rx.last_descriptor == 0)) {
 		printk(KERN_WARNING "mac100 Error: Oversized Ethernet "
 		       "frame spanned multiple buffers\n");
 		stats->rx_length_errors++;
-		return -1;
+		return discard_frame;
 	}
 
 	if (unlikely(p->des01.rx.error_summary)) {
@@ -258,18 +253,18 @@ static int mac100_get_rx_frame_status(void *data, struct stmmac_extra_stats *x,
 			x->rx_crc++;
 			stats->rx_crc_errors++;
 		}
-		ret = -1;
+		ret = discard_frame;
 	}
 	if (unlikely(p->des01.rx.dribbling))
-		ret = -1;
+		ret = discard_frame;
 
 	if (unlikely(p->des01.rx.length_error)) {
 		x->rx_lenght++;
-		ret = -1;
+		ret = discard_frame;
 	}
 	if (unlikely(p->des01.rx.mii_error)) {
 		x->rx_mii++;
-		ret = -1;
+		ret = discard_frame;
 	}
 	if (p->des01.rx.multicast_frame) {
 		x->rx_multicast++;
@@ -284,16 +279,10 @@ static void mac100_irq_status(unsigned long ioaddr)
 	return;
 }
 
-static int mac100_rx_checksum(dma_desc * p)
-{
-	/* The device is not able to compute the csum in HW. */
-	return -1;
-}
-
 static void mac100_set_filter(struct net_device *dev)
 {
 	unsigned long ioaddr = dev->base_addr;
-	unsigned int value = (unsigned int)readl(ioaddr + MAC_CONTROL);
+	u32 value = readl(ioaddr + MAC_CONTROL);
 
 	if (dev->flags & IFF_PROMISC) {
 		value |= MAC_CONTROL_PR;
@@ -364,15 +353,12 @@ static void mac100_pmt(unsigned long ioaddr, unsigned long mode)
 	return;
 }
 
-static void mac100_init_rx_desc(dma_desc * p, unsigned int ring_size,
-				int rx_irq_threshold)
+static void mac100_init_rx_desc(struct dma_desc *p, unsigned int ring_size)
 {
 	int i;
 	for (i = 0; i < ring_size; i++) {
 		p->des01.rx.own = 1;
-		p->des01.rx.buffer1_size = DMA_BUFFER_SIZE - 1;
-		if (i % rx_irq_threshold)
-			p->des01.rx.disable_ic = 1;
+		p->des01.rx.buffer1_size = BUF_SIZE_2KiB - 1;
 		if (i == ring_size - 1) {
 			p->des01.rx.end_ring = 1;
 		}
@@ -381,7 +367,19 @@ static void mac100_init_rx_desc(dma_desc * p, unsigned int ring_size,
 	return;
 }
 
-static void mac100_init_tx_desc(dma_desc * p, unsigned int ring_size)
+static void mac100_disable_rx_ic(struct dma_desc *p, unsigned int ring_size,
+				 int disable_ic)
+{
+	int i;
+	for (i = 0; i < ring_size; i++) {
+		if (i % disable_ic)
+			p->des01.rx.disable_ic = 1;
+		p++;
+	}
+	return;
+}
+
+static void mac100_init_tx_desc(struct dma_desc *p, unsigned int ring_size)
 {
 	int i;
 	for (i = 0; i < ring_size; i++) {
@@ -394,36 +392,36 @@ static void mac100_init_tx_desc(dma_desc * p, unsigned int ring_size)
 	return;
 }
 
-static int mac100_read_tx_owner(dma_desc * p)
+static int mac100_get_tx_owner(struct dma_desc *p)
 {
 	return p->des01.tx.own;
 }
 
-static int mac100_read_rx_owner(dma_desc * p)
+static int mac100_get_rx_owner(struct dma_desc *p)
 {
 	return p->des01.rx.own;
 }
 
-static void mac100_set_tx_owner(dma_desc * p)
+static void mac100_set_tx_owner(struct dma_desc *p)
 {
 	p->des01.tx.own = 1;
 }
 
-static void mac100_set_rx_owner(dma_desc * p)
+static void mac100_set_rx_owner(struct dma_desc *p)
 {
 	p->des01.rx.own = 1;
 }
 
-static int mac100_get_tx_ls(dma_desc * p)
+static int mac100_get_tx_ls(struct dma_desc *p)
 {
 	return p->des01.tx.last_segment;
 }
 
-static void mac100_release_tx_desc(dma_desc * p)
+static void mac100_release_tx_desc(struct dma_desc *p)
 {
 	int ter = p->des01.tx.end_ring;
 
-/*	memset(p, 0, sizeof(dma_desc));*/
+/*	memset(p, 0, sizeof(struct dma_desc));*/
 	/* clean field used within the xmit */
 	p->des01.tx.first_segment = 0;
 	p->des01.tx.last_segment = 0;
@@ -446,24 +444,25 @@ static void mac100_release_tx_desc(dma_desc * p)
 	return;
 }
 
-static void mac100_prepare_tx_desc(dma_desc * p, int is_fs, int len,
-				   unsigned int csum_flags)
+static void mac100_prepare_tx_desc(struct dma_desc *p, int is_fs, int len,
+				   int csum_flag)
 {
 	p->des01.tx.first_segment = is_fs;
 	p->des01.tx.buffer1_size = len;
 }
 
-static void mac100_set_tx_ic(dma_desc * p, int value)
+static void mac100_clear_tx_ic(struct dma_desc *p)
 {
-	p->des01.tx.interrupt = value;
+	p->des01.tx.interrupt = 0;
 }
 
-static void mac100_set_tx_ls(dma_desc * p)
+static void mac100_close_tx_desc(struct dma_desc *p)
 {
 	p->des01.tx.last_segment = 1;
+	p->des01.tx.interrupt = 1;
 }
 
-static int mac100_get_rx_frame_len(dma_desc * p)
+static int mac100_get_rx_frame_len(struct dma_desc *p)
 {
 	return p->des01.rx.frame_length;
 }
@@ -473,43 +472,41 @@ struct device_ops mac100_driver = {
 	.dump_mac_regs = mac100_dump_mac_regs,
 	.dma_init = mac100_dma_init,
 	.dump_dma_regs = mac100_dump_dma_regs,
-	.dma_operation_mode = mac100_dma_operation_mode,
+	.dma_mode = mac100_dma_operation_mode,
 	.dma_diagnostic_fr = mac100_dma_diagnostic_fr,
 	.tx_status = mac100_get_tx_frame_status,
 	.rx_status = mac100_get_rx_frame_status,
 	.get_tx_len = mac100_get_tx_len,
-	.rx_checksum = mac100_rx_checksum,
 	.set_filter = mac100_set_filter,
 	.flow_ctrl = mac100_flow_ctrl,
 	.pmt = mac100_pmt,
 	.init_rx_desc = mac100_init_rx_desc,
 	.init_tx_desc = mac100_init_tx_desc,
-	.read_tx_owner = mac100_read_tx_owner,
-	.read_rx_owner = mac100_read_rx_owner,
+	.get_tx_owner = mac100_get_tx_owner,
+	.get_rx_owner = mac100_get_rx_owner,
 	.release_tx_desc = mac100_release_tx_desc,
 	.prepare_tx_desc = mac100_prepare_tx_desc,
-	.set_tx_ic = mac100_set_tx_ic,
-	.set_tx_ls = mac100_set_tx_ls,
+	.clear_tx_ic = mac100_clear_tx_ic,
+	.close_tx_desc = mac100_close_tx_desc,
 	.get_tx_ls = mac100_get_tx_ls,
 	.set_tx_owner = mac100_set_tx_owner,
 	.set_rx_owner = mac100_set_rx_owner,
 	.get_rx_frame_len = mac100_get_rx_frame_len,
 	.host_irq_status = mac100_irq_status,
+	.disable_rx_ic = mac100_disable_rx_ic,
 };
 
-struct device_info_t *mac100_setup(unsigned long ioaddr)
+struct mac_device_info *mac100_setup(unsigned long ioaddr)
 {
-	struct device_info_t *mac;
+	struct mac_device_info *mac;
 
-	mac = kmalloc(sizeof(const struct device_info_t), GFP_KERNEL);
-	memset(mac, 0, sizeof(struct device_info_t));
+	mac = kmalloc(sizeof(const struct mac_device_info), GFP_KERNEL);
+	memset(mac, 0, sizeof(struct mac_device_info));
 
 	printk(KERN_INFO "\tMAC 10/100\n");
 
 	mac->ops = &mac100_driver;
 	mac->hw.pmt = PMT_NOT_SUPPORTED;
-	mac->hw.buf_size = DMA_BUFFER_SIZE;
-	mac->hw.csum = NO_HW_CSUM;
 	mac->hw.addr_high = MAC_ADDR_HIGH;
 	mac->hw.addr_low = MAC_ADDR_LOW;
 	mac->hw.link.port = MAC_CONTROL_PS;
diff --git a/drivers/net/stmmac/mac100.h b/drivers/net/stmmac/mac100.h
index 97bc789..8fc54b1 100644
--- a/drivers/net/stmmac/mac100.h
+++ b/drivers/net/stmmac/mac100.h
@@ -90,5 +90,3 @@ enum ttc_control {
 #define DMA_MISSED_FRAME_OVE_CNTR 0x0ffe0000	/* Overflow Frame Counter */
 #define DMA_MISSED_FRAME_OVE_M	0x00010000	/* Missed Frame Overflow */
 #define DMA_MISSED_FRAME_M_CNTR	0x0000ffff	/* Missed Frame Couinter */
-
-#define DMA_BUFFER_SIZE	2048
diff --git a/drivers/net/stmmac/stmmac.h b/drivers/net/stmmac/stmmac.h
index 1ed4ae8..836e4f9 100644
--- a/drivers/net/stmmac/stmmac.h
+++ b/drivers/net/stmmac/stmmac.h
@@ -1,62 +1,72 @@
 #define ETH_RESOURCE_NAME	"stmmaceth"
 #define PHY_RESOURCE_NAME	"stmmacphy"
-#define DRV_MODULE_VERSION	"Aug_08"
+#define DRV_MODULE_VERSION	"Nov_08"
 
 #if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)
 #define STMMAC_VLAN_TAG_USED
 #endif
 
 #include "common.h"
+#ifdef CONFIG_STMMAC_TIMER
+#include "stmmac_timer.h"
+#endif
+
+struct stmmac_priv {
+	struct net_device *dev;
+	struct device *device;
+
+	int pbl;
+	int is_gmac;
+	void (*fix_mac_speed) (void *priv, unsigned int speed);
+	void *bsp_priv;
 
-/* Struct private for the STMMAC driver */
-struct eth_driver_local {
 	int bus_id;
 	int phy_addr;
-	int phy_irq;
 	int phy_mask;
 	phy_interface_t phy_interface;
 	int (*phy_reset) (void *priv);
-	void (*fix_mac_speed) (void *priv, unsigned int speed);
-	void *bsp_priv;
+	int phy_irq;
+
+	struct phy_device *phydev;
 	int oldlink;
 	int speed;
 	int oldduplex;
-	struct phy_device *phydev;
-	int pbl;
-	int is_gmac;
-	unsigned int ip_header_len;
+
 	struct mii_bus *mii;
-	u32 msg_enable;
+
 	spinlock_t lock;
 	spinlock_t tx_lock;
-	dma_desc *dma_tx;
-	dma_desc *dma_rx;
+
+	struct dma_desc *dma_tx	____cacheline_aligned;
 	dma_addr_t dma_tx_phy;
-	unsigned int cur_tx, dirty_tx;
-	struct sk_buff **tx_skbuff;
+	struct dma_desc *dma_rx	____cacheline_aligned;
 	dma_addr_t dma_rx_phy;
-	int dma_buf_sz;
-	unsigned int rx_buff;
-	int rx_csum;
-	unsigned int cur_rx, dirty_rx;
+	struct sk_buff **tx_skbuff;
 	struct sk_buff **rx_skbuff;
 	dma_addr_t *rx_skbuff_dma;
-	struct device *device;
+
+	unsigned int cur_rx, dirty_rx;
+	unsigned int cur_tx, dirty_tx;
 	unsigned int dma_tx_size;
 	unsigned int dma_rx_size;
-	struct device_info_t *mac_type;
+	unsigned int dma_buf_sz;
+	unsigned int rx_buff;
+	struct tasklet_struct tx_task;
+	struct stmmac_extra_stats xstats;
+	struct mac_device_info *mac_type;
 	unsigned int flow_ctrl;
 	unsigned int pause;
-#ifdef STMMAC_VLAN_TAG_USED
-	struct vlan_group *vlgrp;
-#endif
-	struct net_device *dev;
-	struct stmmac_extra_stats xstats;
+	u32 msg_enable;
+	int rx_csum;
+	int tx_coe;
 	int wolopts;
 	int wolenabled;
-	int tx_aggregation;
-	int has_timer;
-	struct timer_list timer;
 	int shutdown;
-	struct tasklet_struct tx_task;
+	int tx_coalesce;
+#ifdef CONFIG_STMMAC_TIMER
+	struct stmmac_timer *tm;
+#endif
+#ifdef STMMAC_VLAN_TAG_USED
+	struct vlan_group *vlgrp;
+#endif
 };
diff --git a/drivers/net/stmmac/stmmac_ethtool.c b/drivers/net/stmmac/stmmac_ethtool.c
index c2688c1..ee5a345 100644
--- a/drivers/net/stmmac/stmmac_ethtool.c
+++ b/drivers/net/stmmac/stmmac_ethtool.c
@@ -32,8 +32,8 @@ void stmmac_ethtool_getdrvinfo(struct net_device *dev,
 
 int stmmac_ethtool_getsettings(struct net_device *dev, struct ethtool_cmd *cmd)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-	struct phy_device *phy = lp->phydev;
+	struct stmmac_priv *priv = netdev_priv(dev);
+	struct phy_device *phy = priv->phydev;
 	int rc;
 	if (phy == NULL) {
 		printk(KERN_ERR "%s: %s: PHY is not registered\n",
@@ -48,35 +48,35 @@ int stmmac_ethtool_getsettings(struct net_device *dev, struct ethtool_cmd *cmd)
 	}
 
 	cmd->transceiver = XCVR_INTERNAL;
-	spin_lock_irq(&lp->lock);
+	spin_lock_irq(&priv->lock);
 	rc = phy_ethtool_gset(phy, cmd);
-	spin_unlock_irq(&lp->lock);
+	spin_unlock_irq(&priv->lock);
 	return rc;
 }
 
 int stmmac_ethtool_setsettings(struct net_device *dev, struct ethtool_cmd *cmd)
 {
-	struct eth_driver_local *lp = dev->priv;
-	struct phy_device *phy = lp->phydev;
+	struct stmmac_priv *priv = dev->priv;
+	struct phy_device *phy = priv->phydev;
 	int rc;
 
-	spin_lock(&lp->lock);
+	spin_lock(&priv->lock);
 	rc = phy_ethtool_sset(phy, cmd);
-	spin_unlock(&lp->lock);
+	spin_unlock(&priv->lock);
 
 	return rc;
 }
 
 u32 stmmac_ethtool_getmsglevel(struct net_device * dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-	return lp->msg_enable;
+	struct stmmac_priv *priv = netdev_priv(dev);
+	return priv->msg_enable;
 }
 
 void stmmac_ethtool_setmsglevel(struct net_device *dev, u32 level)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-	lp->msg_enable = level;
+	struct stmmac_priv *priv = netdev_priv(dev);
+	priv->msg_enable = level;
 
 }
 
@@ -114,40 +114,41 @@ void stmmac_ethtool_gregs(struct net_device *dev,
 	return;
 }
 
-int stmmac_ethtool_set_tx_csum(struct net_device *dev, u32 data)
+int stmmac_ethtool_set_tx_csum(struct net_device *netdev, u32 data)
 {
-	if (data)
-		dev->features |= NETIF_F_HW_CSUM;
-	else
-		dev->features &= ~NETIF_F_HW_CSUM;
+	if (data) {
+		netdev->features |= NETIF_F_HW_CSUM;
+	} else {
+		netdev->features &= ~NETIF_F_HW_CSUM;
+	}
 
 	return 0;
 }
 
 u32 stmmac_ethtool_get_rx_csum(struct net_device * dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
-	return (lp->rx_csum);
+	return (priv->rx_csum);
 }
 
 static void
 stmmac_get_pauseparam(struct net_device *netdev,
 		      struct ethtool_pauseparam *pause)
 {
-	struct eth_driver_local *lp = netdev_priv(netdev);
+	struct stmmac_priv *priv = netdev_priv(netdev);
 
-	spin_lock(&lp->lock);
+	spin_lock(&priv->lock);
 
 	pause->rx_pause = pause->tx_pause = 0;
-	pause->autoneg = lp->phydev->autoneg;
+	pause->autoneg = priv->phydev->autoneg;
 
-	if (lp->flow_ctrl & FLOW_RX)
+	if (priv->flow_ctrl & FLOW_RX)
 		pause->rx_pause = 1;
-	if (lp->flow_ctrl & FLOW_TX)
+	if (priv->flow_ctrl & FLOW_TX)
 		pause->tx_pause = 1;
 
-	spin_unlock(&lp->lock);
+	spin_unlock(&priv->lock);
 	return;
 }
 
@@ -155,19 +156,19 @@ static int
 stmmac_set_pauseparam(struct net_device *netdev,
 		      struct ethtool_pauseparam *pause)
 {
-	struct eth_driver_local *lp = netdev_priv(netdev);
-	struct phy_device *phy = lp->phydev;
+	struct stmmac_priv *priv = netdev_priv(netdev);
+	struct phy_device *phy = priv->phydev;
 	int new_pause = FLOW_OFF;
 	int ret = 0;
 
-	spin_lock(&lp->lock);
+	spin_lock(&priv->lock);
 
 	if (pause->rx_pause)
 		new_pause |= FLOW_RX;
 	if (pause->tx_pause)
 		new_pause |= FLOW_TX;
 
-	lp->flow_ctrl = new_pause;
+	priv->flow_ctrl = new_pause;
 
 	if (phy->autoneg) {
 		if (netif_running(netdev)) {
@@ -184,10 +185,10 @@ stmmac_set_pauseparam(struct net_device *netdev,
 		}
 	} else {
 		unsigned long ioaddr = netdev->base_addr;
-		lp->mac_type->ops->flow_ctrl(ioaddr, phy->duplex,
-					     lp->flow_ctrl, lp->pause);
+		priv->mac_type->ops->flow_ctrl(ioaddr, phy->duplex,
+					       priv->flow_ctrl, priv->pause);
 	}
-	spin_unlock(&lp->lock);
+	spin_unlock(&priv->lock);
 	return ret;
 }
 
@@ -231,6 +232,7 @@ static struct {
 	"tx_early_irq"}, {
 	"fatal_bus_error_irq"}, {
 	"rx_poll_n"}, {
+	"tx_task_n"}, {
 	"tx_payload_error"}, {
 	"tx_ip_header_error"}, {
 	"rx_missed_cntr"}, {
@@ -244,14 +246,20 @@ static int stmmac_stats_count(struct net_device *dev)
 static void stmmac_ethtool_stats(struct net_device *dev,
 				 struct ethtool_stats *dummy, u64 * buf)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	unsigned long ioaddr = dev->base_addr;
 	u32 *extra;
 	int i;
 
-	lp->mac_type->ops->dma_diagnostic_fr(&dev->stats, &lp->xstats, ioaddr);
+	priv->mac_type->ops->dma_diagnostic_fr(&dev->stats, &priv->xstats,
+					       ioaddr);
+	/* rx/tx extra stats such as tx/rx_bytes and rx_dropped are not
+	   updated within the critical paths. It's worth getting them here. */
+	priv->xstats.tx_bytes = dev->stats.tx_bytes;
+	priv->xstats.rx_dropped = dev->stats.rx_dropped;
+	priv->xstats.rx_bytes = dev->stats.rx_bytes;
 
-	extra = (u32 *) & lp->xstats;
+	extra = (u32 *) & priv->xstats;
 
 	for (i = 0; i < EXTRA_STATS; i++)
 		buf[i] = extra[i];
@@ -273,35 +281,35 @@ static void stmmac_get_strings(struct net_device *dev, u32 stringset, u8 * buf)
 
 static void stmmac_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
-	spin_lock_irq(&lp->lock);
-	if (lp->wolenabled == PMT_SUPPORTED) {
+	spin_lock_irq(&priv->lock);
+	if (priv->wolenabled == PMT_SUPPORTED) {
 		wol->supported = WAKE_MAGIC /*| WAKE_UCAST */ ;
-		wol->wolopts = lp->wolopts;
+		wol->wolopts = priv->wolopts;
 	}
-	spin_unlock_irq(&lp->lock);
+	spin_unlock_irq(&priv->lock);
 }
 
 static int stmmac_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	u32 support = WAKE_MAGIC;
 
-	if (lp->wolenabled == PMT_NOT_SUPPORTED)
+	if (priv->wolenabled == PMT_NOT_SUPPORTED)
 		return -EINVAL;
 
 	if (wol->wolopts & ~support)
 		return -EINVAL;
 
 	if (wol->wolopts == 0)
-		device_set_wakeup_enable(lp->device, 0);
+		device_set_wakeup_enable(priv->device, 0);
 	else
-		device_set_wakeup_enable(lp->device, 1);
+		device_set_wakeup_enable(priv->device, 1);
 
-	spin_lock_irq(&lp->lock);
-	lp->wolopts = wol->wolopts;
-	spin_unlock_irq(&lp->lock);
+	spin_lock_irq(&priv->lock);
+	priv->wolopts = wol->wolopts;
+	spin_unlock_irq(&priv->lock);
 
 	return 0;
 }
@@ -325,8 +333,6 @@ struct ethtool_ops stmmac_ethtool_ops = {
 	.get_tso = ethtool_op_get_tso,
 	.set_tso = ethtool_op_set_tso,
 #endif
-	.get_ufo = ethtool_op_get_ufo,
-	.set_ufo = ethtool_op_set_ufo,
 	.get_pauseparam = stmmac_get_pauseparam,
 	.set_pauseparam = stmmac_set_pauseparam,
 	.get_ethtool_stats = stmmac_ethtool_stats,
diff --git a/drivers/net/stmmac/stmmac_main.c b/drivers/net/stmmac/stmmac_main.c
index bf5f019..186c711 100644
--- a/drivers/net/stmmac/stmmac_main.c
+++ b/drivers/net/stmmac/stmmac_main.c
@@ -2,53 +2,17 @@
  *
  * drivers/net/stmmac/stmmac_main.c
  *
- * This is the driver for the MAC 10/100/1000 on-chip Ethernet controllers.
+ * This is the driver for the MAC 10/100/1000 on-chip Ethernet controllers
+ * (Synopsys IP).
  *
  * Author: Giuseppe Cavallaro <peppe.cavallaro@st.com>
  *
- * Copyright (C) 2007 by STMicroelectronics
+ * Copyright (C) 2007-2008 by STMicroelectronics
  *
- * ----------------------------------------------------------------------------
- *
- * Changelog:
- * August 2008:
- *	- On egress packets use the skb_checksum_help function to compute
- *	  the csum calculation.
- * July 2008:
- *	- Removed timer optimization through kernel timers.
- *	  RTC and TMU2 timers are also used for mitigating the transmission IRQs.
- * May 2008:
- *	- Suspend/resume functions reviewed and tested the Wake-Up-on LAN
- *	  on the GMAC (mb618).
- *	- Fixed the GMAC 6-bit CRC hash filtering.
- *	- Removed stats from the private structure.
- * April 2008:
- *	- Added kernel timer for handling interrupts.
- *	- Reviewed the GMAC HW configuration.
- *	- Frozen GMAC MMC counters in order to handle related interrupts.
- *	- Fixed a bug within the stmmac_rx function (wrong owner checking).
- * March 2008:
- *	- Added Rx timer optimization (also mitigated by using the normal
- *	  interrupt on completion). See stmmac_timer.c file.
- *	- Added hardware csum for the Gigabit Ethernet device.
- *	- Reviewed the descriptor structures and added a new header file
- *	  (descs.h). 
- * Jan 2008:
- *	- First GMAC working.
- *	- Reviewed stmmac_poll in order to make easier the NAPI v5 porting.
- *	- Reviewed the xmit method in order to support large frames.
- *	- Removed self locking in the xmit (NETIF_F_LLTX).
- *	- Reviwed the software interrupt mitigation (as experimental code).
- *	- Reviewed supend and resume functions.
- * Dec 2007:
- *	- Reviewed the xmit method.
- *	- Fixed transmit errors detection.
- *	- Fixed "dma_[tx/rx]_size_param" module parameters.
- *	- Removed "dma_buffer_size" as module parameter.
- *	- Reviewed ethtool support and added extra statistics.
- * Oct 2007:
- *	- The driver completely merges the new GMAC code and the previous 
- *	  stmmac Ethernet driver (tested on the 7109/7200 STM platforms).
+ * Documentation available at:
+ *  http://www.stlinux.com
+ * Support available at:
+ *  https://bugzilla.stlinux.com/
  * ===========================================================================*/
 
 #include <linux/module.h>
@@ -77,8 +41,8 @@
 /*#define STMMAC_DEBUG*/
 #ifdef STMMAC_DEBUG
 #define DBG(nlevel, klevel, fmt, args...) \
-		(void)(netif_msg_##nlevel(lp) && \
-		printk(KERN_##klevel fmt, ## args))
+		((void)(netif_msg_##nlevel(priv) && \
+		printk(KERN_##klevel fmt, ## args)))
 #else
 #define DBG(nlevel, klevel, fmt, args...)  do { } while(0)
 #endif
@@ -94,85 +58,94 @@
 #undef STMMAC_XMIT_DEBUG
 /*#define STMMAC_XMIT_DEBUG*/
 
-#define MIN_MTU 46
-#define MAX_MTU ETH_DATA_LEN
-
-#define STMMAC_ALIGN(x)	ALIGN((x), dma_get_cache_alignment())
+#define STMMAC_ALIGN(x)	L1_CACHE_ALIGN(x)
 #define STMMAC_IP_ALIGN NET_IP_ALIGN
+#define JUMBO_LEN	9000
 
-#define TX_BUFFS_AVAIL(lp) \
-	(lp->dirty_tx + lp->dma_tx_size - lp->cur_tx - 1)
-
-/* Module Arguments */
+/* Module parameters */
 #define TX_TIMEO (5*HZ)
 static int watchdog = TX_TIMEO;
 module_param(watchdog, int, S_IRUGO | S_IWUSR);
-MODULE_PARM_DESC(watchdog, "Transmit Timeout (in milliseconds)");
+MODULE_PARM_DESC(watchdog, "Transmit timeout");
 
 static int debug = -1;		/* -1: default, 0: no output, 16:  all */
 module_param(debug, int, S_IRUGO | S_IWUSR);
 MODULE_PARM_DESC(debug, "Message Level (0: no output, 16: all)");
 
-static int rx_copybreak = 0;
-module_param(rx_copybreak, int, S_IRUGO | S_IWUSR);
-MODULE_PARM_DESC(rx_copybreak, "Copy only tiny-frames");
+static int minrx;
+module_param(minrx, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(minrx, "Copy only tiny-frames");
 
-static int phy_n = -1;
-module_param(phy_n, int, S_IRUGO);
-MODULE_PARM_DESC(phy_n, "Physical device address");
+static int phyaddr = -1;
+module_param(phyaddr, int, S_IRUGO);
+MODULE_PARM_DESC(phyaddr, "Physical device address");
 
-#define DMA_TX_SIZE 64
-static int dma_tx_size_param = DMA_TX_SIZE;
-module_param(dma_tx_size_param, int, S_IRUGO);
-MODULE_PARM_DESC(dma_tx_size_param, "Number of descriptors in the TX list");
+#define DMA_TX_SIZE 128
+static int dma_txsize = DMA_TX_SIZE;
+module_param(dma_txsize, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(dma_txsize, "Number of descriptors in the TX list");
 
-#define DMA_RX_SIZE 64
-static int dma_rx_size_param = DMA_RX_SIZE;
-module_param(dma_rx_size_param, int, S_IRUGO);
-MODULE_PARM_DESC(dma_rx_size_param, "Number of descriptors in the RX list");
+#define DMA_RX_SIZE 128
+static int dma_rxsize = DMA_RX_SIZE;
+module_param(dma_rxsize, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(dma_rxsize, "Number of descriptors in the RX list");
 
 static int flow_ctrl = FLOW_OFF;
-module_param(flow_ctrl, int, S_IRUGO);
+module_param(flow_ctrl, int, S_IRUGO | S_IWUSR);
 MODULE_PARM_DESC(flow_ctrl, "Flow control ability [on/off]");
 
 static int pause = PAUSE_TIME;
-module_param(pause, int, S_IRUGO);
+module_param(pause, int, S_IRUGO | S_IWUSR);
 MODULE_PARM_DESC(pause, "Flow Control Pause Time");
 
-#define TTC_DEFAULT 0x40
-static int threshold_ctrl = TTC_DEFAULT;
-module_param(threshold_ctrl, int, S_IRUGO);
-MODULE_PARM_DESC(threshold_ctrl, "tranfer threshold control");
+#define TC_DEFAULT 64
+static int tc = TC_DEFAULT;
+module_param(tc, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(tc, "DMA threshold control value");
 
+/*
+ * These values have been set based on testing data as well as attempting
+ * to minimize response time while increasing bulk throughput. */
 #if defined (CONFIG_STMMAC_TIMER)
-#define RX_IRQ_THRESHOLD	16	/* mitigate rx irq */
-#define TX_AGGREGATION		32	/* mitigate tx irq too */
+#define RX_COALESCE	32
+#define TX_COALESCE	64
 #else
-#define RX_IRQ_THRESHOLD 1	/* always Interrupt on completion */
-#define TX_AGGREGATION	-1	/* no mitigation by default */
+#define RX_COALESCE	1	/* Always interrupt on completion */
+#define TX_COALESCE	-1	/* No moderation by default */
 #endif
 
-/* Using timer optimizations, it's worth having some interrupts on frame 
- * reception. This makes safe the network activity especially for the TCP 
- * traffic. */
-static int rx_irq_mitigation = RX_IRQ_THRESHOLD;
-module_param(rx_irq_mitigation, int, S_IRUGO);
-MODULE_PARM_DESC(rx_irq_mitigation, "Rx irq mitigation threshold");
+/* It makes sense to combine interrupt coalescence when the timer is enabled
+ * to avoid adverse effects on timing and make safe the TCP traffic.*/
+static int rx_coalesce = RX_COALESCE;
+module_param(rx_coalesce, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(rx_coalesce, "Rx irq coalescence parameter");
 
-static int tx_aggregation = TX_AGGREGATION;
-module_param(tx_aggregation, int, S_IRUGO | S_IWUSR);
-MODULE_PARM_DESC(tx_aggregation, "Tx aggregation value");
+static int tx_coalesce = TX_COALESCE;
+module_param(tx_coalesce, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(tx_coalesce, "Tx irq coalescence parameter");
 
-/* Pay attention to tune timer parameters; take care of both
+/* Pay attention to tune this parameter; take care of both
  * hardware capability and network stabitily/performance impact. 
  * Many tests showed that ~4ms latency seems to be good enough. */
 #ifdef CONFIG_STMMAC_TIMER
 #define DEFAULT_PERIODIC_RATE	256
-static int periodic_rate = DEFAULT_PERIODIC_RATE;
-module_param(periodic_rate, int, S_IRUGO | S_IWUSR);
-MODULE_PARM_DESC(periodic_rate, "Timer periodic rate (default: 256Hz)");
+static int tmrate = DEFAULT_PERIODIC_RATE;
+module_param(tmrate, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(tmrate, "External timer freq. (default: 256Hz)");
 #endif
 
+#define DMA_BUFFER_SIZE	BUF_SIZE_2KiB
+static int buf_sz = DMA_BUFFER_SIZE;
+module_param(buf_sz, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(buf_sz, "DMA buffer size");
+
+/* In case of Giga ETH, we can enable/disable the COE for the
+ * transmit HW checksum computation.
+ * Note that, if tx csum is off in HW, SG will be still supported. */
+static int tx_coe = HW_CSUM;
+module_param(tx_coe, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(tx_coe, "GMAC COE type 2 [on/off]");
+
 static const u32 default_msg_level = (NETIF_MSG_DRV | NETIF_MSG_PROBE |
 				      NETIF_MSG_LINK | NETIF_MSG_IFUP |
 				      NETIF_MSG_IFDOWN | NETIF_MSG_TIMER);
@@ -181,44 +154,36 @@ static irqreturn_t stmmac_interrupt(int irq, void *dev_id);
 static int stmmac_rx(struct net_device *dev, int limit);
 
 extern struct ethtool_ops stmmac_ethtool_ops;
-extern struct device_info_t *gmac_setup(unsigned long addr);
-extern struct device_info_t *mac100_setup(unsigned long addr);
 extern int stmmac_mdio_unregister(struct net_device *ndev);
 extern int stmmac_mdio_register(struct net_device *ndev);
 
-#ifdef CONFIG_STMMAC_TIMER
-extern int stmmac_timer_close(void);
-extern int stmmac_timer_stop(void);
-extern int stmmac_timer_start(unsigned int freq);
-extern int stmmac_timer_open(struct net_device *dev, unsigned int freq);
-#endif
-
+/**
+ * stmmac_verify_args - Check work parameters passed to the driver
+ * Description: wrong parameters are replaced with the default values
+ */
 static __inline__ void stmmac_verify_args(void)
 {
-	/* Wrong parameters are replaced with the default values */
 	if (watchdog < 0)
 		watchdog = TX_TIMEO;
-	if (rx_copybreak < 0)
-		rx_copybreak = ETH_FRAME_LEN;
-	if (dma_rx_size_param < 0)
-		dma_rx_size_param = DMA_RX_SIZE;
-	if (dma_tx_size_param < 0)
-		dma_tx_size_param = DMA_TX_SIZE;
-
+	if (minrx < 0)
+		minrx = ETH_FRAME_LEN;
+	if (dma_rxsize < 0)
+		dma_rxsize = DMA_RX_SIZE;
+	if (dma_txsize < 0)
+		dma_txsize = DMA_TX_SIZE;
+	if (tx_coalesce >= (dma_txsize))
+		tx_coalesce = TX_COALESCE;
+	if (rx_coalesce > (dma_rxsize))
+		rx_coalesce = RX_COALESCE;
+	if ((buf_sz < DMA_BUFFER_SIZE) || (buf_sz > BUF_SIZE_16KiB))
+		buf_sz = DMA_BUFFER_SIZE;
 	if (flow_ctrl > 1)
 		flow_ctrl = FLOW_AUTO;
 	else if (flow_ctrl < 0)
 		flow_ctrl = FLOW_OFF;
-
 	if ((pause < 0) || (pause > 0xffff))
 		pause = PAUSE_TIME;
 
-	if (tx_aggregation >= (dma_tx_size_param))
-		tx_aggregation = TX_AGGREGATION;
-
-	if (rx_irq_mitigation > (dma_rx_size_param))
-		rx_irq_mitigation = RX_IRQ_THRESHOLD;
-
 	return;
 }
 
@@ -237,6 +202,11 @@ static __inline__ void print_pkt(unsigned char *buf, int len)
 }
 #endif
 
+static inline u32 stmmac_tx_avail(struct stmmac_priv *priv)
+{
+	return (priv->dirty_tx + priv->dma_tx_size - priv->cur_tx - 1);
+}
+
 /**
  * stmmac_adjust_link
  * @dev: net device structure
@@ -244,65 +214,67 @@ static __inline__ void print_pkt(unsigned char *buf, int len)
  */
 static void stmmac_adjust_link(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-	struct phy_device *phydev = lp->phydev;
+	struct stmmac_priv *priv = netdev_priv(dev);
+	struct phy_device *phydev = priv->phydev;
 	unsigned long ioaddr = dev->base_addr;
 	unsigned long flags;
 	int new_state = 0;
-	unsigned int fc = lp->flow_ctrl, pause_time = lp->pause;
+	unsigned int fc = priv->flow_ctrl, pause_time = priv->pause;
 
-        if (phydev == NULL)
-           return;
+	if (phydev == NULL)
+		return;
 
 	DBG(probe, DEBUG, "stmmac_adjust_link: called.  address %d link %d\n",
 	    phydev->addr, phydev->link);
 
-	spin_lock_irqsave(&lp->lock, flags);
+	spin_lock_irqsave(&priv->lock, flags);
 	if (phydev->link) {
-		unsigned int ctrl = (unsigned int)readl(ioaddr + MAC_CTRL_REG);
+		u32 ctrl = readl(ioaddr + MAC_CTRL_REG);
 
 		/* Now we make sure that we can be in full duplex mode.
 		 * If not, we operate in half-duplex mode. */
-		if (phydev->duplex != lp->oldduplex) {
+		if (phydev->duplex != priv->oldduplex) {
 			new_state = 1;
 			if (!(phydev->duplex)) {
-				ctrl &= ~lp->mac_type->hw.link.duplex;
+				ctrl &= ~priv->mac_type->hw.link.duplex;
 			} else {
-				ctrl |= lp->mac_type->hw.link.duplex;
+				ctrl |= priv->mac_type->hw.link.duplex;
 			}
-			lp->oldduplex = phydev->duplex;
+			priv->oldduplex = phydev->duplex;
 		}
 		/* Flow Control operation */
 		if (phydev->pause)
-			lp->mac_type->ops->flow_ctrl(ioaddr, phydev->duplex,
-						     fc, pause_time);
+			priv->mac_type->ops->flow_ctrl(ioaddr, phydev->duplex,
+						       fc, pause_time);
 
-		if (phydev->speed != lp->speed) {
+		if (phydev->speed != priv->speed) {
 			new_state = 1;
 			switch (phydev->speed) {
 			case 1000:
-				if (likely(lp->is_gmac))
-					ctrl &= ~lp->mac_type->hw.link.port;
+				if (likely(priv->is_gmac))
+					ctrl &= ~priv->mac_type->hw.link.port;
 				break;
 			case 100:
 			case 10:
-				if (lp->is_gmac) {
-					ctrl |= lp->mac_type->hw.link.port;
+				if (priv->is_gmac) {
+					ctrl |= priv->mac_type->hw.link.port;
 					if (phydev->speed == SPEED_100) {
 						ctrl |=
-						    lp->mac_type->hw.link.speed;
+						    priv->mac_type->hw.link.
+						    speed;
 					} else {
 						ctrl &=
-						    ~(lp->mac_type->hw.link.
-						      speed);
+						    ~(priv->mac_type->hw.
+						      link.speed);
 					}
 				} else {
-					ctrl &= ~lp->mac_type->hw.link.port;
+					ctrl &= ~priv->mac_type->hw.link.port;
 				}
-				lp->fix_mac_speed(lp->bsp_priv, phydev->speed);
+				priv->fix_mac_speed(priv->bsp_priv,
+						    phydev->speed);
 				break;
 			default:
-				if (netif_msg_link(lp))
+				if (netif_msg_link(priv))
 					printk(KERN_WARNING
 					       "%s: Ack!  Speed (%d) is not 10"
 					       " or 100!\n", dev->name,
@@ -310,27 +282,27 @@ static void stmmac_adjust_link(struct net_device *dev)
 				break;
 			}
 
-			lp->speed = phydev->speed;
+			priv->speed = phydev->speed;
 		}
 
 		writel(ctrl, ioaddr + MAC_CTRL_REG);
 
-		if (!lp->oldlink) {
+		if (!priv->oldlink) {
 			new_state = 1;
-			lp->oldlink = 1;
+			priv->oldlink = 1;
 			netif_schedule(dev);
 		}
-	} else if (lp->oldlink) {
+	} else if (priv->oldlink) {
 		new_state = 1;
-		lp->oldlink = 0;
-		lp->speed = 0;
-		lp->oldduplex = -1;
+		priv->oldlink = 0;
+		priv->speed = 0;
+		priv->oldduplex = -1;
 	}
 
-	if (new_state && netif_msg_link(lp))
+	if (new_state && netif_msg_link(priv))
 		phy_print_status(phydev);
 
-	spin_unlock_irqrestore(&lp->lock, flags);
+	spin_unlock_irqrestore(&priv->lock, flags);
 
 	DBG(probe, DEBUG, "stmmac_adjust_link: exiting\n");
 }
@@ -344,24 +316,25 @@ static void stmmac_adjust_link(struct net_device *dev)
  */
 static int stmmac_init_phy(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	struct phy_device *phydev;
 	char phy_id[BUS_ID_SIZE];
 
-	lp->oldlink = 0;
-	lp->speed = 0;
-	lp->oldduplex = -1;
+	priv->oldlink = 0;
+	priv->speed = 0;
+	priv->oldduplex = -1;
 
-        if (lp->phy_addr == -1) {
-                /* We don't have a PHY, so do nothing */
-                return 0;
-        }
+	if (priv->phy_addr == -1) {
+		/* We don't have a PHY, so do nothing */
+		return 0;
+	}
 
-	snprintf(phy_id, BUS_ID_SIZE, PHY_ID_FMT, lp->bus_id, lp->phy_addr);
+	snprintf(phy_id, BUS_ID_SIZE, PHY_ID_FMT, priv->bus_id, priv->phy_addr);
 	DBG(probe, DEBUG, "stmmac_init_phy:  trying to attach to %s\n", phy_id);
 
 	phydev =
-	    phy_connect(dev, phy_id, &stmmac_adjust_link, 0, lp->phy_interface);
+	    phy_connect(dev, phy_id, &stmmac_adjust_link, 0,
+			priv->phy_interface);
 
 	if (IS_ERR(phydev)) {
 		printk(KERN_ERR "%s: Could not attach to PHY\n", dev->name);
@@ -372,7 +345,7 @@ static int stmmac_init_phy(struct net_device *dev)
 	    "stmmac_init_phy:  %s: attached to PHY. Link = %d\n",
 	    dev->name, phydev->link);
 
-	lp->phydev = phydev;
+	priv->phydev = phydev;
 
 	return 0;
 }
@@ -412,8 +385,8 @@ static void get_mac_address(unsigned long ioaddr, unsigned char *addr,
 	unsigned int hi_addr, lo_addr;
 
 	/* Read the MAC address from the hardware */
-	hi_addr = (unsigned int)readl(ioaddr + high);
-	lo_addr = (unsigned int)readl(ioaddr + low);
+	hi_addr = readl(ioaddr + high);
+	lo_addr = readl(ioaddr + low);
 
 	/* Extract the MAC address from the high and low words */
 	addr[0] = lo_addr & 0xff;
@@ -434,7 +407,7 @@ static void get_mac_address(unsigned long ioaddr, unsigned char *addr,
 static void stmmac_mac_enable_rx(struct net_device *dev)
 {
 	unsigned long ioaddr = dev->base_addr;
-	unsigned int value = (unsigned int)readl(ioaddr + MAC_CTRL_REG);
+	u32 value = readl(ioaddr + MAC_CTRL_REG);
 
 	/* set the RE (receive enable, bit 2) */
 	value |= MAC_RNABLE_RX;
@@ -450,7 +423,7 @@ static void stmmac_mac_enable_rx(struct net_device *dev)
 static void stmmac_mac_enable_tx(struct net_device *dev)
 {
 	unsigned long ioaddr = dev->base_addr;
-	unsigned int value = (unsigned int)readl(ioaddr + MAC_CTRL_REG);
+	u32 value = readl(ioaddr + MAC_CTRL_REG);
 
 	/* set: TE (transmitter enable, bit 3) */
 	value |= MAC_ENABLE_TX;
@@ -466,7 +439,7 @@ static void stmmac_mac_enable_tx(struct net_device *dev)
 static void stmmac_mac_disable_rx(struct net_device *dev)
 {
 	unsigned long ioaddr = dev->base_addr;
-	unsigned int value = (unsigned int)readl(ioaddr + MAC_CTRL_REG);
+	u32 value = readl(ioaddr + MAC_CTRL_REG);
 
 	value &= ~MAC_RNABLE_RX;
 	writel(value, ioaddr + MAC_CTRL_REG);
@@ -481,14 +454,14 @@ static void stmmac_mac_disable_rx(struct net_device *dev)
 static void stmmac_mac_disable_tx(struct net_device *dev)
 {
 	unsigned long ioaddr = dev->base_addr;
-	unsigned int value = (unsigned int)readl(ioaddr + MAC_CTRL_REG);
+	u32 value = readl(ioaddr + MAC_CTRL_REG);
 
 	value &= ~MAC_ENABLE_TX;
 	writel(value, ioaddr + MAC_CTRL_REG);
 	return;
 }
 
-static void display_ring(dma_desc * p, int size)
+static void display_ring(struct dma_desc *p, int size)
 {
 	struct tmp_s {
 		u64 a;
@@ -498,9 +471,10 @@ static void display_ring(dma_desc * p, int size)
 	int i;
 	for (i = 0; i < size; i++) {
 		struct tmp_s *x = (struct tmp_s *)(p + i);
-		printk("\t%d [0x%x]: des0=0x%x des1=0x%x buff=0x%x", i,
-		       (unsigned int)virt_to_phys(&p[i]), (unsigned int)(x->a),
-		       (unsigned int)((x->a) >> 32), x->b);
+		printk("\t%d [0x%x]: DES0=0x%x DES1=0x%x BUF1=0x%x BUF2=0x%x",
+		       i, (unsigned int)virt_to_phys(&p[i]),
+		       (unsigned int)(x->a), (unsigned int)((x->a) >> 32),
+		       x->b, x->c);
 		printk("\n");
 	}
 }
@@ -513,52 +487,68 @@ static void display_ring(dma_desc * p, int size)
 static void init_dma_desc_rings(struct net_device *dev)
 {
 	int i;
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	struct sk_buff *skb;
-	unsigned int txsize = lp->dma_tx_size;
-	unsigned int rxsize = lp->dma_rx_size;
-	int bfsize = lp->dma_buf_sz;
+	unsigned int txsize = priv->dma_tx_size;
+	unsigned int rxsize = priv->dma_rx_size;
+	unsigned int bfsize = priv->dma_buf_sz;
+	int buff2_needed = 0;
+
+	if (dev->mtu >= BUF_SIZE_8KiB) {
+		bfsize = BUF_SIZE_16KiB;
+	} else if (dev->mtu >= BUF_SIZE_4KiB) {
+		bfsize = BUF_SIZE_8KiB;
+	} else if (dev->mtu >= DMA_BUFFER_SIZE) {
+		bfsize = BUF_SIZE_4KiB;
+	} else {
+		bfsize = DMA_BUFFER_SIZE;
+	}
 
-	DBG(probe, INFO, "%s: allocate and init the DMA RX/TX\n"
-	    "(txsize %d, rxsize %d, bfsize %d)\n",
-	    ETH_RESOURCE_NAME, txsize, rxsize, bfsize);
+	/* If the MTU exceeds 8k so use the second buffer in the chain */
+	if (bfsize >= BUF_SIZE_8KiB)
+		buff2_needed = 1;
 
-	lp->rx_skbuff_dma =
+	DBG(probe, INFO, "stmmac: txsize %d, rxsize %d, bfsize %d\n",
+	    txsize, rxsize, bfsize);
+
+	priv->rx_skbuff_dma =
 	    (dma_addr_t *) kmalloc(rxsize * sizeof(dma_addr_t), GFP_KERNEL);
-	lp->rx_skbuff =
+	priv->rx_skbuff =
 	    (struct sk_buff **)kmalloc(sizeof(struct sk_buff *) * rxsize,
 				       GFP_KERNEL);
-	lp->dma_rx = (dma_desc *) dma_alloc_coherent(lp->device,
-						     rxsize *
-						     sizeof(struct dma_desc_t),
-						     &lp->dma_rx_phy,
-						     GFP_KERNEL);
-	lp->tx_skbuff =
+	priv->dma_rx = (struct dma_desc *)dma_alloc_coherent(priv->device,
+							     rxsize *
+							     sizeof(struct
+								    dma_desc),
+							     &priv->dma_rx_phy,
+							     GFP_KERNEL);
+	priv->tx_skbuff =
 	    (struct sk_buff **)kmalloc(sizeof(struct sk_buff *) * txsize,
 				       GFP_KERNEL);
-	lp->dma_tx = (dma_desc *) dma_alloc_coherent(lp->device,
-						     txsize *
-						     sizeof(struct dma_desc_t),
-						     &lp->dma_tx_phy,
-						     GFP_KERNEL);
-
-	if ((lp->dma_rx == NULL) || (lp->dma_tx == NULL)) {
+	priv->dma_tx =
+	    (struct dma_desc *)dma_alloc_coherent(priv->device,
+						  txsize *
+						  sizeof(struct dma_desc),
+						  &priv->dma_tx_phy,
+						  GFP_KERNEL);
+
+	if ((priv->dma_rx == NULL) || (priv->dma_tx == NULL)) {
 		printk(KERN_ERR "%s:ERROR allocating the DMA Tx/Rx desc\n",
 		       __FUNCTION__);
 		return;
 	}
 
-	DBG(probe, DEBUG, "%s: DMA desc rings: virt addr (Rx 0x%08x, "
-	    "Tx 0x%08x) DMA phy addr (Rx 0x%08x,Tx 0x%08x)\n",
-	    dev->name, (unsigned int)lp->dma_rx, (unsigned int)lp->dma_tx,
-	    (unsigned int)lp->dma_rx_phy, (unsigned int)lp->dma_tx_phy);
+	DBG(probe, DEBUG, "%s: DMA desc rings: virt addr (Rx %p, "
+	    "Tx %p)\n\tDMA phy addr (Rx 0x%08x, Tx 0x%08x)\n",
+	    dev->name, priv->dma_rx, priv->dma_tx,
+	    (unsigned int)priv->dma_rx_phy, (unsigned int)priv->dma_tx_phy);
 
 	/* ---- RX INITIALIZATION */
-	DBG(probe, DEBUG, "[RX skb data]   [DMA RX skb data] "
+	DBG(probe, DEBUG, "Rx preallocated skb:\n[skb]\t\t[skb data] "
 	    "(buff size: %d)\n", bfsize);
 
 	for (i = 0; i < rxsize; i++) {
-		dma_desc *p = lp->dma_rx + i;
+		struct dma_desc *p = priv->dma_rx + i;
 
 		skb = netdev_alloc_skb(dev, bfsize);
 		if (unlikely(skb == NULL)) {
@@ -568,33 +558,39 @@ static void init_dma_desc_rings(struct net_device *dev)
 		}
 		skb_reserve(skb, STMMAC_IP_ALIGN);
 
-		lp->rx_skbuff[i] = skb;
-		lp->rx_skbuff_dma[i] = dma_map_single(lp->device, skb->data,
-						      bfsize, DMA_FROM_DEVICE);
-		p->des2 = lp->rx_skbuff_dma[i];
-		DBG(probe, DEBUG, "[0x%08x]\t[0x%08x]\n",
-		    (unsigned int)lp->rx_skbuff[i],
-		    (unsigned int)lp->rx_skbuff[i]->data);
+		priv->rx_skbuff[i] = skb;
+		priv->rx_skbuff_dma[i] = dma_map_single(priv->device, skb->data,
+							bfsize,
+							DMA_FROM_DEVICE);
+		p->des2 = priv->rx_skbuff_dma[i];
+		if (unlikely(buff2_needed))
+			p->des3 = p->des2 + BUF_SIZE_8KiB;
+		DBG(probe, DEBUG, "[%p]\t[%p]\n",
+		    priv->rx_skbuff[i], priv->rx_skbuff[i]->data);
 	}
-	lp->cur_rx = 0;
-	lp->dirty_rx = (unsigned int)(i - rxsize);
+	priv->cur_rx = 0;
+	priv->dirty_rx = (unsigned int)(i - rxsize);
+	priv->dma_buf_sz = bfsize;
+	buf_sz = bfsize;
 
 	/* ---- TX INITIALIZATION */
 	for (i = 0; i < txsize; i++) {
-		lp->tx_skbuff[i] = NULL;
-		lp->dma_tx[i].des2 = 0;
+		priv->tx_skbuff[i] = NULL;
+		priv->dma_tx[i].des2 = 0;
 	}
-	lp->dirty_tx = lp->cur_tx = 0;
+	priv->dirty_tx = 0;
+	priv->cur_tx = 0;
 
 	/* Clear the Rx/Tx descriptors */
-	lp->mac_type->ops->init_rx_desc(lp->dma_rx, rxsize, rx_irq_mitigation);
-	lp->mac_type->ops->init_tx_desc(lp->dma_tx, txsize);
+	priv->mac_type->ops->init_rx_desc(priv->dma_rx, rxsize);
+	priv->mac_type->ops->disable_rx_ic(priv->dma_rx, rxsize, rx_coalesce);
+	priv->mac_type->ops->init_tx_desc(priv->dma_tx, txsize);
 
-	if (netif_msg_hw(lp)) {
+	if (netif_msg_hw(priv)) {
 		printk("RX descriptor ring:\n");
-		display_ring(lp->dma_rx, rxsize);
+		display_ring(priv->dma_rx, rxsize);
 		printk("TX descriptor ring:\n");
-		display_ring(lp->dma_tx, txsize);
+		display_ring(priv->dma_tx, txsize);
 	}
 	return;
 }
@@ -606,16 +602,16 @@ static void init_dma_desc_rings(struct net_device *dev)
  */
 static void dma_free_rx_skbufs(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	int i;
 
-	for (i = 0; i < lp->dma_rx_size; i++) {
-		if (lp->rx_skbuff[i]) {
-			dma_unmap_single(lp->device, lp->rx_skbuff_dma[i],
-					 lp->dma_buf_sz, DMA_FROM_DEVICE);
-			dev_kfree_skb(lp->rx_skbuff[i]);
+	for (i = 0; i < priv->dma_rx_size; i++) {
+		if (priv->rx_skbuff[i]) {
+			dma_unmap_single(priv->device, priv->rx_skbuff_dma[i],
+					 priv->dma_buf_sz, DMA_FROM_DEVICE);
+			dev_kfree_skb(priv->rx_skbuff[i]);
 		}
-		lp->rx_skbuff[i] = NULL;
+		priv->rx_skbuff[i] = NULL;
 	}
 	return;
 }
@@ -627,19 +623,18 @@ static void dma_free_rx_skbufs(struct net_device *dev)
  */
 static void dma_free_tx_skbufs(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	int i;
 
-	for (i = 0; i < lp->dma_tx_size; i++) {
-		if (lp->tx_skbuff[i] != NULL) {
-			if ((lp->dma_tx + i)->des2) {
-				dma_unmap_single(lp->device, p->des2,
-						 lp->mac_type->
-						 ops->get_tx_len(p),
-						 DMA_TO_DEVICE);
-			}
-			dev_kfree_skb_any(lp->tx_skbuff[i]);
-			lp->tx_skbuff[i] = NULL;
+	for (i = 0; i < priv->dma_tx_size; i++) {
+		if (priv->tx_skbuff[i] != NULL) {
+			if ((priv->dma_tx + i)->des2)
+				dma_unmap_single(priv->device,
+						 (priv->dma_tx + i)->des2,
+						 priv->mac_type->ops->
+						 get_tx_len(p), DMA_TO_DEVICE);
+			dev_kfree_skb_any(priv->tx_skbuff[i]);
+			priv->tx_skbuff[i] = NULL;
 		}
 	}
 	return;
@@ -652,7 +647,7 @@ static void dma_free_tx_skbufs(struct net_device *dev)
  */
 static void free_dma_desc_resources(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
 	/* Release the DMA TX/RX socket buffers */
 	dma_free_rx_skbufs(dev);
@@ -660,15 +655,15 @@ static void free_dma_desc_resources(struct net_device *dev)
 
 	/* Free the region of consistent memory previously allocated for 
 	 * the DMA */
-	dma_free_coherent(lp->device,
-			  lp->dma_tx_size * sizeof(struct dma_desc_t),
-			  lp->dma_tx, lp->dma_tx_phy);
-	dma_free_coherent(lp->device,
-			  lp->dma_rx_size * sizeof(struct dma_desc_t),
-			  lp->dma_rx, lp->dma_rx_phy);
-	kfree(lp->rx_skbuff_dma);
-	kfree(lp->rx_skbuff);
-	kfree(lp->tx_skbuff);
+	dma_free_coherent(priv->device,
+			  priv->dma_tx_size * sizeof(struct dma_desc),
+			  priv->dma_tx, priv->dma_tx_phy);
+	dma_free_coherent(priv->device,
+			  priv->dma_rx_size * sizeof(struct dma_desc),
+			  priv->dma_rx, priv->dma_rx_phy);
+	kfree(priv->rx_skbuff_dma);
+	kfree(priv->rx_skbuff);
+	kfree(priv->tx_skbuff);
 
 	return;
 }
@@ -680,8 +675,7 @@ static void free_dma_desc_resources(struct net_device *dev)
  */
 static void stmmac_dma_start_tx(unsigned long ioaddr)
 {
-	unsigned int value;
-	value = (unsigned int)readl(ioaddr + DMA_CONTROL);
+	u32 value = readl(ioaddr + DMA_CONTROL);
 	value |= DMA_CONTROL_ST;
 	writel(value, ioaddr + DMA_CONTROL);
 	return;
@@ -689,8 +683,7 @@ static void stmmac_dma_start_tx(unsigned long ioaddr)
 
 static void stmmac_dma_stop_tx(unsigned long ioaddr)
 {
-	unsigned int value;
-	value = (unsigned int)readl(ioaddr + DMA_CONTROL);
+	u32 value = readl(ioaddr + DMA_CONTROL);
 	value &= ~DMA_CONTROL_ST;
 	writel(value, ioaddr + DMA_CONTROL);
 	return;
@@ -703,8 +696,7 @@ static void stmmac_dma_stop_tx(unsigned long ioaddr)
  */
 static void stmmac_dma_start_rx(unsigned long ioaddr)
 {
-	unsigned int value;
-	value = (unsigned int)readl(ioaddr + DMA_CONTROL);
+	u32 value = readl(ioaddr + DMA_CONTROL);
 	value |= DMA_CONTROL_SR;
 	writel(value, ioaddr + DMA_CONTROL);
 
@@ -713,15 +705,48 @@ static void stmmac_dma_start_rx(unsigned long ioaddr)
 
 static void stmmac_dma_stop_rx(unsigned long ioaddr)
 {
-	unsigned int value;
-
-	value = (unsigned int)readl(ioaddr + DMA_CONTROL);
+	u32 value = readl(ioaddr + DMA_CONTROL);
 	value &= ~DMA_CONTROL_SR;
 	writel(value, ioaddr + DMA_CONTROL);
 
 	return;
 }
 
+/**
+ *  stmmac_dma_operation_mode - HW DMA operation mode
+ *  @dev : pointer to the device structure.
+ *  Description:
+ *  This function sets the DMA operation mode: tx/rx DMA thresholds
+ *  or Store-And-Forward capability. It also verifies the COE for the
+ *  transmission in case of Giga ETH.
+ */
+static void stmmac_dma_operation_mode(struct net_device *dev)
+{
+	struct stmmac_priv *priv = netdev_priv(dev);
+
+	if (!priv->is_gmac) {
+		/* MAC 10/100 */
+		priv->mac_type->ops->dma_mode(dev->base_addr,
+					      priv->xstats.threshold, 0);
+		priv->tx_coe = NO_HW_CSUM;
+	} else {
+		if ((dev->mtu <= ETH_DATA_LEN) && (tx_coe)) {
+			priv->mac_type->ops->dma_mode(dev->base_addr,
+						      SF_DMA_MODE, SF_DMA_MODE);
+			priv->tx_coe = HW_CSUM;
+		} else {
+			/* Checksum computation is performed in software. */
+			priv->mac_type->ops->dma_mode(dev->base_addr,
+						      priv->xstats.threshold,
+						      SF_DMA_MODE);
+			priv->tx_coe = NO_HW_CSUM;
+		}
+	}
+	tx_coe = priv->tx_coe;
+
+	return;
+}
+
 static __inline__ void stmmac_dma_enable_irq_rx(unsigned long ioaddr)
 {
 	writel(DMA_INTR_DEFAULT_MASK, ioaddr + DMA_INTR_ENA);
@@ -823,52 +848,56 @@ static void show_rx_process_state(unsigned int status)
  */
 static void stmmac_tx(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-	unsigned int txsize = lp->dma_tx_size;
+	struct stmmac_priv *priv = netdev_priv(dev);
+	unsigned int txsize = priv->dma_tx_size;
 	unsigned long ioaddr = dev->base_addr;
-	int entry = lp->dirty_tx % txsize;
+	unsigned int entry = priv->dirty_tx % txsize;
 
-	spin_lock(&lp->tx_lock);
-	while (lp->dirty_tx != lp->cur_tx) {
+	spin_lock(&priv->tx_lock);
+	while (priv->dirty_tx != priv->cur_tx) {
 		int last;
-		dma_desc *p = lp->dma_tx + entry;
+		struct dma_desc *p = priv->dma_tx + entry;
 
-		if (lp->mac_type->ops->read_tx_owner(p))
+		if (priv->mac_type->ops->get_tx_owner(p))
 			break;
 		/* verify tx error by looking at the last segment */
-		last = lp->mac_type->ops->get_tx_ls(p);
+		last = priv->mac_type->ops->get_tx_ls(p);
 		if (likely(last)) {
-			int tx_error = lp->mac_type->ops->tx_status(&dev->stats,
-								    &lp->xstats,
-								    p, ioaddr);
+			int tx_error =
+			    priv->mac_type->ops->tx_status(&dev->stats,
+							   &priv->xstats,
+							   p, ioaddr);
 			if (likely(tx_error == 0)) {
 				dev->stats.tx_packets++;
 			} else {
 				dev->stats.tx_errors++;
 			}
 		}
-		DBG(intr, DEBUG, "stmmac_tx: curr %d, dirty %d\n", lp->cur_tx,
-		    lp->dirty_tx);
+		DBG(intr, DEBUG, "stmmac_tx: curr %d, dirty %d\n",
+		    priv->cur_tx, priv->dirty_tx);
 
 		if (likely(p->des2)) {
-			dma_unmap_single(lp->device, p->des2,
-					 lp->mac_type->ops->get_tx_len(p),
+			dma_unmap_single(priv->device, p->des2,
+					 priv->mac_type->ops->get_tx_len(p),
 					 DMA_TO_DEVICE);
 		}
-		if (likely(lp->tx_skbuff[entry] != NULL)) {
-			dev_kfree_skb_irq(lp->tx_skbuff[entry]);
-			lp->tx_skbuff[entry] = NULL;
+		if (unlikely(p->des3))
+			p->des3 = 0;
+
+		if (likely(priv->tx_skbuff[entry] != NULL)) {
+			dev_kfree_skb_irq(priv->tx_skbuff[entry]);
+			priv->tx_skbuff[entry] = NULL;
 		}
 
-		lp->mac_type->ops->release_tx_desc(p);
+		priv->mac_type->ops->release_tx_desc(p);
 
-		entry = (++lp->dirty_tx) % txsize;
+		entry = (++priv->dirty_tx) % txsize;
 	}
 	if (unlikely(netif_queue_stopped(dev) &&
-		     TX_BUFFS_AVAIL(lp) > (MAX_SKB_FRAGS + 1)))
+		     stmmac_tx_avail(priv) > (MAX_SKB_FRAGS + 1)))
 		netif_wake_queue(dev);
 
-	spin_unlock(&lp->tx_lock);
+	spin_unlock(&priv->tx_lock);
 	return;
 }
 
@@ -877,7 +906,7 @@ static void stmmac_tx(struct net_device *dev)
  * @dev: net device structure
  * Description: it schedules the reception process.
  */
-void stmmac_schedule_rx(struct net_device *dev)
+static void stmmac_schedule_rx(struct net_device *dev)
 {
 	stmmac_dma_disable_irq_rx(dev->base_addr);
 
@@ -891,23 +920,50 @@ void stmmac_schedule_rx(struct net_device *dev)
 static void stmmac_tx_tasklet(unsigned long data)
 {
 	struct net_device *dev = (struct net_device *)data;
+	struct stmmac_priv *priv = netdev_priv(dev);
 
+	priv->xstats.tx_task_n++;
 	stmmac_tx(dev);
 
+#ifdef CONFIG_STMMAC_TIMER
+	priv->tm->timer_start(tmrate);
+#endif
 	return;
 }
 
 #ifdef CONFIG_STMMAC_TIMER
 void stmmac_timer_work(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
+
+	unsigned int rxentry = priv->cur_rx % priv->dma_rx_size;
+	unsigned int txentry = priv->dirty_tx % priv->dma_tx_size;
+	int rxret, txret;
+
+	/* Look at if there is pending work to do; otherwise, do not spend
+	   any other time here. */
+	rxret = priv->mac_type->ops->get_rx_owner(priv->dma_rx + rxentry);
+	if (likely(rxret == 0))
+		stmmac_schedule_rx(dev);
 
-	stmmac_schedule_rx(dev);
+	txret = priv->mac_type->ops->get_tx_owner(priv->dma_rx + txentry);
+	if (likely(txret == 0))
+		tasklet_schedule(&priv->tx_task);
 
-	tasklet_schedule(&lp->tx_task);
+	/* Timer will be re-started later. */
+	if (likely(rxret == 0) || (rxret == 0))
+		priv->tm->timer_stop();
 
 	return;
 }
+
+static void stmmac_no_timer_started(unsigned int x)
+{;
+};
+
+static void stmmac_no_timer_stopped(void)
+{;
+};
 #endif
 
 /**
@@ -915,24 +971,25 @@ void stmmac_timer_work(struct net_device *dev)
  * @dev: net device structure
  * Description: clean descriptors and restart the transmission.
  */
-static __inline__ void stmmac_tx_err(struct net_device *dev)
+static void stmmac_tx_err(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
-	spin_lock(&lp->tx_lock);
+	spin_lock(&priv->tx_lock);
 
 	netif_stop_queue(dev);
 
 	stmmac_dma_stop_tx(dev->base_addr);
 	dma_free_tx_skbufs(dev);
-	lp->mac_type->ops->init_tx_desc(lp->dma_tx, lp->dma_tx_size);
-	lp->dirty_tx = lp->cur_tx = 0;
+	priv->mac_type->ops->init_tx_desc(priv->dma_tx, priv->dma_tx_size);
+	priv->dirty_tx = 0;
+	priv->cur_tx = 0;
 	stmmac_dma_start_tx(dev->base_addr);
 
 	dev->stats.tx_errors++;
 	netif_wake_queue(dev);
 
-	spin_unlock(&lp->tx_lock);
+	spin_unlock(&priv->tx_lock);
 	return;
 }
 
@@ -944,20 +1001,18 @@ static __inline__ void stmmac_tx_err(struct net_device *dev)
  */
 static void stmmac_dma_interrupt(struct net_device *dev)
 {
-	unsigned int intr_status;
 	unsigned long ioaddr = dev->base_addr;
-	struct eth_driver_local *lp = netdev_priv(dev);
-
+	struct stmmac_priv *priv = netdev_priv(dev);
 	/* read the status register (CSR5) */
-	intr_status = (unsigned int)readl(ioaddr + DMA_STATUS);
+	u32 intr_status = readl(ioaddr + DMA_STATUS);
 
 	DBG(intr, INFO, "%s: [CSR5: 0x%08x]\n", __FUNCTION__, intr_status);
 
 #ifdef STMMAC_DEBUG
 	/* It displays the DMA transmit process state (CSR5 register) */
-	if (netif_msg_tx_done(lp))
+	if (netif_msg_tx_done(priv))
 		show_tx_process_state(intr_status);
-	if (netif_msg_rx_status(lp))
+	if (netif_msg_rx_status(priv))
 		show_rx_process_state(intr_status);
 #endif
 	/* Clear the interrupt by writing a logic 1 to the CSR5[15-0] */
@@ -968,41 +1023,50 @@ static void stmmac_dma_interrupt(struct net_device *dev)
 		DBG(intr, INFO, "CSR5[15] DMA ABNORMAL IRQ: ");
 		if (unlikely(intr_status & DMA_STATUS_UNF)) {
 			DBG(intr, INFO, "transmit underflow\n");
+			if ((priv->xstats.threshold != SF_DMA_MODE)
+			    && (priv->xstats.threshold <= 256)) {
+				/* Try to bump up the threshold */
+				priv->xstats.threshold += 64;
+				priv->mac_type->ops->dma_mode(ioaddr,
+							      priv->
+							      xstats.threshold,
+							      SF_DMA_MODE);
+			}
 			stmmac_tx_err(dev);
-			lp->xstats.tx_undeflow_irq++;
+			priv->xstats.tx_undeflow_irq++;
 		}
 		if (unlikely(intr_status & DMA_STATUS_TJT)) {
 			DBG(intr, INFO, "transmit jabber\n");
-			lp->xstats.tx_jabber_irq++;
+			priv->xstats.tx_jabber_irq++;
 		}
 		if (unlikely(intr_status & DMA_STATUS_OVF)) {
 			DBG(intr, INFO, "recv overflow\n");
-			lp->xstats.rx_overflow_irq++;
+			priv->xstats.rx_overflow_irq++;
 		}
 		if (unlikely(intr_status & DMA_STATUS_RU)) {
 			DBG(intr, INFO, "receive buffer unavailable\n");
-			lp->xstats.rx_buf_unav_irq++;
+			priv->xstats.rx_buf_unav_irq++;
 		}
 		if (unlikely(intr_status & DMA_STATUS_RPS)) {
 			DBG(intr, INFO, "receive process stopped\n");
-			lp->xstats.rx_process_stopped_irq++;
+			priv->xstats.rx_process_stopped_irq++;
 		}
 		if (unlikely(intr_status & DMA_STATUS_RWT)) {
 			DBG(intr, INFO, "receive watchdog\n");
-			lp->xstats.rx_watchdog_irq++;
+			priv->xstats.rx_watchdog_irq++;
 		}
 		if (unlikely(intr_status & DMA_STATUS_ETI)) {
 			DBG(intr, INFO, "transmit early interrupt\n");
-			lp->xstats.tx_early_irq++;
+			priv->xstats.tx_early_irq++;
 		}
 		if (unlikely(intr_status & DMA_STATUS_TPS)) {
 			DBG(intr, INFO, "transmit process stopped\n");
-			lp->xstats.tx_process_stopped_irq++;
+			priv->xstats.tx_process_stopped_irq++;
 			stmmac_tx_err(dev);
 		}
 		if (unlikely(intr_status & DMA_STATUS_FBI)) {
 			DBG(intr, INFO, "fatal bus error\n");
-			lp->xstats.fatal_bus_error_irq++;
+			priv->xstats.fatal_bus_error_irq++;
 			stmmac_tx_err(dev);
 		}
 	}
@@ -1014,14 +1078,14 @@ static void stmmac_dma_interrupt(struct net_device *dev)
 
 			RX_DBG("Receive irq [buf: 0x%08x]\n",
 			       readl(ioaddr + DMA_CUR_RX_BUF_ADDR));
-			lp->xstats.rx_irq_n++;
+			priv->xstats.rx_irq_n++;
 			stmmac_schedule_rx(dev);
 		}
-		if (unlikely(intr_status & (DMA_STATUS_TI))) {
+		if (intr_status & (DMA_STATUS_TI)) {
 			DBG(intr, INFO, " Transmit irq [buf: 0x%08x]\n",
 			    readl(ioaddr + DMA_CUR_TX_BUF_ADDR));
-			lp->xstats.tx_irq_n++;
-			tasklet_schedule(&lp->tx_task);
+			priv->xstats.tx_irq_n++;
+			tasklet_schedule(&priv->tx_task);
 		}
 	}
 
@@ -1048,7 +1112,7 @@ static void stmmac_dma_interrupt(struct net_device *dev)
  */
 static int stmmac_open(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	unsigned long ioaddr = dev->base_addr;
 	int ret;
 
@@ -1061,6 +1125,8 @@ static int stmmac_open(struct net_device *dev)
 		return -EINVAL;
 	}
 
+	stmmac_verify_args();
+
 	/* Attach the PHY */
 	ret = stmmac_init_phy(dev);
 	if (ret) {
@@ -1079,32 +1145,48 @@ static int stmmac_open(struct net_device *dev)
 		return ret;
 	}
 #ifdef CONFIG_STMMAC_TIMER
-	lp->has_timer = stmmac_timer_open(dev, periodic_rate);
-	if (unlikely(lp->has_timer < 0)) {
-		printk(KERN_WARNING "stmmac: timer opt disabled\n");
-		rx_irq_mitigation = 1;
+	priv->tm = kmalloc(sizeof(struct stmmac_timer *), GFP_KERNEL);
+	if (priv->tm == NULL) {
+		printk(KERN_ERR "%s: ERROR: timer memory alloc failed \n",
+		       __FUNCTION__);
+		return -ENOMEM;
+	}
+	priv->tm->freq = tmrate;
+
+	/* Test if the HW timer can be actually used.
+	 * In case of failure go haead without using any timers. */
+	if (unlikely((stmmac_open_hw_timer(dev, priv->tm)) < 0)) {
+		printk(KERN_WARNING "stmmaceth: cannot attach the HW timer\n");
+		rx_coalesce = 1;
+		tmrate = 0;
+		priv->tm->freq = 0;
+		priv->tm->timer_start = stmmac_no_timer_started;
+		priv->tm->timer_stop = stmmac_no_timer_stopped;
 	}
 #endif
 
-	/* Create and initialize the TX/RX descriptors rings */
+	/* Create and initialize the TX/RX descriptors chains */
+	priv->dma_tx_size = STMMAC_ALIGN(dma_txsize);
+	priv->dma_rx_size = STMMAC_ALIGN(dma_rxsize);
+	priv->dma_buf_sz = STMMAC_ALIGN(buf_sz);
 	init_dma_desc_rings(dev);
 
 	/* DMA initialization and SW reset */
-	if (lp->mac_type->ops->dma_init(ioaddr, lp->pbl, lp->dma_tx_phy,
-					lp->dma_rx_phy) < 0) {
+	if (priv->mac_type->ops->dma_init(ioaddr, priv->pbl, priv->dma_tx_phy,
+					  priv->dma_rx_phy) < 0) {
 		printk(KERN_ERR "%s: DMA initialization failed\n",
 		       __FUNCTION__);
 		return -1;
 	}
 
 	/* Copy the MAC addr into the HW (in case we have set it with nwhw) */
-	set_mac_addr(ioaddr, dev->dev_addr, lp->mac_type->hw.addr_high,
-		     lp->mac_type->hw.addr_low);
+	set_mac_addr(ioaddr, dev->dev_addr, priv->mac_type->hw.addr_high,
+		     priv->mac_type->hw.addr_low);
 
 	/* Initialize the MAC Core */
-	lp->mac_type->ops->core_init(ioaddr);
-	lp->tx_aggregation = 0;
-	lp->shutdown = 0;
+	priv->mac_type->ops->core_init(ioaddr);
+	priv->tx_coalesce = 0;
+	priv->shutdown = 0;
 
 	/* Initialise the MMC (if present) to disable all interrupts */
 	writel(0xffffffff, ioaddr + MMC_HIGH_INTR_MASK);
@@ -1115,11 +1197,11 @@ static int stmmac_open(struct net_device *dev)
 	stmmac_mac_enable_tx(dev);
 
 	/* Extra statistics */
-	memset(&lp->xstats, 0, sizeof(struct stmmac_extra_stats));
-	lp->xstats.threshold = threshold_ctrl;
+	memset(&priv->xstats, 0, sizeof(struct stmmac_extra_stats));
+	priv->xstats.threshold = tc;
 
-	/* Estabish the tx/rx operating modes and commands */
-	lp->mac_type->ops->dma_operation_mode(ioaddr, threshold_ctrl);
+	/* Set the HW DMA mode and the COE */
+	stmmac_dma_operation_mode(dev);
 
 	/* Start the ball rolling... */
 	DBG(probe, DEBUG, "%s: DMA RX/TX processes started...\n",
@@ -1128,19 +1210,18 @@ static int stmmac_open(struct net_device *dev)
 	stmmac_dma_start_rx(ioaddr);
 
 #ifdef CONFIG_STMMAC_TIMER
-	if (likely(lp->has_timer == 0))
-		stmmac_timer_start(periodic_rate);
+	priv->tm->timer_start(tmrate);
 #endif
-	tasklet_init(&lp->tx_task, stmmac_tx_tasklet, (unsigned long)dev);
+	tasklet_init(&priv->tx_task, stmmac_tx_tasklet, (unsigned long)dev);
 
 	/* Dump DMA/MAC registers */
-	if (netif_msg_hw(lp)) {
-		lp->mac_type->ops->dump_mac_regs(ioaddr);
-		lp->mac_type->ops->dump_dma_regs(ioaddr);
+	if (netif_msg_hw(priv)) {
+		priv->mac_type->ops->dump_mac_regs(ioaddr);
+		priv->mac_type->ops->dump_dma_regs(ioaddr);
 	}
 
-        if (lp->phydev)
-	   phy_start(lp->phydev);
+	if (priv->phydev)
+		phy_start(priv->phydev);
 
 	netif_start_queue(dev);
 	return 0;
@@ -1154,21 +1235,21 @@ static int stmmac_open(struct net_device *dev)
  */
 static int stmmac_release(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
 	/* Stop and disconnect the PHY */
-	phy_stop(lp->phydev);
-	phy_disconnect(lp->phydev);
-	lp->phydev = NULL;
+	phy_stop(priv->phydev);
+	phy_disconnect(priv->phydev);
+	priv->phydev = NULL;
 
 	netif_stop_queue(dev);
-	tasklet_kill(&lp->tx_task);
+	tasklet_kill(&priv->tx_task);
 
 #ifdef CONFIG_STMMAC_TIMER
-	if (likely(lp->has_timer == 0)) {
-		stmmac_timer_stop();
-		stmmac_timer_close();
-	}
+	/* Stop and release the timer */
+	stmmac_close_hw_timer();
+	if (priv->tm != NULL)
+		kfree(priv->tm);
 #endif
 
 	/* Free the IRQ lines */
@@ -1190,6 +1271,47 @@ static int stmmac_release(struct net_device *dev)
 	return 0;
 }
 
+static unsigned int stmmac_handle_jumbo_frames(struct sk_buff *skb,
+					       struct net_device *dev,
+					       int csum_insertion)
+{
+	struct stmmac_priv *priv = netdev_priv(dev);
+	unsigned int nopaged_len = skb_headlen(skb);
+	unsigned int txsize = priv->dma_tx_size;
+	unsigned int entry = priv->cur_tx % txsize;
+	struct dma_desc *desc = priv->dma_tx + entry;
+
+	if (nopaged_len > BUF_SIZE_8KiB) {
+
+		int buf2_size = nopaged_len - BUF_SIZE_8KiB;
+
+		desc->des2 = dma_map_single(priv->device, skb->data,
+					    BUF_SIZE_8KiB, DMA_TO_DEVICE);
+		desc->des3 = desc->des2 + BUF_SIZE_4KiB;
+		priv->mac_type->ops->prepare_tx_desc(desc, 1, BUF_SIZE_8KiB,
+						     csum_insertion);
+
+		entry = (++priv->cur_tx) % txsize;
+		desc = priv->dma_tx + entry;
+
+		desc->des2 = dma_map_single(priv->device,
+					    skb->data + BUF_SIZE_8KiB,
+					    buf2_size, DMA_TO_DEVICE);
+		desc->des3 = desc->des2 + BUF_SIZE_4KiB;
+		priv->mac_type->ops->prepare_tx_desc(desc, 0,
+						     buf2_size, csum_insertion);
+		priv->mac_type->ops->set_tx_owner(desc);
+		priv->tx_skbuff[entry] = NULL;
+	} else {
+		desc->des2 = dma_map_single(priv->device, skb->data,
+					    nopaged_len, DMA_TO_DEVICE);
+		desc->des3 = desc->des2 + BUF_SIZE_4KiB;
+		priv->mac_type->ops->prepare_tx_desc(desc, 1, nopaged_len,
+						     csum_insertion);
+	}
+	return entry;
+}
+
 /**
  *  stmmac_xmit:
  *  @skb : the socket buffer
@@ -1198,24 +1320,24 @@ static int stmmac_release(struct net_device *dev)
  */
 static int stmmac_xmit(struct sk_buff *skb, struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	unsigned long flags;
-	unsigned int txsize = lp->dma_tx_size, hwcsum,
-	    nfrags = skb_shinfo(skb)->nr_frags,
-	    entry = lp->cur_tx % txsize, i, nopaged_len, first = entry;
-	dma_desc *p = lp->dma_tx;
+	unsigned int txsize = priv->dma_tx_size;
+	unsigned int entry;
+	int i, csum_insertion = 0, nfrags = skb_shinfo(skb)->nr_frags;
+	struct dma_desc *desc, *first;
+
+	entry = priv->cur_tx % txsize;
 
 	/* This is a hard error log it. */
-	if (unlikely(TX_BUFFS_AVAIL(lp) < nfrags + 1)) {
+	if (unlikely(stmmac_tx_avail(priv) < nfrags + 1)) {
 		netif_stop_queue(dev);
 		printk(KERN_ERR "%s: BUG! Tx Ring full when queue awake\n",
 		       dev->name);
 		return NETDEV_TX_BUSY;
 	}
 
-	spin_lock_irqsave(&lp->tx_lock, flags);
-
-	if (unlikely((lp->tx_skbuff[entry] != NULL))) {
+	if (unlikely((priv->tx_skbuff[entry] != NULL))) {
 		printk(KERN_ERR "%s: BUG! Inconsistent Tx skb utilization\n",
 		       dev->name);
 		dev_kfree_skb_any(skb);
@@ -1223,104 +1345,107 @@ static int stmmac_xmit(struct sk_buff *skb, struct net_device *dev)
 		return -1;
 	}
 
-	hwcsum = 0;
-	if (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {
-		if (lp->mac_type->hw.csum == NO_HW_CSUM)
+	spin_lock_irqsave(&priv->tx_lock, flags);
+
+	if (likely((skb->ip_summed == CHECKSUM_PARTIAL))) {
+		if (likely(priv->tx_coe == NO_HW_CSUM))
 			skb_checksum_help(skb);
 		else
-			hwcsum = 1;
+			csum_insertion = 1;
 	}
 
-	/* Get the amount of non-paged data (skb->data). */
-	nopaged_len = skb_headlen(skb);
+	desc = priv->dma_tx + entry;
+	first = desc;
 
 #ifdef STMMAC_XMIT_DEBUG
-	if (nfrags > 0) {
-		printk("stmmac xmit: len: %d, nopaged_len: %d n_frags: %d\n",
-		       skb->len, nopaged_len, nfrags);
-	}
+	if ((nfrags > 0) || (skb->len > ETH_FRAME_LEN))
+		printk(KERN_DEBUG "stmmac xmit: skb len: %d, nopaged_len: %d,\n"
+		       "\t\tn_frags: %d, ip_summed: %d\n",
+		       skb->len, skb_headlen(skb), nfrags, skb->ip_summed);
 #endif
+	priv->tx_skbuff[entry] = skb;
+	if (unlikely(skb->len >= BUF_SIZE_4KiB)) {
+		entry = stmmac_handle_jumbo_frames(skb, dev, csum_insertion);
+		desc = priv->dma_tx + entry;
+	} else {
+		unsigned int nopaged_len = skb_headlen(skb);
+		desc->des2 = dma_map_single(priv->device, skb->data,
+					    nopaged_len, DMA_TO_DEVICE);
+		priv->mac_type->ops->prepare_tx_desc(desc, 1, nopaged_len,
+						     csum_insertion);
+	}
 
-	/* Handle non-paged data (skb->data) */
-	p[entry].des2 = dma_map_single(lp->device, skb->data,
-				       nopaged_len, DMA_TO_DEVICE);
-	lp->tx_skbuff[entry] = skb;
-	lp->mac_type->ops->prepare_tx_desc((p + entry), 1, nopaged_len, hwcsum);
-
-	/* Handle paged fragments */
 	for (i = 0; i < nfrags; i++) {
 		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
 		int len = frag->size;
 
-		lp->cur_tx++;
-		entry = lp->cur_tx % txsize;
+		entry = (++priv->cur_tx) % txsize;
+		desc = priv->dma_tx + entry;
 
 #ifdef STMMAC_XMIT_DEBUG
 		printk("\t[entry %d] segment len: %d\n", entry, len);
 #endif
-		p[entry].des2 = dma_map_page(lp->device, frag->page,
-					     frag->page_offset,
-					     len, DMA_TO_DEVICE);
-		lp->tx_skbuff[entry] = NULL;
-		lp->mac_type->ops->prepare_tx_desc((p + entry), 0, len, hwcsum);
-		lp->mac_type->ops->set_tx_owner(p + entry);
+		desc->des2 = dma_map_page(priv->device, frag->page,
+					  frag->page_offset,
+					  len, DMA_TO_DEVICE);
+		priv->tx_skbuff[entry] = NULL;
+		priv->mac_type->ops->prepare_tx_desc(desc, 0, len,
+						     csum_insertion);
+		priv->mac_type->ops->set_tx_owner(desc);
 	}
 
-	/* If there are more than one fragment, we set the interrupt
-	 * on completition bit in the latest segment. */
-	lp->mac_type->ops->set_tx_owner(p + first);	/* to avoid raise condition */
-	lp->mac_type->ops->set_tx_ls(p + entry);
-
-	lp->mac_type->ops->set_tx_ic(p + entry, 1);
+	/* Interrupt on completition only for the latest segment */
+	priv->mac_type->ops->close_tx_desc(desc);
+	/* to avoid raise condition */
+	priv->mac_type->ops->set_tx_owner(first);
 
-	lp->cur_tx++;
+	priv->cur_tx++;
 
 #ifdef STMMAC_XMIT_DEBUG
-	if (netif_msg_pktdata(lp)) {
+	if (netif_msg_pktdata(priv)) {
 		printk("stmmac xmit: current=%d, dirty=%d, entry=%d, "
-		       "first=%d, nfrags=%d\n",
-		       (lp->cur_tx % txsize), (lp->dirty_tx % txsize), entry,
-		       first, nfrags);
-		display_ring(lp->dma_tx, txsize);
+		       "first=%p, nfrags=%d\n",
+		       (priv->cur_tx % txsize), (priv->dirty_tx % txsize),
+		       entry, first, nfrags);
+		display_ring(priv->dma_tx, txsize);
 		printk(">>> frame to be transmitted: ");
 		print_pkt(skb->data, skb->len);
 	}
 #endif
-	if (TX_BUFFS_AVAIL(lp) <= (MAX_SKB_FRAGS + 1) ||
-	    (!(lp->mac_type->hw.link.duplex) && hwcsum)) {
+	if (stmmac_tx_avail(priv) <= (MAX_SKB_FRAGS + 1) ||
+	    (!(priv->mac_type->hw.link.duplex) && csum_insertion)) {
 		netif_stop_queue(dev);
 	} else {
-		/* Aggregation of Tx interrupts */
-		if (lp->tx_aggregation <= tx_aggregation) {
-			lp->tx_aggregation++;
-			lp->mac_type->ops->set_tx_ic(p + entry, 0);
+		/* Tx interrupts moderation */
+		if (priv->tx_coalesce <= tx_coalesce) {
+			priv->tx_coalesce++;
+			priv->mac_type->ops->clear_tx_ic(desc);
 		} else {
-			lp->tx_aggregation = 0;
+			priv->tx_coalesce = 0;
 		}
 	}
 
 	dev->stats.tx_bytes += skb->len;
-	lp->xstats.tx_bytes += skb->len;
 
 	/* CSR1 enables the transmit DMA to check for new descriptor */
 	writel(1, dev->base_addr + DMA_XMT_POLL_DEMAND);
 
 	dev->trans_start = jiffies;
-	spin_unlock_irqrestore(&lp->tx_lock, flags);
+	spin_unlock_irqrestore(&priv->tx_lock, flags);
 
 	return NETDEV_TX_OK;
 }
 
 static __inline__ void stmmac_rx_refill(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-	unsigned int rxsize = lp->dma_rx_size;
-	int bfsize = lp->dma_buf_sz;
-	dma_desc *p = lp->dma_rx;
-
-	for (; lp->cur_rx - lp->dirty_rx > 0; lp->dirty_rx++) {
-		int entry = lp->dirty_rx % rxsize;
-		if (lp->rx_skbuff[entry] == NULL) {
+	struct stmmac_priv *priv = netdev_priv(dev);
+	unsigned int rxsize = priv->dma_rx_size;
+	int bfsize = priv->dma_buf_sz;
+	struct dma_desc *p = priv->dma_rx;
+
+	for (; priv->cur_rx - priv->dirty_rx > 0; priv->dirty_rx++) {
+		unsigned int entry = priv->dirty_rx % rxsize;
+		if (priv->rx_skbuff[entry] == NULL) {
 			struct sk_buff *skb = netdev_alloc_skb(dev, bfsize);
 			if (unlikely(skb == NULL)) {
 				printk(KERN_ERR "%s: skb is NULL\n",
@@ -1328,54 +1453,65 @@ static __inline__ void stmmac_rx_refill(struct net_device *dev)
 				break;
 			}
 			skb_reserve(skb, STMMAC_IP_ALIGN);
-			lp->rx_skbuff[entry] = skb;
-			lp->rx_skbuff_dma[entry] = dma_map_single(lp->device,
-								  skb->data,
-								  bfsize,
-								  DMA_FROM_DEVICE);
-			(p + entry)->des2 = lp->rx_skbuff_dma[entry];
+			priv->rx_skbuff[entry] = skb;
+			priv->rx_skbuff_dma[entry] =
+			    dma_map_single(priv->device, skb->data, bfsize,
+					   DMA_FROM_DEVICE);
+			(p + entry)->des2 = priv->rx_skbuff_dma[entry];
+			if (priv->is_gmac) {
+				if (bfsize >= BUF_SIZE_8KiB)
+					(p + entry)->des3 =
+					    (p + entry)->des2 + BUF_SIZE_8KiB;
+			}
 			RX_DBG("\trefill entry #%d\n", entry);
 		}
-		lp->mac_type->ops->set_rx_owner(p + entry);
+		priv->mac_type->ops->set_rx_owner(p + entry);
 	}
 	return;
 }
 
 static int stmmac_rx(struct net_device *dev, int limit)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-	unsigned int rxsize = lp->dma_rx_size;
-	int entry = lp->cur_rx % rxsize, count;
+	struct stmmac_priv *priv = netdev_priv(dev);
+	unsigned int rxsize = priv->dma_rx_size;
+	unsigned int entry = priv->cur_rx % rxsize, count;
 
 #ifdef STMMAC_RX_DEBUG
-	printk(">>> stmmac_rx: descriptor ring:\n");
-	display_ring(lp->dma_rx, rxsize);
+	if (netif_msg_hw(priv)) {
+		printk(KERN_DEBUG ">>> stmmac_rx: descriptor ring:\n");
+		display_ring(priv->dma_rx, rxsize);
+	}
 #endif
-	lp->xstats.rx_poll_n++;
-
 	for (count = 0; count < limit; ++count) {
-		dma_desc *p = lp->dma_rx + entry;
+		struct dma_desc *p = priv->dma_rx + entry;
+		int status;
 
-		if (lp->mac_type->ops->read_rx_owner(p))
+		if (priv->mac_type->ops->get_rx_owner(p))
 			break;
 		/* read the status of the incoming frame */
-		if (unlikely((lp->mac_type->ops->rx_status(&dev->stats,
-							   &lp->xstats,
-							   p) < 0))) {
+		status = (priv->mac_type->ops->rx_status(&dev->stats,
+							 &priv->xstats, p));
+		if (unlikely(status == discard_frame)) {
 			dev->stats.rx_errors++;
 		} else {
 			struct sk_buff *skb;
 			/* Length should omit the CRC */
 			int frame_len =
-			    lp->mac_type->ops->get_rx_frame_len(p) - 4;
+			    priv->mac_type->ops->get_rx_frame_len(p) - 4;
 
-			RX_DBG
-			    ("\tdesc: 0x%0x [entry %d] buff=0x%x\n",
-			     (unsigned int)p, entry, p->des2);
+#ifdef STMMAC_RX_DEBUG
+			if (frame_len > ETH_FRAME_LEN)
+				printk(KERN_DEBUG "\tRX frame size: %d,"
+				       " COE status: %d\n", frame_len, status);
+
+			if (netif_msg_hw(priv))
+				printk(KERN_DEBUG "\tdesc: %p [entry %d]"
+				       " buff=0x%x\n", p, entry, p->des2);
+#endif
 
 			/* Check if the packet is long enough to accept without
 			   copying to a minimally-sized skbuff. */
-			if (unlikely(frame_len < rx_copybreak)) {
+			if (unlikely(frame_len < minrx)) {
 				skb =
 				    dev_alloc_skb(STMMAC_ALIGN(frame_len + 2));
 				if (unlikely(!skb)) {
@@ -1389,44 +1525,45 @@ static int stmmac_rx(struct net_device *dev, int limit)
 				}
 
 				skb_reserve(skb, STMMAC_IP_ALIGN);
-				dma_sync_single_for_cpu(lp->device,
-							lp->rx_skbuff_dma
+				dma_sync_single_for_cpu(priv->device,
+							priv->rx_skbuff_dma
 							[entry], frame_len,
 							DMA_FROM_DEVICE);
 				skb_copy_to_linear_data(skb,
-							lp->rx_skbuff[entry]->
-							data, frame_len);
+							priv->
+							rx_skbuff[entry]->data,
+							frame_len);
 
 				skb_put(skb, frame_len);
-				dma_sync_single_for_device(lp->device,
-							   lp->rx_skbuff_dma
+				dma_sync_single_for_device(priv->device,
+							   priv->rx_skbuff_dma
 							   [entry], frame_len,
 							   DMA_FROM_DEVICE);
 			} else {	/* zero-copy */
-				skb = lp->rx_skbuff[entry];
+				skb = priv->rx_skbuff[entry];
 				if (unlikely(!skb)) {
 					printk(KERN_ERR "%s: Inconsistent Rx "
 					       "descriptor chain.\n",
 					       dev->name);
 					dev->stats.rx_dropped++;
-					lp->xstats.rx_dropped++;
 					break;
 				}
-				lp->rx_skbuff[entry] = NULL;
+				priv->rx_skbuff[entry] = NULL;
 				skb_put(skb, frame_len);
-				dma_unmap_single(lp->device,
-						 lp->rx_skbuff_dma[entry],
-						 lp->dma_buf_sz,
+				dma_unmap_single(priv->device,
+						 priv->rx_skbuff_dma[entry],
+						 priv->dma_buf_sz,
 						 DMA_FROM_DEVICE);
 			}
 #ifdef STMMAC_RX_DEBUG
-			if (netif_msg_pktdata(lp)) {
-				printk(KERN_DEBUG " - frame received: ");
+			if (netif_msg_pktdata(priv)) {
+				printk(KERN_INFO " frame received (%dbytes)",
+				       frame_len);
 				print_pkt(skb->data, frame_len);
 			}
 #endif
 			skb->protocol = eth_type_trans(skb, dev);
-			if (lp->mac_type->ops->rx_checksum(p) < 0)
+			if (status == csum_none)
 				skb->ip_summed = CHECKSUM_NONE;
 			else
 				skb->ip_summed = CHECKSUM_UNNECESSARY;
@@ -1435,11 +1572,9 @@ static int stmmac_rx(struct net_device *dev, int limit)
 
 			dev->stats.rx_packets++;
 			dev->stats.rx_bytes += frame_len;
-			lp->xstats.rx_bytes += frame_len;
 			dev->last_rx = jiffies;
 		}
-		entry = (++lp->cur_rx) % rxsize;
-		p = lp->dma_rx + entry;
+		entry = (++priv->cur_rx) % rxsize;
 	}
 
 	stmmac_rx_refill(dev);
@@ -1459,15 +1594,22 @@ static int stmmac_rx(struct net_device *dev, int limit)
  */
 static int stmmac_poll(struct net_device *dev, int *budget)
 {
-	int work_done, limit = min(dev->quota, *budget);;
+	int work_done, limit = min(dev->quota, *budget);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
 	work_done = stmmac_rx(dev, limit);
 	dev->quota -= work_done;
 	*budget -= work_done;
 
+	priv->xstats.rx_poll_n++;
+
 	if (work_done < limit) {
 		netif_rx_complete(dev);
+
 		stmmac_dma_enable_irq_rx(dev->base_addr);
+#ifdef CONFIG_STMMAC_TIMER
+		priv->tm->timer_start(tmrate);
+#endif
 		return 0;
 	}
 	return 1;
@@ -1477,27 +1619,27 @@ static int stmmac_poll(struct net_device *dev, int *budget)
  *  stmmac_tx_timeout
  *  @dev : Pointer to net device structure
  *  Description: this function is called when a packet transmission fails to
- *   complete within a reasonable period. The driver will mark the error in the
+ *   complete within a reasonable tmrate. The driver will mark the error in the
  *   netdev structure and arrange for the device to be reset to a sane state
  *   in order to transmit a new packet.
  */
 static void stmmac_tx_timeout(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
 	printk(KERN_WARNING "%s: Tx timeout at %ld, latency %ld\n",
 	       dev->name, jiffies, (jiffies - dev->trans_start));
 
 #ifdef STMMAC_DEBUG
 	printk("(current=%d, dirty=%d)\n",
-	       (lp->cur_tx % lp->dma_tx_size),
-	       (lp->dirty_tx % lp->dma_tx_size));
+	       (priv->cur_tx % priv->dma_tx_size),
+	       (priv->dirty_tx % priv->dma_tx_size));
 	printk("DMA tx ring status: \n");
-	display_ring(lp->dma_tx, lp->dma_tx_size);
+	display_ring(priv->dma_tx, priv->dma_tx_size);
 #endif
-	/* Remove tx optmizarion */
-	tx_aggregation = TX_AGGREGATION;
-	lp->tx_aggregation = 0;
+	/* Remove tx moderation */
+	tx_coalesce = -1;
+	priv->tx_coalesce = 0;
 
 	/* Clear Tx resources and restart transmitting again */
 	stmmac_tx_err(dev);
@@ -1542,10 +1684,10 @@ static int stmmac_config(struct net_device *dev, struct ifmap *map)
  */
 static void stmmac_multicast_list(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
 	/* Calling the hw function. */
-	lp->mac_type->ops->set_filter(dev);
+	priv->mac_type->ops->set_filter(dev);
 
 	return;
 }
@@ -1563,14 +1705,25 @@ static void stmmac_multicast_list(struct net_device *dev)
  */
 static int stmmac_change_mtu(struct net_device *dev, int new_mtu)
 {
+	struct stmmac_priv *priv = netdev_priv(dev);
+	int max_mtu;
+
 	if (netif_running(dev)) {
 		printk(KERN_ERR
 		       "%s: must be stopped to change its MTU\n", dev->name);
 		return -EBUSY;
 	}
 
-	if ((new_mtu < MIN_MTU) || (new_mtu > MAX_MTU))
+	if (priv->is_gmac)
+		max_mtu = JUMBO_LEN;
+	else
+		max_mtu = ETH_DATA_LEN;
+
+	if ((new_mtu < 46) || (new_mtu > max_mtu)) {
+		printk(KERN_ERR
+		       "%s: invalid MTU, max MTU is: %d\n", dev->name, max_mtu);
 		return -EINVAL;
+	}
 
 	dev->mtu = new_mtu;
 
@@ -1580,17 +1733,17 @@ static int stmmac_change_mtu(struct net_device *dev, int new_mtu)
 static irqreturn_t stmmac_interrupt(int irq, void *dev_id)
 {
 	struct net_device *dev = (struct net_device *)dev_id;
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
 	if (unlikely(!dev)) {
 		printk(KERN_ERR "%s: invalid dev pointer\n", __FUNCTION__);
 		return IRQ_NONE;
 	}
 
-	if (lp->is_gmac) {
+	if (priv->is_gmac) {
 		unsigned long ioaddr = dev->base_addr;
 		/* To handle GMAC own interrupts */
-		lp->mac_type->ops->host_irq_status(ioaddr);
+		priv->mac_type->ops->host_irq_status(ioaddr);
 	}
 	stmmac_dma_interrupt(dev);
 
@@ -1620,7 +1773,7 @@ static void stmmac_poll_controller(struct net_device *dev)
  */
 static int stmmac_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	int ret = -EOPNOTSUPP;
 
 	if (!netif_running(dev))
@@ -1630,12 +1783,12 @@ static int stmmac_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
 	case SIOCGMIIPHY:
 	case SIOCGMIIREG:
 	case SIOCSMIIREG:
-		if (!lp->phydev)
+		if (!priv->phydev)
 			return -EINVAL;
 
-		spin_lock(&lp->lock);
-		ret = phy_mii_ioctl(lp->phydev, if_mii(rq), cmd);
-		spin_unlock(&lp->lock);
+		spin_lock(&priv->lock);
+		ret = phy_mii_ioctl(priv->phydev, if_mii(rq), cmd);
+		spin_unlock(&priv->lock);
 	default:
 		break;
 	}
@@ -1646,13 +1799,13 @@ static int stmmac_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
 static void stmmac_vlan_rx_register(struct net_device *dev,
 				    struct vlan_group *grp)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
-	spin_lock(&lp->lock);
+	spin_lock(&priv->lock);
 	/* VLAN Tag identifier register already contains the VLAN tag ID. 
 	   (see hw mac initialization). */
-	lp->vlgrp = grp;
-	spin_unlock(&lp->lock);
+	priv->vlgrp = grp;
+	spin_unlock(&priv->lock);
 }
 #endif
 
@@ -1666,9 +1819,7 @@ static void stmmac_vlan_rx_register(struct net_device *dev,
 static int stmmac_probe(struct net_device *dev)
 {
 	int ret = 0;
-	struct eth_driver_local *lp = netdev_priv(dev);
-
-	stmmac_verify_args();
+	struct stmmac_priv *priv = netdev_priv(dev);
 
 	ether_setup(dev);
 
@@ -1694,28 +1845,23 @@ static int stmmac_probe(struct net_device *dev)
 	dev->vlan_rx_register = stmmac_vlan_rx_register;
 #endif
 
-	lp->msg_enable = netif_msg_init(debug, default_msg_level);
-
-	if (lp->is_gmac) {
-		lp->rx_csum = 1;
-	}
+	priv->msg_enable = netif_msg_init(debug, default_msg_level);
 
-	/* Just to keep aligned values. */
-	lp->dma_tx_size = STMMAC_ALIGN(dma_tx_size_param);
-	lp->dma_rx_size = STMMAC_ALIGN(dma_rx_size_param);
-	lp->dma_buf_sz = lp->mac_type->hw.buf_size;
+	if (priv->is_gmac)
+		priv->rx_csum = 1;
 
 	if (flow_ctrl)
-		lp->flow_ctrl = FLOW_AUTO;	/* RX/TX pause on */
+		priv->flow_ctrl = FLOW_AUTO;	/* RX/TX pause on */
 
-	lp->pause = pause;
+	priv->pause = pause;
 
 	dev->poll = stmmac_poll;
 	dev->weight = 64;
 
 	/* Get the MAC address */
 	get_mac_address(dev->base_addr, dev->dev_addr,
-			lp->mac_type->hw.addr_high, lp->mac_type->hw.addr_low);
+			priv->mac_type->hw.addr_high,
+			priv->mac_type->hw.addr_low);
 
 	if (!is_valid_ether_addr(dev->dev_addr)) {
 		printk(KERN_WARNING "\tno valid MAC address; "
@@ -1732,8 +1878,8 @@ static int stmmac_probe(struct net_device *dev)
 	    dev->name, (dev->features & NETIF_F_SG) ? "on" : "off",
 	    (dev->features & NETIF_F_HW_CSUM) ? "on" : "off");
 
-	spin_lock_init(&lp->lock);
-	spin_lock_init(&lp->tx_lock);
+	spin_lock_init(&priv->lock);
+	spin_lock_init(&priv->tx_lock);
 
 	return ret;
 }
@@ -1746,17 +1892,17 @@ static int stmmac_probe(struct net_device *dev)
  */
 static __inline__ void stmmac_mac_device_setup(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	unsigned long ioaddr = dev->base_addr;
 
-	struct device_info_t *device;
+	struct mac_device_info *device;
 
-	if (lp->is_gmac)
+	if (priv->is_gmac)
 		device = gmac_setup(ioaddr);
 	else
 		device = mac100_setup(ioaddr);
-	lp->mac_type = device;
-	lp->wolenabled = lp->mac_type->hw.pmt;	// PMT supported
+	priv->mac_type = device;
+	priv->wolenabled = priv->mac_type->hw.pmt;	/* PMT supported */
 
 	return;
 }
@@ -1802,7 +1948,7 @@ static struct platform_driver stmmacphy_driver = {
  */
 static int stmmac_associate_phy(struct device *dev, void *data)
 {
-	struct eth_driver_local *lp = (struct eth_driver_local *)data;
+	struct stmmac_priv *priv = (struct stmmac_priv *)data;
 	struct plat_stmmacphy_data *plat_dat;
 
 	plat_dat = (struct plat_stmmacphy_data *)(dev->platform_data);
@@ -1811,27 +1957,27 @@ static int stmmac_associate_phy(struct device *dev, void *data)
 	    "stmmacphy_dvr_probe: checking phy for bus %d\n", plat_dat->bus_id);
 
 	/* Check that this phy is for the MAC being initialised */
-	if (lp->bus_id != plat_dat->bus_id)
+	if (priv->bus_id != plat_dat->bus_id)
 		return 0;
 
-	/* OK, this PHY is connected to the MAC.  Go ahead and get the parameters */
+	/* OK, this PHY is connected to the MAC.
+	   Go ahead and get the parameters */
 	DBG(probe, DEBUG, "stmmacphy_dvr_probe: OK. Found PHY config\n");
-	lp->phy_irq =
+	priv->phy_irq =
 	    platform_get_irq_byname(to_platform_device(dev), "phyirq");
 	DBG(probe, DEBUG,
 	    "stmmacphy_dvr_probe: PHY irq on bus %d is %d\n",
-	    plat_dat->bus_id, lp->phy_irq);
+	    plat_dat->bus_id, priv->phy_irq);
 
 	/* Override with kernel parameters if supplied XXX CRS XXX 
 	 * this needs to have multiple instances */
-	if ((phy_n >= 0) && (phy_n <= 31)) {
-		plat_dat->phy_addr = phy_n;
-	}
+	if ((phyaddr >= 0) && (phyaddr <= 31))
+		plat_dat->phy_addr = phyaddr;
 
-	lp->phy_addr = plat_dat->phy_addr;
-	lp->phy_mask = plat_dat->phy_mask;
-	lp->phy_interface = plat_dat->interface;
-	lp->phy_reset = plat_dat->phy_reset;
+	priv->phy_addr = plat_dat->phy_addr;
+	priv->phy_mask = plat_dat->phy_mask;
+	priv->phy_interface = plat_dat->interface;
+	priv->phy_reset = plat_dat->phy_reset;
 
 	DBG(probe, DEBUG, "stmmacphy_dvr_probe: exiting\n");
 	return 1;		/* forces exit of driver_for_each_device() */
@@ -1850,7 +1996,7 @@ static int stmmac_dvr_probe(struct platform_device *pdev)
 	struct resource *res;
 	unsigned int *addr = NULL;
 	struct net_device *ndev = NULL;
-	struct eth_driver_local *lp;
+	struct stmmac_priv *priv;
 	struct plat_stmmacenet_data *plat_dat;
 
 	printk(KERN_INFO "STMMAC driver:\n\tplatform registration... ");
@@ -1878,7 +2024,7 @@ static int stmmac_dvr_probe(struct platform_device *pdev)
 		goto out;
 	}
 
-	ndev = alloc_etherdev(sizeof(struct eth_driver_local));
+	ndev = alloc_etherdev(sizeof(struct stmmac_priv));
 	if (!ndev) {
 		printk(KERN_ERR "%s: ERROR: allocating the device\n",
 		       __FUNCTION__);
@@ -1894,13 +2040,13 @@ static int stmmac_dvr_probe(struct platform_device *pdev)
 		goto out;
 	}
 
-	lp = netdev_priv(ndev);
-	lp->device = &(pdev->dev);
-	lp->dev = ndev;
+	priv = netdev_priv(ndev);
+	priv->device = &(pdev->dev);
+	priv->dev = ndev;
 	plat_dat = (struct plat_stmmacenet_data *)((pdev->dev).platform_data);
-	lp->bus_id = plat_dat->bus_id;
-	lp->pbl = plat_dat->pbl;	/* TLI */
-	lp->is_gmac = plat_dat->has_gmac;	/* GMAC is on board */
+	priv->bus_id = plat_dat->bus_id;
+	priv->pbl = plat_dat->pbl;	/* TLI */
+	priv->is_gmac = plat_dat->has_gmac;	/* GMAC is on board */
 
 	platform_set_drvdata(pdev, ndev);
 
@@ -1918,15 +2064,15 @@ static int stmmac_dvr_probe(struct platform_device *pdev)
 
 	/* associate a PHY - it is provided by another platform bus */
 	if (!driver_for_each_device
-	    (&(stmmacphy_driver.driver), NULL, (void *)lp,
+	    (&(stmmacphy_driver.driver), NULL, (void *)priv,
 	     stmmac_associate_phy)) {
 		printk(KERN_ERR "No PHY device is associated with this MAC!\n");
 		ret = -ENODEV;
 		goto out;
 	}
 
-	lp->fix_mac_speed = plat_dat->fix_mac_speed;
-	lp->bsp_priv = plat_dat->bsp_priv;
+	priv->fix_mac_speed = plat_dat->fix_mac_speed;
+	priv->bsp_priv = plat_dat->bsp_priv;
 
 	/* MDIO bus Registration */
 	printk(KERN_DEBUG "registering MDIO bus...\n");
@@ -1982,71 +2128,71 @@ static int stmmac_dvr_remove(struct platform_device *pdev)
 }
 
 #ifdef CONFIG_PM
-
 static int stmmac_suspend(struct platform_device *pdev, pm_message_t state)
 {
 	struct net_device *dev = platform_get_drvdata(pdev);
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 
 	if (!dev || !netif_running(dev))
 		return 0;
 
-	spin_lock(&lp->lock);
+	spin_lock(&priv->lock);
 
 	if (state.event == PM_EVENT_SUSPEND) {
 		netif_device_detach(dev);
 		netif_stop_queue(dev);
-		phy_stop(lp->phydev);
+		phy_stop(priv->phydev);
 		netif_stop_queue(dev);
-		tasklet_disable(&lp->tx_task);
+		tasklet_disable(&priv->tx_task);
 
 #ifdef CONFIG_STMMAC_TIMER
-		if (likely(lp->has_timer == 0)) {
-			stmmac_timer_stop();
-		}
+		priv->tm->timer_stop();
 #endif
 		/* Stop TX/RX DMA */
 		stmmac_dma_stop_tx(dev->base_addr);
 		stmmac_dma_stop_rx(dev->base_addr);
 		/* Clear the Rx/Tx descriptors */
-		lp->mac_type->ops->init_rx_desc(lp->dma_rx, lp->dma_rx_size,
-						rx_irq_mitigation);
-		lp->mac_type->ops->init_tx_desc(lp->dma_tx, lp->dma_tx_size);
+		priv->mac_type->ops->init_rx_desc(priv->dma_rx,
+						  priv->dma_rx_size);
+		priv->mac_type->ops->disable_rx_ic(priv->dma_rx, rxsize,
+						   rx_coalesce);
+		priv->mac_type->ops->init_tx_desc(priv->dma_tx,
+						  priv->dma_tx_size);
 
 		stmmac_mac_disable_tx(dev);
 
 		if (device_may_wakeup(&(pdev->dev))) {
 			/* Enable Power down mode by programming the PMT regs */
-			if (lp->wolenabled == PMT_SUPPORTED)
-				lp->mac_type->ops->pmt(dev->base_addr,
-						       lp->wolopts);
+			if (priv->wolenabled == PMT_SUPPORTED)
+				priv->mac_type->ops->pmt(dev->base_addr,
+							 priv->wolopts);
 		} else {
 			stmmac_mac_disable_rx(dev);
 		}
 	} else {
-		lp->shutdown = 1;
+		priv->shutdown = 1;
 		/* Although this can appear slightly redundant it actually 
 		 * makes fast the standby operation and guarantees the driver 
 		 * working if hibernation is on media. */
 		stmmac_release(dev);
 	}
 
-	spin_unlock(&lp->lock);
+	spin_unlock(&priv->lock);
 	return 0;
 }
 
 static int stmmac_resume(struct platform_device *pdev)
 {
 	struct net_device *dev = platform_get_drvdata(pdev);
-	struct eth_driver_local *lp = netdev_priv(dev);
+	struct stmmac_priv *priv = netdev_priv(dev);
 	unsigned long ioaddr = dev->base_addr;
 
 	if (!netif_running(dev))
 		return 0;
 
-	spin_lock(&lp->lock);
+	spin_lock(&priv->lock);
 
-	if (lp->shutdown) {
+	if (priv->shutdown) {
 		/* Re-open the interface and re-init the MAC/DMA
 		   and the rings. */
 		stmmac_open(dev);
@@ -2062,18 +2208,16 @@ static int stmmac_resume(struct platform_device *pdev)
 	stmmac_dma_start_rx(ioaddr);
 
 #ifdef CONFIG_STMMAC_TIMER
-	if (likely(lp->has_timer == 0)) {
-		stmmac_timer_start(periodic_rate);
-	}
+	priv->tm->timer_start(tmrate);
 #endif
-	tasklet_enable(&lp->tx_task);
+	tasklet_enable(&priv->tx_task);
 
-	phy_start(lp->phydev);
+	phy_start(priv->phydev);
 
 	netif_start_queue(dev);
 
       out_resume:
-	spin_unlock(&lp->lock);
+	spin_unlock(&priv->lock);
 	return 0;
 }
 #endif
@@ -2114,6 +2258,7 @@ static void __exit stmmac_cleanup_module(void)
 	platform_driver_unregister(&stmmac_driver);
 }
 
+#ifndef MODULE
 static int __init stmmac_cmdline_opt(char *str)
 {
 	char *opt;
@@ -2122,31 +2267,35 @@ static int __init stmmac_cmdline_opt(char *str)
 		return -EINVAL;
 
 	while ((opt = strsep(&str, ",")) != NULL) {
-		if (!strncmp(opt, "msglvl:", 7)) {
-			debug = simple_strtoul(opt + 7, NULL, 0);
+		if (!strncmp(opt, "debug:", 6)) {
+			debug = simple_strtoul(opt + 6, NULL, 0);
 		} else if (!strncmp(opt, "phyaddr:", 8)) {
-			phy_n = simple_strtoul(opt + 8, NULL, 0);
+			phyaddr = simple_strtoul(opt + 8, NULL, 0);
+		} else if (!strncmp(opt, "dma_txsize:", 11)) {
+			dma_txsize = simple_strtoul(opt + 11, NULL, 0);
+		} else if (!strncmp(opt, "dma_rxsize:", 11)) {
+			dma_rxsize = simple_strtoul(opt + 11, NULL, 0);
+		} else if (!strncmp(opt, "buf_sz:", 7)) {
+			buf_sz = simple_strtoul(opt + 7, NULL, 0);
+		} else if (!strncmp(opt, "tc:", 3)) {
+			tc = simple_strtoul(opt + 3, NULL, 0);
+		} else if (!strncmp(opt, "tx_coe:", 7)) {
+			tx_coe = simple_strtoul(opt + 7, NULL, 0);
 		} else if (!strncmp(opt, "watchdog:", 9)) {
 			watchdog = simple_strtoul(opt + 9, NULL, 0);
-		} else if (!strncmp(opt, "minrx:", 6)) {
-			rx_copybreak = simple_strtoul(opt + 6, NULL, 0);
-		} else if (!strncmp(opt, "txsize:", 7)) {
-			dma_tx_size_param = simple_strtoul(opt + 7, NULL, 0);
-		} else if (!strncmp(opt, "rxsize:", 7)) {
-			dma_rx_size_param = simple_strtoul(opt + 7, NULL, 0);
 		} else if (!strncmp(opt, "flow_ctrl:", 10)) {
 			flow_ctrl = simple_strtoul(opt + 10, NULL, 0);
 		} else if (!strncmp(opt, "pause:", 6)) {
 			pause = simple_strtoul(opt + 6, NULL, 0);
-		} else if (!strncmp(opt, "tc:", 3)) {
-			threshold_ctrl = simple_strtoul(opt + 3, NULL, 0);
-		} else if (!strncmp(opt, "txmit:", 6)) {
-			tx_aggregation = simple_strtoul(opt + 6, NULL, 0);
-		} else if (!strncmp(opt, "rxmit:", 6)) {
-			rx_irq_mitigation = simple_strtoul(opt + 6, NULL, 0);
+		} else if (!strncmp(opt, "minrx:", 6)) {
+			minrx = simple_strtoul(opt + 6, NULL, 0);
+		} else if (!strncmp(opt, "tx_coalesce:", 12)) {
+			tx_coalesce = simple_strtoul(opt + 12, NULL, 0);
+		} else if (!strncmp(opt, "rx_coalesce:", 12)) {
+			rx_coalesce = simple_strtoul(opt + 12, NULL, 0);
 #ifdef CONFIG_STMMAC_TIMER
-		} else if (!strncmp(opt, "period:", 7)) {
-			periodic_rate = simple_strtoul(opt + 7, NULL, 0);
+		} else if (!strncmp(opt, "tmrate:", 7)) {
+			tmrate = simple_strtoul(opt + 7, NULL, 0);
 #endif
 		}
 	}
@@ -2154,6 +2303,7 @@ static int __init stmmac_cmdline_opt(char *str)
 }
 
 __setup("stmmaceth=", stmmac_cmdline_opt);
+#endif
 
 module_init(stmmac_init_module);
 module_exit(stmmac_cleanup_module);
diff --git a/drivers/net/stmmac/stmmac_mdio.c b/drivers/net/stmmac/stmmac_mdio.c
index f0abfc1..b69cbb5 100644
--- a/drivers/net/stmmac/stmmac_mdio.c
+++ b/drivers/net/stmmac/stmmac_mdio.c
@@ -39,10 +39,10 @@
 int stmmac_mdio_read(struct mii_bus *bus, int phyaddr, int phyreg)
 {
 	struct net_device *ndev = bus->priv;
-	struct eth_driver_local *lp = netdev_priv(ndev);
+	struct stmmac_priv *priv = netdev_priv(ndev);
 	unsigned long ioaddr = ndev->base_addr;
-	unsigned int mii_address = lp->mac_type->hw.mii.addr;
-	unsigned int mii_data = lp->mac_type->hw.mii.data;
+	unsigned int mii_address = priv->mac_type->hw.mii.addr;
+	unsigned int mii_data = priv->mac_type->hw.mii.data;
 
 	int data;
 	u16 regValue = (((phyaddr << 11) & (0x0000F800)) |
@@ -74,10 +74,10 @@ int stmmac_mdio_read(struct mii_bus *bus, int phyaddr, int phyreg)
 int stmmac_mdio_write(struct mii_bus *bus, int phyaddr, int phyreg, u16 phydata)
 {
 	struct net_device *ndev = bus->priv;
-	struct eth_driver_local *lp = netdev_priv(ndev);
+	struct stmmac_priv *priv = netdev_priv(ndev);
 	unsigned long ioaddr = ndev->base_addr;
-	unsigned int mii_address = lp->mac_type->hw.mii.addr;
-	unsigned int mii_data = lp->mac_type->hw.mii.data;
+	unsigned int mii_address = priv->mac_type->hw.mii.addr;
+	unsigned int mii_data = priv->mac_type->hw.mii.data;
 
 	u16 value =
 	    (((phyaddr << 11) & (0x0000F800)) | ((phyreg << 6) & (0x000007C0)))
@@ -96,10 +96,13 @@ int stmmac_mdio_write(struct mii_bus *bus, int phyaddr, int phyreg, u16 phydata)
 	/* Wait until any existing MII operation is complete */
 	while (((readl(ioaddr + mii_address)) & MII_BUSY) == 1) {
 	}
-
-	/* NOTE: we need to perform this "extra" read in order to fix an error
-	 * during the write operation */
+	/* This "extra" read was added, in the past, to fix an
+	* issue related to the control MII bus specific operation (MDC/MDIO).
+	* It forced the close operation of the message on the bus (hw hack
+	* was to add a specific pull-up on one of the two MCD/MDIO lines).
+	* It can be removed because no new board actually needs it.
 	stmmac_mdio_read(bus, phyaddr, phyreg);
+	*/
 	return 0;
 }
 
@@ -107,15 +110,15 @@ int stmmac_mdio_write(struct mii_bus *bus, int phyaddr, int phyreg, u16 phydata)
 int stmmac_mdio_reset(struct mii_bus *bus)
 {
 	struct net_device *ndev = bus->priv;
-	struct eth_driver_local *lp = netdev_priv(ndev);
+	struct stmmac_priv *priv = netdev_priv(ndev);
 	unsigned long ioaddr = ndev->base_addr;
-	unsigned int mii_address = lp->mac_type->hw.mii.addr;
+	unsigned int mii_address = priv->mac_type->hw.mii.addr;
 
 	printk(KERN_DEBUG "stmmac_mdio_reset: called!\n");
 
-	if (lp->phy_reset) {
+	if (priv->phy_reset) {
 		printk(KERN_DEBUG "stmmac_mdio_reset: calling phy_reset\n");
-		return lp->phy_reset(lp->bsp_priv);
+		return priv->phy_reset(priv->bsp_priv);
 	}
 
 	/* This is a workaround for problems with the STE101P PHY.
@@ -137,23 +140,23 @@ int stmmac_mdio_register(struct net_device *ndev)
 	int err = 0;
 	struct mii_bus *new_bus = kzalloc(sizeof(struct mii_bus), GFP_KERNEL);
 	int *irqlist = kzalloc(sizeof(int) * PHY_MAX_ADDR, GFP_KERNEL);
-	struct eth_driver_local *lp = netdev_priv(ndev);
+	struct stmmac_priv *priv = netdev_priv(ndev);
 
 	if (new_bus == NULL)
 		return -ENOMEM;
 
 	/* Assign IRQ to phy at address phy_addr */
-	irqlist[lp->phy_addr] = lp->phy_irq;
+	irqlist[priv->phy_addr] = priv->phy_irq;
 
 	new_bus->name = "STMMAC MII Bus";
 	new_bus->read = &stmmac_mdio_read;
 	new_bus->write = &stmmac_mdio_write;
 	new_bus->reset = &stmmac_mdio_reset;
-	new_bus->id = (int)lp->bus_id;
+	new_bus->id = (int)priv->bus_id;
 	new_bus->priv = ndev;
 	new_bus->irq = irqlist;
-	new_bus->phy_mask = lp->phy_mask;
-	new_bus->dev = lp->device;
+	new_bus->phy_mask = priv->phy_mask;
+	new_bus->dev = priv->device;
 	printk(KERN_DEBUG "calling mdiobus_register\n");
 	err = mdiobus_register(new_bus);
 	printk(KERN_DEBUG "calling mdiobus_register done\n");
@@ -163,7 +166,7 @@ int stmmac_mdio_register(struct net_device *ndev)
 		goto bus_register_fail;
 	}
 
-	lp->mii = new_bus;
+	priv->mii = new_bus;
 
 	return 0;
       bus_register_fail:
@@ -178,11 +181,11 @@ int stmmac_mdio_register(struct net_device *ndev)
  */
 int stmmac_mdio_unregister(struct net_device *ndev)
 {
-	struct eth_driver_local *lp = netdev_priv(ndev);
+	struct stmmac_priv *priv = netdev_priv(ndev);
 
-	mdiobus_unregister(lp->mii);
-	lp->mii->priv = NULL;
-	kfree(lp->mii);
+	mdiobus_unregister(priv->mii);
+	priv->mii->priv = NULL;
+	kfree(priv->mii);
 
 	return 0;
 }
diff --git a/drivers/net/stmmac/stmmac_timer.c b/drivers/net/stmmac/stmmac_timer.c
index c6fea28..6c50ba4 100644
--- a/drivers/net/stmmac/stmmac_timer.c
+++ b/drivers/net/stmmac/stmmac_timer.c
@@ -11,17 +11,11 @@
 
 #include <linux/kernel.h>
 #include <linux/etherdevice.h>
+#include "stmmac_timer.h"
 
-extern void stmmac_timer_work(struct net_device *dev);
-
-int stmmac_timer_open(struct net_device *dev, unsigned int freq);
-int stmmac_timer_close(void);
-int stmmac_timer_start(unsigned int freq);
-int stmmac_timer_stop(void);
-
-static void stmmac_timer_handler(void *priv)
+static void stmmac_timer_handler(void *data)
 {
-	struct net_device *dev = (struct net_device *)priv;
+	struct net_device *dev = (struct net_device *)data;
 
 	stmmac_timer_work(dev);
 
@@ -36,27 +30,20 @@ printk(KERN_INFO "stmmac_timer: %s Timer ON (freq %dHz)\n",timer,freq);
 static struct rtc_device *stmmac_rtc;
 static rtc_task_t stmmac_task;
 
-int stmmac_timer_close(void)
+static void stmmac_rtc_start(unsigned int new_freq)
 {
-	rtc_irq_unregister(stmmac_rtc, &stmmac_task);
-	rtc_class_close(stmmac_rtc);
-	return 0;
-}
-
-int stmmac_timer_start(unsigned int freq)
-{
-	rtc_irq_set_freq(stmmac_rtc, &stmmac_task, freq);
+	rtc_irq_set_freq(stmmac_rtc, &stmmac_task, new_freq);
 	rtc_irq_set_state(stmmac_rtc, &stmmac_task, 1);
-	return 0;
+	return;
 }
 
-int stmmac_timer_stop(void)
+static void stmmac_rtc_stop(void)
 {
 	rtc_irq_set_state(stmmac_rtc, &stmmac_task, 0);
-	return 0;
+	return;
 }
 
-int stmmac_timer_open(struct net_device *dev, unsigned int freq)
+int stmmac_open_hw_timer(struct net_device *dev, struct stmmac_timer *tm)
 {
 	stmmac_task.private_data = dev;
 	stmmac_task.func = stmmac_timer_handler;
@@ -70,18 +57,29 @@ int stmmac_timer_open(struct net_device *dev, unsigned int freq)
 	rtc_irq_register(stmmac_rtc, &stmmac_task);
 
 	/* Periodic mode is not supported */
-	if ((rtc_irq_set_freq(stmmac_rtc, &stmmac_task, freq) < 0)) {
+	if ((rtc_irq_set_freq(stmmac_rtc, &stmmac_task, tm->freq) < 0)) {
 		printk(KERN_ERR "set periodic failed\n");
 		rtc_irq_unregister(stmmac_rtc, &stmmac_task);
 		rtc_class_close(stmmac_rtc);
 		return -1;
 	}
 
-	STMMAC_TIMER_MSG(CONFIG_RTC_HCTOSYS_DEVICE,freq);
+	STMMAC_TIMER_MSG(CONFIG_RTC_HCTOSYS_DEVICE, tm->freq);
+
+	tm->timer_start = stmmac_rtc_start;
+	tm->timer_stop = stmmac_rtc_stop;
 
 	return 0;
 }
 
+int stmmac_close_hw_timer(void)
+{
+	rtc_irq_set_state(stmmac_rtc, &stmmac_task, 0);
+	rtc_irq_unregister(stmmac_rtc, &stmmac_task);
+	rtc_class_close(stmmac_rtc);
+	return 0;
+}
+
 #elif defined(CONFIG_STMMAC_TMU_TIMER)
 #include <linux/clk.h>
 #define TMU_CHANNEL "tmu2_clk"
@@ -89,38 +87,41 @@ static struct clk *timer_clock;
 extern int tmu2_register_user(void *fnt, void *data);
 extern void tmu2_unregister_user(void);
 
-int stmmac_timer_start(unsigned int freq)
+static void stmmac_tmu_start(unsigned int new_freq)
 {
-	clk_set_rate(timer_clock, freq);
+	clk_set_rate(timer_clock, new_freq);
 	clk_enable(timer_clock);
-	return 0;
+	return;
 }
 
-int stmmac_timer_stop(void)
+static void stmmac_tmu_stop(void)
 {
 	clk_disable(timer_clock);
-	return 0;
+	return;
 }
 
-int stmmac_timer_open(struct net_device *dev, unsigned int freq)
+int stmmac_open_hw_timer(struct net_device *dev, struct stmmac_timer *tm)
 {
 	timer_clock = clk_get(NULL, TMU_CHANNEL);
 
 	if (timer_clock == NULL)
 		return -1;
 
-	if (tmu2_register_user(stmmac_timer_handler, (void *) dev) < 0){
+	if (tmu2_register_user(stmmac_timer_handler, (void *)dev) < 0) {
 		timer_clock = NULL;
 		return -1;
 	}
 
-	STMMAC_TIMER_MSG("TMU2",freq);
+	STMMAC_TIMER_MSG("TMU2", tm->freq);
+	tm->timer_start = stmmac_tmu_start;
+	tm->timer_stop = stmmac_tmu_stop;
 
 	return 0;
 }
 
-int stmmac_timer_close(void)
+int stmmac_close_hw_timer(void)
 {
+	clk_disable(timer_clock);
 	tmu2_unregister_user();
 	clk_put(timer_clock);
 	return 0;
-- 
1.5.3.6

