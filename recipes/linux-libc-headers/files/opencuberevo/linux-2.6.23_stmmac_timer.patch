This patch adds the timer optimization code (tested on 7109/7200 mac 10/100) 
and the tx csum experimental code for the 7111 Gmac.

Signed-off-by: Giuseppe Cavallaro <peppe.cavallaro@st.com>

diff -uprN linux.orig/drivers/net/stmmac/common.h linux/drivers/net/stmmac/common.h
--- linux.orig/drivers/net/stmmac/common.h	2008-03-07 14:51:51.000000000 +0100
+++ linux/drivers/net/stmmac/common.h	2008-03-14 08:22:37.749996000 +0100
@@ -1,3 +1,5 @@
+#include "descs.h"
+
 /* *********************************************
    DMA CRS Control and Status Register Mapping 
  * *********************************************/
@@ -14,17 +16,6 @@
 #define DMA_CUR_RX_BUF_ADDR	0x00001054	/* Current Host Rx Buffer */
 
 /* ********************************
-   DMA Bus Mode register defines 
- * ********************************/
-#define DMA_BUS_MODE_PBL_MASK	0x00003f00	/* Programmable Burst Len */
-#define DMA_BUS_MODE_PBL_SHIFT	8
-#define DMA_BUS_MODE_DSL_MASK	0x0000007c	/* Descriptor Skip Length */
-#define DMA_BUS_MODE_DSL_SHIFT	2	/*   (in DWORDS)      */
-#define DMA_BUS_MODE_BAR_BUS	0x00000002	/* Bar-Bus Arbitration */
-#define DMA_BUS_MODE_SFT_RESET	0x00000001	/* Software Reset */
-#define DMA_BUS_MODE_DEFAULT	0x00000000
-
-/* ********************************
    DMA Control register defines
  * ********************************/
 #define DMA_CONTROL_ST		0x00002000	/* Start/Stop Transmission */
@@ -41,7 +32,7 @@
 #define DMA_INTR_ENA_ERE 0x00004000	/* Early Receive */
 
 #define DMA_INTR_NORMAL	(DMA_INTR_ENA_NIE | DMA_INTR_ENA_RIE | DMA_INTR_ENA_TIE \
-			| DMA_INTR_ENA_ERE | DMA_INTR_ENA_TUE)
+			/*| DMA_INTR_ENA_ERE | DMA_INTR_ENA_TUE*/)
 
 /**** ABNORMAL INTERRUPT ****/
 #define DMA_INTR_ENA_AIE 0x00008000	/* Abnormal Summary */
@@ -55,8 +46,8 @@
 #define DMA_INTR_ENA_TJE 0x00000008	/* Transmit Jabber */
 #define DMA_INTR_ENA_TSE 0x00000002	/* Transmit Stopped */
 
-#define DMA_INTR_ABNORMAL	DMA_INTR_ENA_AIE
-				
+#define DMA_INTR_ABNORMAL	DMA_INTR_ENA_AIE | DMA_INTR_ENA_FBE /*| DMA_INTR_ENA_UNE*/
+
 /* DMA default interrupt mask */
 #define DMA_INTR_DEFAULT_MASK	(DMA_INTR_NORMAL | DMA_INTR_ABNORMAL)
 /* Disable DMA Rx IRQ (NAPI) */
@@ -89,61 +80,22 @@
 #define DMA_STATUS_TPS	0x00000002	/* Transmit Process Stopped */
 #define DMA_STATUS_TI	0x00000001	/* Transmit Interrupt */
 
-#define MAC_WAKEUP_FILTER	0x00000028	/* Wake-up Frame Filter */
-#define MAC_PMT 		0x0000002c	/* PMT Control and Status */
-#define DMA_STATUS_PMT	0x10000000
-
-/* ****************************
- *     Descriptor defines
- * ****************************/
-#define OWN_BIT			0x80000000	/* Own Bit */
-#define DES1_CONTROL_CH		0x01000000	/* Second Address Chained */
-#define DES1_CONTROL_TER	0x02000000	/* End of Ring */
-#define DES1_RBS2_SIZE_MASK	0x003ff800	/* Buffer 2 Size Mask */
-#define DES1_RBS2_SIZE_SHIFT	11		/* Buffer 2 Size Shift */
-#define DES1_RBS1_SIZE_MASK	0x000007ff	/* Buffer 1 Size Mask */
-#define DES1_RBS1_SIZE_SHIFT	0		/* Buffer 1 Size Shift */
-
-/* Transmit descriptor 0*/
-#define TDES0_STATUS_ES		  0x00008000	/* Error Summary */
-
-/* Transmit descriptor 1*/
-#define TDES1_CONTROL_IC	0x80000000	/* Interrupt on Completion */
-#define TDES1_CONTROL_LS	0x40000000	/* Last Segment */
-#define TDES1_CONTROL_FS	0x20000000	/* First Segment */
-#define TDES1_CONTROL_AC	0x04000000	/* Add CRC Disable */
-#define TDES1_CONTROL_DPD	0x00800000	/* Disable Padding */
-
-/* Rx descriptor 0 */
-#define RDES0_STATUS_FL_MASK 0x3fff0000	/* Frame Length Mask */
-#define RDES0_STATUS_FL_SHIFT 16	/* Frame Length Shift */
-#define RDES0_STATUS_FS 0x00000200   /* First Descriptor */
-#define RDES0_STATUS_LS 0x00000100   /* Last Descriptor */
-#define RDES0_STATUS_ES	0x00008000	/* Error Summary */
-
-#define RDES1_CONTROL_DIC 0x80000000 /* Prevents Interrupt on Completion */
-
-/* MAC 10/100 */
-
-#define MAC_CTRL_DESC_TER DES1_CONTROL_TER /*MAC RX/TX end-ring bit*/
-
-/* GMAC */
-#define GMAC_TX_CONTROL_TER  0x00200000 //TER bit: TDES0[21]
-#define GMAC_RX_CONTROL_TER  0x00008000 //TER bit: RDES1[25] 
-#define GMAC_TX_LAST_SEGMENT 0x20000000 //LAST SEG: TDES0[29]
-#define GMAC_TX_FIRST_SEGMENT 0x10000000 //FIRST SEG: TDES0[28]
-#define GMAC_TX_IC 0x40000000 //TDES0[30] interrupt on completion
+#define DMA_BUFFER_SIZE	2048
 
 /* Other defines */
 #define HASH_TABLE_SIZE 64
 #define PAUSE_TIME 0x200
 
 /* Flow Control defines */
-#define FLOW_OFF	0x0
-#define FLOW_RX		0x1
-#define FLOW_TX		0x2
+#define FLOW_OFF	0
+#define FLOW_RX		1
+#define FLOW_TX		2
 #define FLOW_AUTO	(FLOW_TX | FLOW_RX)
 
+/* HW csum */
+#define NO_HW_CSUM 0
+#define HAS_HW_CSUM 1
+
 /* Power Down and WOL */
 #define PMT_NOT_SUPPORTED 0
 #define PMT_SUPPORTED 1
@@ -171,7 +123,7 @@ struct stmmac_extra_stats {
 	unsigned long rx_lenght;
 	unsigned long rx_mii;
 	unsigned long rx_multicast;
-	unsigned long rx_overflow;
+	unsigned long rx_gmac_overflow;
 	unsigned long rx_watchdog;
 	unsigned long rx_filter;
 	unsigned long rx_dropped;
@@ -180,7 +132,7 @@ struct stmmac_extra_stats {
 	unsigned long tx_irq_n;
 	unsigned long rx_irq_n;
 	unsigned long tx_undeflow_irq;
-	unsigned long tx_threshold;
+	unsigned long threshold;
 	unsigned long tx_process_stopped_irq;
 	unsigned long tx_jabber_irq;
 	unsigned long rx_overflow_irq;
@@ -190,37 +142,58 @@ struct stmmac_extra_stats {
 	unsigned long tx_early_irq;
 	unsigned long fatal_bus_error_irq;
 	unsigned long rx_poll_n;
-};
-#define EXTRA_STATS 36
-
-/* Specific device structures (to mark the
- * difference between mac and gmac)*/
+	unsigned long tx_payload_error;
+	unsigned long tx_ip_header_error;
+	unsigned long rx_missed_cntr;
+	unsigned long rx_overflow_cntr;
+};
+#define EXTRA_STATS 40
+
+/* Specific device structure VFP in order to mark the
+ * difference between mac and gmac in terms of registers, descriptors etc.
+ */
 struct device_ops {
-	/* MAC controller initialization */
+	/* MAC core */
 	void (*core_init) (unsigned long ioaddr);
-	/* MAC registers */
-	void (*mac_registers) (unsigned long ioaddr);
-	/* DMA registers */
-	void (*dma_registers) (unsigned long ioaddr);
-	/* DMA tx threshold */
-	void (*dma_ttc) (unsigned long ioaddr, int value);
-	/* Return zero if no error is happened during the transmission */
-	int (*tx_err) (void *p, struct stmmac_extra_stats *x,
-			unsigned int status);
-	/* Check if the frame was not successfully received */
-	int (*rx_err) (void *p, struct stmmac_extra_stats *x,
-			unsigned int status);
-	/* Verify the TX checksum */
-	void (*tx_checksum) (struct sk_buff * skb);
-	/* Verifies the RX checksum */
-	void (*rx_checksum) (struct sk_buff * skb, int status);
-	/* Enable/Disable Multicast filtering */
+	void (*dump_mac_regs) (unsigned long ioaddr);
+
+	/* DMA core */
+	int (*dma_init) (unsigned long ioaddr, int pbl, u32 dma_tx, u32 dma_rx);
+	void (*dump_dma_regs) (unsigned long ioaddr);
+	void (*dma_operation_mode) (unsigned long ioaddr, int threshold);
+	void (*dma_diagnostic_fr) (void *data, struct stmmac_extra_stats *x,
+					unsigned long ioaddr);
+
+
+	/* Descriptors */
+	void (*init_rx_desc) (dma_desc * p, unsigned int ring_size,
+			      int rx_irq_threshol);
+	void (*init_tx_desc) (dma_desc * p, unsigned int ring_size);
+	int (*set_buf_size) (unsigned int len);
+	int (*read_tx_ls) (void);
+	int (*read_tx_owner) (dma_desc * p);
+	int (*read_rx_owner) (dma_desc * p);
+	void (*release_tx_desc) (dma_desc * p);
+	void (*prepare_tx_desc) (dma_desc * p, int is_fs, int len, 
+				unsigned int csum_flags);
+	void (*set_tx_ic) (dma_desc * p, int value);
+	void (*set_tx_ls) (dma_desc * p);
+	int (*get_tx_ls) (dma_desc * p);
+	void (*set_tx_owner) (dma_desc * p);
+	void (*set_rx_owner) (dma_desc * p);
+	int (*get_rx_frame_len) (dma_desc * p);
+
+	/* driver functions */
+	int (*tx_status) (void *data, struct stmmac_extra_stats * x,
+			  dma_desc * p, unsigned long ioaddr);
+	int (*rx_status) (void *data, struct stmmac_extra_stats * x,
+			  dma_desc * p);
+	void (*tx_checksum) (struct sk_buff * skb, dma_desc * p);
+	int (*rx_checksum) (dma_desc * p);
 	void (*set_filter) (struct net_device * dev);
-	/* Flow Control */
 	void (*flow_ctrl) (unsigned long ioaddr, unsigned int duplex,
 			   unsigned int fc, unsigned int pause_time);
-	/* Wake-up On Lan */
-	void (*enable_wol) (unsigned long ioaddr, unsigned long mode);
+	void (*pmt) (unsigned long ioaddr, unsigned long mode);
 };
 
 struct mac_link_t {
@@ -237,8 +210,9 @@ struct mii_regs_t {
 struct mac_regs_t {
 	unsigned int addr_high;	/* Multicast Hash Table High */
 	unsigned int addr_low;	/* Multicast Hash Table Low */
-	unsigned int version;	/* Core Version register (GMAC)*/
+	unsigned int version;	/* Core Version register (GMAC) */
 	unsigned int pmt;	/* Power-Down mode (GMAC) */
+	unsigned int csum;	/* Checksum Offload */
 	struct mac_link_t link;
 	struct mii_regs_t mii;
 };
diff -uprN linux.orig/drivers/net/stmmac/descs.h linux/drivers/net/stmmac/descs.h
--- linux.orig/drivers/net/stmmac/descs.h	1970-01-01 01:00:00.000000000 +0100
+++ linux/drivers/net/stmmac/descs.h	2008-03-14 08:22:37.759999000 +0100
@@ -0,0 +1,142 @@
+struct dma_desc_t {
+	/* Receive descriptor */
+	union {
+		struct {
+			/* RDES0 */
+			u32 reserved1:1;
+			u32 crc_error:1;
+			u32 dribbling:1;
+			u32 mii_error:1;
+			u32 receive_watchdog:1;
+			u32 frame_type:1;
+			u32 collision:1;
+			u32 frame_too_long:1;
+			u32 last_descriptor:1;
+			u32 first_descriptor:1;
+			u32 multicast_frame:1;
+			u32 run_frame:1;
+			u32 length_error:1;
+			u32 partial_frame_error:1;
+			u32 descriptor_error:1;
+			u32 error_summary:1;
+			u32 frame_length:14;
+			u32 filtering_fail:1;
+			u32 own:1;
+			/* RDES1 */
+			u32 buffer1_size:11;
+			u32 buffer2_size:11;
+			u32 reserved2:2;
+			u32 second_address_chained:1;
+			u32 end_ring:1;
+			u32 reserved3:5;
+			u32 disable_ic:1;
+		} rx;
+		struct {
+			/* RDES0 */
+			u32 payload_csum_error:1;
+			u32 crc_error:1;
+			u32 dribbling:1;
+			u32 error_gmii:1;
+			u32 receive_watchdog:1;
+			u32 frame_type:1;
+			u32 late_collision:1;
+			u32 ipc_csum_error:1;
+			u32 last_descriptor:1;
+			u32 first_descriptor:1;
+			u32 vlan_tag:1;
+			u32 overflow_error:1;
+			u32 length_error:1;
+			u32 source_filter_fail:1;
+			u32 descriptor_error:1;
+			u32 error_summary:1;
+			u32 frame_length:14;
+			u32 filtering_fail:1;
+			u32 own:1;
+			/* RDES1 */
+			u32 buffer1_size:13;
+			u32 reserved1:1;
+			u32 second_address_chained:1;
+			u32 end_ring:1;
+			u32 buffer2_size:13;
+			u32 reserved2:2;
+			u32 disable_ic:1;
+		} erx;		/* -- enhanced -- */
+
+		/* Transmit descriptor */
+		struct {
+			/* TDES0 */
+			u32 deferred:1;
+			u32 underflow_error:1;
+			u32 excessive_deferral:1;
+			u32 collision_count:4;
+			u32 heartbeat_fail:1;
+			u32 excessive_collisions:1;
+			u32 late_collision:1;
+			u32 no_carrier:1;
+			u32 loss_carrier:1;
+			u32 reserved1:3;
+			u32 error_summary:1;
+			u32 reserved2:15;
+			u32 own:1;
+			/* TDES1 */
+			u32 buffer1_size:11;
+			u32 buffer2_size:11;
+			u32 reserved3:1;
+			u32 disable_padding:1;
+			u32 second_address_chained:1;
+			u32 end_ring:1;
+			u32 crc_disable:1;
+			u32 reserved4:2;
+			u32 first_segment:1;
+			u32 last_segment:1;
+			u32 interrupt:1;
+		} tx;
+		struct {
+			/* TDES0 */
+			u32 deferred:1;
+			u32 underflow_error:1;
+			u32 excessive_deferral:1;
+			u32 collision_count:4;
+			u32 vlan_frame:1;
+			u32 excessive_collisions:1;
+			u32 late_collision:1;
+			u32 no_carrier:1;
+			u32 loss_carrier:1;
+			u32 payload_error:1;
+			u32 frame_flushed:1;
+			u32 jabber_timeout:1;
+			u32 error_summary:1;
+			u32 ip_header_error:1;
+			u32 time_stamp_status:1;
+			u32 reserved1:2;
+			u32 second_address_chained:1;
+			u32 end_ring:1;
+			u32 checksum_insertion:2;
+			u32 reserved2:1;
+			u32 time_stamp_enable:1;
+			u32 disable_padding:1;
+			u32 crc_disable:1;
+			u32 first_segment:1;
+			u32 last_segment:1;
+			u32 interrupt:1;
+			u32 own:1;
+			/* TDES1 */
+			u32 buffer1_size:13;
+			u32 reserved3:3;
+			u32 buffer2_size:13;
+			u32 reserved4:3;
+		} etx;		/* -- enhanced -- */
+	} des01;
+	unsigned int des2;
+	unsigned int des3;
+};
+
+typedef struct dma_desc_t dma_desc;
+
+/* Transmit checksum insertion control */
+enum tdes_csum_insertion {
+	cic_disabled = 0,	/* Checksum Insertion Control */
+	cic_only_ip = 1,	/* Only IP header */
+	cic_no_pseudoheader = 2,	/* IP header but pseudoheader is not calculated */
+	cic_full = 3,		/* IP header and pseudoheader */
+};
diff -uprN linux.orig/drivers/net/stmmac/gmac.c linux/drivers/net/stmmac/gmac.c
--- linux.orig/drivers/net/stmmac/gmac.c	2008-03-07 14:51:51.000000000 +0100
+++ linux/drivers/net/stmmac/gmac.c	2008-03-18 08:25:19.459999000 +0100
@@ -23,7 +23,15 @@
 #include "common.h"
 #include "gmac.h"
 
-static void gmac_mac_registers(unsigned long ioaddr)
+#undef GMAC_DEBUG
+/*#define GMAC_DEBUG*/
+#ifdef GMAC_DEBUG
+#define DBG(fmt,args...)  printk(fmt, ## args)
+#else
+#define DBG(fmt, args...)  do { } while(0)
+#endif
+
+static void gmac_dump_regs(unsigned long ioaddr)
 {
 	int i;
 	printk("\t----------------------------------------------\n"
@@ -41,149 +49,257 @@ static void gmac_mac_registers(unsigned 
 	return;
 }
 
-static void gmac_dma_ttc(unsigned long ioaddr, int value)
+static int gmac_dma_init(unsigned long ioaddr, int pbl, u32 dma_tx, u32 dma_rx)
+{
+	unsigned int value;
+
+	/* DMA SW reset */
+	value = (unsigned int)readl(ioaddr + DMA_BUS_MODE);
+	value |= DMA_BUS_MODE_SFT_RESET;
+	writel(value, ioaddr + DMA_BUS_MODE);
+	while ((readl(ioaddr + DMA_BUS_MODE) & DMA_BUS_MODE_SFT_RESET)) {
+	}
+
+	/* Enable Application Access by writing to DMA CSR0 */
+	value = DMA_BUS_MODE_4PBL | ((pbl << DMA_BUS_MODE_PBL_SHIFT) |
+				     (pbl << DMA_BUS_MODE_RPBL_SHIFT));
+
+#ifdef CONFIG_STMMAC_DA
+	value |= DMA_BUS_MODE_DA;	/* Rx has priority over tx */
+#endif
+	writel(value, ioaddr + DMA_BUS_MODE);
+
+	/* Mask interrupts by writing to CSR7 */
+	writel(DMA_INTR_DEFAULT_MASK, ioaddr + DMA_INTR_ENA);
+
+	/* The base address of the RX/TX descriptor lists must be written into
+	 * DMA CSR3 and CSR4, respectively. */
+	writel(dma_tx, ioaddr + DMA_TX_BASE_ADDR);
+	writel(dma_rx, ioaddr + DMA_RCV_BASE_ADDR);
+
+	return 0;
+}
+
+/* Transmit FIFO flush operation */
+static void gmac_flush_tx_fifo(unsigned long ioaddr)
 {
 	unsigned int csr6;
-	/* Store and Forward capability is not used.
-	 * The transmit threshold can be programmed by
-	 * setting the TTC bits in the DMA control register.*/
+
 	csr6 = (unsigned int)readl(ioaddr + DMA_CONTROL);
+	writel((csr6 | DMA_CONTROL_FTF), ioaddr + DMA_CONTROL);
+
+	while ((readl(ioaddr + DMA_CONTROL) & DMA_CONTROL_FTF)) {
+	}
+}
 
-	if (value <= 32)
+static void gmac_dma_operation_mode(unsigned long ioaddr, int threshold)
+{
+	unsigned int csr6;
+
+	csr6 = (unsigned int)readl(ioaddr + DMA_CONTROL);
+
+#ifdef GMAC_TX_STORE_AND_FORWARD
+	csr6 |= DMA_CONTROL_TSF;
+#else
+	if (threshold <= 32)
 		csr6 |= DMA_CONTROL_TTC_32;
-	else if (value <= 64)
+	else if (threshold <= 64)
 		csr6 |= DMA_CONTROL_TTC_64;
-	else if (value <= 128)
+	else if (threshold <= 128)
 		csr6 |= DMA_CONTROL_TTC_128;
-	else if (value <= 192)
+	else if (threshold <= 192)
 		csr6 |= DMA_CONTROL_TTC_192;
 	else
 		csr6 |= DMA_CONTROL_TTC_256;
+#endif
 
-	writel(csr6, ioaddr + DMA_CONTROL);
+#ifdef GMAC_RX_STORE_AND_FORWARD
+	csr6 |= DMA_CONTROL_RSF;
+#else
+	if (threshold <= 32)
+		csr6 |= DMA_CONTROL_RTC_32;
+	else if (threshold <= 64)
+		csr6 |= DMA_CONTROL_RTC_64;
+	else if (threshold <= 96)
+		csr6 |= DMA_CONTROL_RTC_96;
+	else
+		csr6 |= DMA_CONTROL_RTC_128;
+#endif
+	/* Operating on second frame increase the performance 
+	 * especially when transmit store-and-forward is used.*/
+	csr6 |= DMA_CONTROL_OSF;
 
+	writel(csr6, ioaddr + DMA_CONTROL);
 	return;
+}
 
-
+/* Not yet implemented --- RMON */
+static void gmac_dma_diagnostic_fr(void *data, struct stmmac_extra_stats *x,
+				   unsigned long ioaddr)
+{
 	return;
 }
 
-static void gmac_dma_registers(unsigned long ioaddr)
+static void gmac_dump_dma_regs(unsigned long ioaddr)
 {
 	int i;
 	printk(KERN_INFO " DMA registers\n");
 	for (i = 0; i < 9; i++) {
 		if ((i < 9) || (i > 17)) {
 			int offset = i * 4;
-			printk(KERN_INFO "\t Reg No. %d (offset 0x%x): 0x%08x\n", 
-				i, (DMA_BUS_MODE + offset),
+			printk(KERN_INFO
+			       "\t Reg No. %d (offset 0x%x): 0x%08x\n", i,
+			       (DMA_BUS_MODE + offset),
 			       readl(ioaddr + DMA_BUS_MODE + offset));
 		}
 	}
 	return;
 }
 
-static int gmac_tx_hw_error(void *p, struct stmmac_extra_stats *x,
-			unsigned int status)
+static int gmac_get_tx_frame_status(void *data, struct stmmac_extra_stats *x,
+				    dma_desc * p, unsigned long ioaddr)
 {
 	int ret = 0;
-	struct net_device_stats *stats = (struct net_device_stats *)p;
+	struct net_device_stats *stats = (struct net_device_stats *)data;
 
-	if (unlikely(status & TDES0_STATUS_DF)) {
-		x->tx_deferred++;
-		ret = -1;
-	}
-	if (unlikely(status & TDES0_STATUS_VLAN)) {
-		x->tx_vlan++;
-		ret = -1;
-	}
-	if (unlikely(status & TDES0_STATUS_ES)) {
-		if (unlikely(status & TDES0_STATUS_JT))
+	if (unlikely(p->des01.etx.error_summary)) {
+
+		if (unlikely(p->des01.etx.jabber_timeout)) {
+			DBG(KERN_ERR "GMAC TX: jabber_timeout error\n");
 			x->tx_jabber++;
-		if (unlikely(status & TDES0_STATUS_FF))
+		}
+
+		if (unlikely(p->des01.etx.frame_flushed)) {
+			DBG(KERN_ERR "GMAC TX: frame_flushed error\n");
 			x->tx_frame_flushed++;
-		if (unlikely(status & TDES0_STATUS_LOSS_CARRIER))
+			gmac_flush_tx_fifo(ioaddr);
+		}
+
+		if (unlikely(p->des01.etx.loss_carrier)) {
+			DBG(KERN_ERR "GMAC TX: loss_carrier error\n");
 			x->tx_losscarrier++;
-		if (status & TDES0_STATUS_NO_CARRIER)
+			stats->tx_carrier_errors++;
+		}
+		if (unlikely(p->des01.etx.no_carrier)) {
+			DBG(KERN_ERR "GMAC TX: no_carrier error\n");
 			x->tx_carrier++;
-		if (status & TDES0_STATUS_LATE_COL) {
-			stats->collisions +=
-			    ((status & TDES0_STATUS_COLCNT_MASK) >>
-			     TDES0_STATUS_COLCNT_SHIFT);
-		}
-		if (status & TDES0_STATUS_EX_COL) {
-			stats->collisions +=
-			    ((status & TDES0_STATUS_COLCNT_MASK) >>
-			     TDES0_STATUS_COLCNT_SHIFT);
+			stats->tx_carrier_errors++;
 		}
-		if (status & TDES0_STATUS_EX_DEF)
+		if (unlikely(p->des01.etx.late_collision)) {
+			DBG(KERN_ERR "GMAC TX: late_collision error\n");
+			stats->collisions += p->des01.etx.collision_count;
+		}
+		if (unlikely(p->des01.etx.excessive_collisions)) {
+			DBG(KERN_ERR "GMAC TX: excessive_collisions\n");
+			stats->collisions += p->des01.etx.collision_count;
+		}
+		if (unlikely(p->des01.etx.excessive_deferral))
 			x->tx_deferred++;
-		if (status & TDES0_STATUS_UF)
+
+		if (unlikely(p->des01.etx.underflow_error)) {
+			DBG(KERN_ERR "GMAC TX: underflow error\n");
+			gmac_flush_tx_fifo(ioaddr);
 			x->tx_underflow++;
+		}
+
+		if (unlikely(p->des01.etx.payload_error)) {
+			DBG(KERN_ERR "%s: TX Addr/Payload csum error\n",
+			    __FUNCTION__);
+			x->tx_payload_error++;
+			gmac_flush_tx_fifo(ioaddr);
+		}
+
+		if (unlikely(p->des01.etx.ip_header_error)) {
+			DBG(KERN_ERR "%s: TX IP header csum error\n",
+			    __FUNCTION__);
+			x->tx_ip_header_error++;
+		}
+
+		ret = -1;
+	}
+
+	if (unlikely(p->des01.etx.deferred)) {
+		x->tx_deferred++;
 		ret = -1;
 	}
+	if (p->des01.etx.vlan_frame) {
+		DBG(KERN_INFO "GMAC TX: VLAN frame\n");
+		x->tx_vlan++;
+	}
 
 	return (ret);
 }
 
-static int gmac_rx_hw_error(void *p, struct stmmac_extra_stats *x,
-			    unsigned int status)
+static int gmac_get_rx_frame_status(void *data, struct stmmac_extra_stats *x,
+				    dma_desc * p)
 {
 	int ret = 0;
-	struct net_device_stats *stats = (struct net_device_stats *)p;
+	struct net_device_stats *stats = (struct net_device_stats *)data;
 
-	if (unlikely(status & RDES0_STATUS_DE)){
-		x->rx_desc++;
-		ret = -1;
-	}
-	if (unlikely(status & RDES0_STATUS_OE)){
-		x->rx_overflow++;
-		ret = -1;
-	}
-	if (unlikely(status & RDES0_STATUS_LC)) {
-		stats->collisions++;
-		ret = -1;
-	}
-	if (unlikely(status & RDES0_STATUS_RWT)) {
-		x->rx_watchdog++;
+	if (unlikely(p->des01.erx.error_summary)) {
+		if (unlikely(p->des01.erx.descriptor_error)) {
+			/* frame doesn't fit within the current descriptor. */
+			DBG(KERN_ERR "GMAC RX: descriptor error\n");
+			x->rx_desc++;
+			stats->rx_length_errors++;
+		}
+		if (unlikely(p->des01.erx.overflow_error)) {
+			DBG(KERN_ERR "GMAC RX: Overflow error\n");
+			x->rx_gmac_overflow++;
+		}
+		if (unlikely(p->des01.erx.late_collision)) {
+			DBG(KERN_ERR "GMAC RX: late_collision\n");
+			stats->collisions++;
+			stats->collisions++;
+		}
+		if (unlikely(p->des01.erx.receive_watchdog)) {
+			DBG(KERN_ERR "GMAC RX: receive_watchdog error\n");
+			x->rx_watchdog++;
+		}
+		if (unlikely(p->des01.erx.error_gmii)) {
+			DBG(KERN_ERR "GMAC RX: GMII error\n");
+			x->rx_mii++;
+		}
+		if (unlikely(p->des01.erx.crc_error)) {
+			DBG(KERN_ERR "GMAC RX: CRC error\n");
+			x->rx_crc++;
+			stats->rx_crc_errors++;
+		}
 		ret = -1;
 	}
-	if (unlikely(status & RDES0_STATUS_RE)) {
-		x->rx_mii++;
+
+	if (unlikely(p->des01.erx.dribbling)) {
+		DBG(KERN_ERR "GMAC RX:  dribbling error\n");
 		ret = -1;
 	}
-	if (unlikely(status & RDES0_STATUS_CE)) {
-		x->rx_crc++;
-		stats->rx_crc_errors++;
-	}
-
-	if (unlikely(status & RDES0_STATUS_FILTER_FAIL)) {
+	if (unlikely(p->des01.erx.filtering_fail)) {
+		DBG(KERN_ERR "GMAC RX: filtering_fail error\n");
 		x->rx_filter++;
 		ret = -1;
 	}
-	if (unlikely(status & RDES0_STATUS_LENGTH_ERROR)) {
+	if (unlikely(p->des01.erx.length_error)) {
+		DBG(KERN_ERR "GMAC RX: length_error error\n");
 		x->rx_lenght++;
 		ret = -1;
 	}
 	return (ret);
 }
 
-static void gmac_tx_checksum(struct sk_buff *skb)
+static int gmac_rx_checksum(dma_desc * p)
 {
-	return;
-}
+	int ret = 0;
+	/* Full COE type 2 is supported */
+	if (unlikely((p->des01.erx.ipc_csum_error == 1)) ||
+	    (p->des01.erx.payload_csum_error == 1)) {
+
+		if (p->des01.erx.payload_csum_error)
+			DBG(KERN_WARNING "%s: IPC csum error\n", __FUNCTION__);
+		if (p->des01.erx.payload_csum_error)
+			DBG(KERN_WARNING "(Address/Payload csum error.)\n");
 
-static void gmac_rx_checksum(struct sk_buff *skb, int status)
-{
-	/* IPC verification (To be reviewed)*/
-	if (unlikely(status & RDES0_STATUS_IPC)) {
-		/* Packet with erroneous checksum, so let the
-		 * upper layers deal with it.  */
-		skb->ip_summed = CHECKSUM_NONE;
-	} else {
-		skb->ip_summed = CHECKSUM_UNNECESSARY;
+		ret = -1;
 	}
-	return;
+	return ret;
 }
 
 static void gmac_core_init(unsigned long ioaddr)
@@ -198,6 +314,7 @@ static void gmac_core_init(unsigned long
 #if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)
 	writel(ETH_P_8021Q, ioaddr + GMAC_VLAN);
 #endif
+
 	return;
 }
 
@@ -210,7 +327,7 @@ static void gmac_set_filter(struct net_d
 		value = GMAC_FRAME_FILTER_PR;
 	} else if ((dev->mc_count > HASH_TABLE_SIZE)
 		   || (dev->flags & IFF_ALLMULTI)) {
-		value = GMAC_FRAME_FILTER_PM; /// pass all multi
+		value = GMAC_FRAME_FILTER_PM;	/// pass all multi
 		writel(0xffffffff, ioaddr + GMAC_HASH_HIGH);
 		writel(0xffffffff, ioaddr + GMAC_HASH_LOW);
 	} else if (dev->mc_count == 0) {
@@ -242,10 +359,10 @@ static void gmac_set_filter(struct net_d
 
 	writel(value, ioaddr + GMAC_FRAME_FILTER);
 
-	printk(KERN_DEBUG "%s: GMAC frame filter reg: 0x%08x - Hash regs: "
-		"HI 0x%08x, LO 0x%08x\n",
-		__FUNCTION__, readl(ioaddr + GMAC_FRAME_FILTER),
-		readl(ioaddr + GMAC_HASH_HIGH), readl(ioaddr + GMAC_HASH_LOW));
+	DBG(KERN_INFO "%s: GMAC frame filter reg: 0x%08x - Hash regs: "
+	    "HI 0x%08x, LO 0x%08x\n",
+	    __FUNCTION__, readl(ioaddr + GMAC_FRAME_FILTER),
+	    readl(ioaddr + GMAC_HASH_HIGH), readl(ioaddr + GMAC_HASH_LOW));
 	return;
 }
 
@@ -254,41 +371,154 @@ static void gmac_flow_ctrl(unsigned long
 {
 	unsigned int flow = 0;
 
-	if (fc & FLOW_RX)
+	DBG(KERN_DEBUG "GMAC Flow-Control:\n");
+	if (fc & FLOW_RX) {
+		DBG(KERN_DEBUG "\tReceive Flow-Control ON\n");
 		flow |= GMAC_FLOW_CTRL_RFE;
-	if (fc & FLOW_TX)
+	}
+	if (fc & FLOW_TX) {
+		DBG(KERN_DEBUG "\tTransmit Flow-Control ON\n");
 		flow |= GMAC_FLOW_CTRL_TFE;
+	}
 
-	if (duplex)
+	if (duplex) {
+		DBG(KERN_DEBUG "\tduplex mode: pause time: %d\n", pause_time);
 		flow |= (pause_time << GMAC_FLOW_CTRL_PT_SHIFT);
+	}
+
 	writel(flow, ioaddr + GMAC_FLOW_CTRL);
 	return;
 }
 
-static void gmac_enable_wol(unsigned long ioaddr, unsigned long mode)
+static void gmac_pmt(unsigned long ioaddr, unsigned long mode)
+{
+	unsigned int pmt = power_down;
+
+	if (mode == WAKE_MAGIC) {
+		pmt |= magic_pkt_en;
+	} else if (mode == WAKE_UCAST) {
+		pmt |= global_unicast;
+	}
+
+	writel(pmt, ioaddr + GMAC_PMT);
+	return;
+}
+
+static void gmac_init_rx_desc(dma_desc * p, unsigned int ring_size,
+			      int rx_irq_threshold)
+{
+	int i;
+	for (i = 0; i < ring_size; i++) {
+		p->des01.erx.own = 1;
+		p->des01.erx.buffer1_size = DMA_BUFFER_SIZE - 1;
+		if (i % rx_irq_threshold)
+			p->des01.erx.disable_ic = 1;
+		if (i == ring_size - 1)
+			p->des01.erx.end_ring = 1;
+		p++;
+	}
+	return;
+}
+
+static void gmac_init_tx_desc(dma_desc * p, unsigned int ring_size)
+{
+	int i;
+
+	for (i = 0; i < ring_size; i++) {
+		p->des01.etx.own = 0;
+		if (i == ring_size - 1)
+			p->des01.etx.end_ring = 1;
+		p++;
+	}
+
+	return;
+}
+
+static int gmac_read_tx_owner(dma_desc * p)
 {
-	/* To be reviewed! */
-	unsigned int pmt = 0x1; /* PWR_DOWN bit */
+	return p->des01.etx.own;
+}
+
+static int gmac_read_rx_owner(dma_desc * p)
+{
+	return p->des01.erx.own;
+}
 
-	if (mode == WAKE_MAGIC)
-		pmt |= 0x2;
+static void gmac_set_tx_owner(dma_desc * p)
+{
+	p->des01.etx.own = 1;
+}
+
+static void gmac_set_rx_owner(dma_desc * p)
+{
+	p->des01.erx.own = 1;
+}
+
+static int gmac_get_tx_ls(dma_desc * p)
+{
+	return p->des01.etx.last_segment;
+}
+
+static void gmac_release_tx_desc(dma_desc * p)
+{
+	int ter = p->des01.etx.end_ring;
+
+	memset(p, 0, sizeof(dma_desc));
+	p->des01.etx.end_ring = ter;
 
-	writel(pmt, ioaddr + MAC_PMT);
 	return;
 }
 
+static void gmac_prepare_tx_desc(dma_desc * p, int is_fs, int len,
+				 unsigned int csum_flags)
+{
+	p->des01.etx.first_segment = is_fs;
+	p->des01.etx.buffer1_size = len;
+	if (csum_flags)
+		p->des01.etx.checksum_insertion = cic_full;
+	/*p->des01.etx.checksum_insertion = cic_no_pseudoheader; */
+}
+
+static void gmac_set_tx_ic(dma_desc * p, int value)
+{
+	p->des01.etx.interrupt = value;
+}
+
+static void gmac_set_tx_ls(dma_desc * p)
+{
+	p->des01.etx.last_segment = 1;
+}
+
+static int gmac_get_rx_frame_len(dma_desc * p)
+{
+	return p->des01.erx.frame_length;
+}
+
 struct device_ops gmac_driver = {
 	.core_init = gmac_core_init,
-	.mac_registers = gmac_mac_registers,
-	.dma_registers = gmac_dma_registers,
-	.dma_ttc = gmac_dma_ttc,
-	.tx_err = gmac_tx_hw_error,
-	.rx_err = gmac_rx_hw_error,
-	.tx_checksum = gmac_tx_checksum,
+	.dump_mac_regs = gmac_dump_regs,
+	.dma_init = gmac_dma_init,
+	.dump_dma_regs = gmac_dump_dma_regs,
+	.dma_operation_mode = gmac_dma_operation_mode,
+	.dma_diagnostic_fr = gmac_dma_diagnostic_fr,
+	.tx_status = gmac_get_tx_frame_status,
+	.rx_status = gmac_get_rx_frame_status,
 	.rx_checksum = gmac_rx_checksum,
 	.set_filter = gmac_set_filter,
 	.flow_ctrl = gmac_flow_ctrl,
-	.enable_wol = gmac_enable_wol,
+	.pmt = gmac_pmt,
+	.init_rx_desc = gmac_init_rx_desc,
+	.init_tx_desc = gmac_init_tx_desc,
+	.read_tx_owner = gmac_read_tx_owner,
+	.read_rx_owner = gmac_read_rx_owner,
+	.release_tx_desc = gmac_release_tx_desc,
+	.prepare_tx_desc = gmac_prepare_tx_desc,
+	.set_tx_ic = gmac_set_tx_ic,
+	.set_tx_ls = gmac_set_tx_ls,
+	.get_tx_ls = gmac_get_tx_ls,
+	.set_tx_owner = gmac_set_tx_owner,
+	.set_rx_owner = gmac_set_rx_owner,
+	.get_rx_frame_len = gmac_get_rx_frame_len,
 };
 
 struct device_info_t *gmac_setup(unsigned long ioaddr)
@@ -298,13 +528,18 @@ struct device_info_t *gmac_setup(unsigne
 	id = (unsigned int)readl(ioaddr + GMAC_VERSION);
 
 	printk(KERN_INFO "\tGMAC - user ID: 0x%x, Synopsys ID: 0x%x\n",
-		((id & 0x0000ff00)>>8), (id & 0x000000ff));
+	       ((id & 0x0000ff00) >> 8), (id & 0x000000ff));
 
 	mac = kmalloc(sizeof(const struct device_info_t), GFP_KERNEL);
 	memset(mac, 0, sizeof(struct device_info_t));
 
 	mac->ops = &gmac_driver;
 	mac->hw.pmt = PMT_SUPPORTED;
+#ifdef GMAC_TX_STORE_AND_FORWARD
+	mac->hw.csum = HAS_HW_CSUM;
+#else
+	mac->hw.csum = NO_HW_CSUM;
+#endif
 	mac->hw.addr_high = GMAC_ADDR_HIGH;
 	mac->hw.addr_low = GMAC_ADDR_LOW;
 	mac->hw.link.port = GMAC_CONTROL_PS;
diff -uprN linux.orig/drivers/net/stmmac/gmac.h linux/drivers/net/stmmac/gmac.h
--- linux.orig/drivers/net/stmmac/gmac.h	2008-03-07 14:51:51.000000000 +0100
+++ linux/drivers/net/stmmac/gmac.h	2008-03-14 08:22:37.809998000 +0100
@@ -15,9 +15,22 @@
 
 /* GMAC ID */
 #define GMAC_VERSION	0x00000020	/* GMAC CORE Version */
+#define GMAC_INT_STATUS	0x00000038	/* interrupt status register */
+#define GMAC_INT_MASK	0x0000003c	/* interrupt status register */
 
-#define GMAC_INT_STATUS	0x00000038 /* interrupt status register */
-#define GMAC_INT_MASK	0x0000003c /* interrupt status register */
+#define GMAC_WAKEUP_FILTER       0x00000028      /* Wake-up Frame Filter */
+
+/* PMT Control and Statu */
+#define GMAC_PMT                 0x0000002c
+enum power_event{
+	pointer_reset  = 0x80000000,
+	global_unicast = 0x00000200,
+	wake_up_rx_frame  = 0x00000040,
+	magic_frame    = 0x00000020,
+	wake_up_frame_en = 0x00000004,
+	magic_pkt_en	 = 0x00000002,
+	power_down	 = 0x00000001,
+};
 
 /* GMAC HW ADDR regs */
 #define GMAC_ADDR_HIGH	0x00000040	/* Mac Address 0 HI */
@@ -32,14 +45,19 @@
 #define GMAC_ANE_EXP	0x000000d0	/* ANE expansion */
 #define GMAC_TBI	0x000000d4	/* TBI extend status */
 #define GMAC_GMII_STATUS 0x000000d8	/* S/R-GMII status */
+
 /* GMAC Configuration defines */
-#define GMAC_CONTROL_WD	0x00800000	/* Disable Watchdog */
+#define GMAC_CONTROL_TC	0x01000000	/* Transmit Conf. in RGMII/SGMII */
+#define GMAC_CONTROL_WD	0x00800000	/* Disable Watchdog on receive */
 #define GMAC_CONTROL_JD	0x00400000	/* Jabber disable */
 #define GMAC_CONTROL_BE	0x00200000	/* Frame Burst Enable */
 #define GMAC_CONTROL_JE	0x00100000	/* Jumbo frame */
-#define GMAC_CONTROL_IFG_88	0x00040000
-#define GMAC_CONTROL_IFG_80	0x00020000
-#define GMAC_CONTROL_IFG_40	0x000e0000
+enum inter_frame_gap {
+	GMAC_CONTROL_IFG_88 = 0x00040000,
+	GMAC_CONTROL_IFG_80 = 0x00020000,
+	GMAC_CONTROL_IFG_40 = 0x000e0000,
+};
+#define GMAC_CONTROL_DCRS	0x00010000	/* Disable carrier sense during tx */
 #define GMAC_CONTROL_PS		0x00008000	/* Port Select 0:GMI 1:MII */
 #define GMAC_CONTROL_FES	0x00004000	/* Speed 0:10 1:100 */
 #define GMAC_CONTROL_DO		0x00002000	/* Disable Rx Own */
@@ -53,16 +71,16 @@
 #define GMAC_CONTROL_TE		0x00000008	/* Transmitter Enable */
 #define GMAC_CONTROL_RE		0x00000004	/* Receiver Enable */
 
-#define GMAC_CORE_INIT (GMAC_CONTROL_PS | GMAC_CONTROL_ACS | GMAC_CONTROL_IPC)
+#define GMAC_CORE_INIT (GMAC_CONTROL_JD | GMAC_CONTROL_PS | GMAC_CONTROL_ACS | GMAC_CONTROL_IPC)
 
 /* GMAC Frame Filter defines */
 #define GMAC_FRAME_FILTER_PR	0x00000001	/* Promiscuous Mode */
-#define GMAC_FRAME_FILTER_HUC	0x00000002	/*Hash Unicast */
-#define GMAC_FRAME_FILTER_HMC	0x00000004	/*Hash Multicast */
-#define GMAC_FRAME_FILTER_DAIF	0x00000008	/*DA Inverse Filtering */
-#define GMAC_FRAME_FILTER_PM	0x00000010	/*Pass all multicast */
-#define GMAC_FRAME_FILTER_DBF	0x00000020	/*Disable Broadcast frames */
-#define GMAC_FRAME_FILTER_RA	0x80000000	/*Receive all mode */
+#define GMAC_FRAME_FILTER_HUC	0x00000002	/* Hash Unicast */
+#define GMAC_FRAME_FILTER_HMC	0x00000004	/* Hash Multicast */
+#define GMAC_FRAME_FILTER_DAIF	0x00000008	/* DA Inverse Filtering */
+#define GMAC_FRAME_FILTER_PM	0x00000010	/* Pass all multicast */
+#define GMAC_FRAME_FILTER_DBF	0x00000020	/* Disable Broadcast frames */
+#define GMAC_FRAME_FILTER_RA	0x80000000	/* Receive all mode */
 /* GMII ADDR  defines */
 #define GMAC_MII_ADDR_WRITE	0x00000002	/* MII Write */
 #define GMAC_MII_ADDR_BUSY	0x00000001	/* MII Busy */
@@ -74,6 +92,28 @@
 #define GMAC_FLOW_CTRL_FCB_BPA	0x00000001	/* Flow Control Busy ... */
 
 /*--- DMA BLOCK defines ---*/
+/* DMA Bus Mode register defines */
+#define DMA_BUS_MODE_SFT_RESET	0x00000001	/* Software Reset */
+#define DMA_BUS_MODE_DA		0x00000002	/* Arbitration scheme */
+#define DMA_BUS_MODE_DSL_MASK	0x0000007c	/* Descriptor Skip Length */
+#define DMA_BUS_MODE_DSL_SHIFT	2	/*   (in DWORDS)      */
+/* Programmable burst length (passed thorugh platform)*/
+#define DMA_BUS_MODE_PBL_MASK	0x00003f00	/* Programmable Burst Len */
+#define DMA_BUS_MODE_PBL_SHIFT	8
+
+enum rx_tx_priority_ratio {
+	double_ratio = 0x00004000,	/*2:1 */
+	triple_ratio = 0x00008000,	/*3:1 */
+	quadruple_ratio = 0x0000c000,	/*4:1 */
+};
+
+#define DMA_BUS_MODE_FB	0x00010000	/*Fixed burst */
+#define DMA_BUS_MODE_RPBL_MASK	0x003e0000	/* Rx-Programmable Burst Len */
+#define DMA_BUS_MODE_RPBL_SHIFT	17
+#define DMA_BUS_MODE_USP	0x00800000
+#define DMA_BUS_MODE_4PBL	0x01000000
+#define DMA_BUS_MODE_AAL	0x02000000
+
 /* DMA CRS Control and Status Register Mapping */
 #define DMA_HOST_TX_DESC	  0x00001048	/* Current Host Tx descriptor */
 #define DMA_HOST_RX_DESC	  0x0000104c	/* Current Host Rx descriptor */
@@ -87,48 +127,53 @@
 #define DMA_STATUS_GMI		0x08000000	/* MMC interrupt */
 #define DMA_STATUS_GLI		0x04000000	/* GMAC Line interface interrupt */
 
-/* DMA operation mode defines */
-#define DMA_CONTROL_SF		0x00200000	/* Store And Forward */
+/* DMA operation mode defines (start/stop tx/rx are placed in common header)*/
+#define DMA_CONTROL_DT		0x04000000	/* Disable Drop TCP/IP csum error */
+#define DMA_CONTROL_RSF		0x02000000	/* Receive Store and Forward */
+#define DMA_CONTROL_DFF		0x01000000	/* Disaable flushing */
+/* Theshold for Activating the FC */
+enum rfa {
+	act_full_minus_1 = 0x00800000,
+	act_full_minus_2 = 0x00800200,
+	act_full_minus_3 = 0x00800400,
+	act_full_minus_4 = 0x00800600,
+};
+/* Theshold for Deactivating the FC */
+enum rfd {
+	deac_full_minus_1 = 0x00400000,
+	deac_full_minus_2 = 0x00400800,
+	deac_full_minus_3 = 0x00401000,
+	deac_full_minus_4 = 0x00401800,
+};
+#define DMA_CONTROL_TSF		0x00200000	/* Transmit  Store and Forward */
 #define DMA_CONTROL_FTF		0x00100000	/* Flush transmit FIFO */
-#define DMA_CONTROL_TTC_MASK	0x0001c000	/* Transmit Threshold Control */
-#define DMA_CONTROL_TTC_64	0x00000000
-#define DMA_CONTROL_TTC_128	0x00040000
-#define DMA_CONTROL_TTC_192	0x00080000
-#define DMA_CONTROL_TTC_256	0x000c0000
-#define DMA_CONTROL_TTC_40	0x00100000
-#define DMA_CONTROL_TTC_32	0x00140000
-#define DMA_CONTROL_TTC_24	0x00180000
-#define DMA_CONTROL_TTC_16	0x001c0000
-
-/* --- Descriptor defines --- */
-/* Receive Descriptor 0*/
-#define RDES0_STATUS_FILTER_FAIL  0x40000000	/* DA Filtering Fails */
-#define RDES0_STATUS_FL_MASK      0x3fff0000	/* Frame Length Mask */
-#define RDES0_STATUS_FL_SHIFT     16	/* Frame Length Shift */
-#define RDES0_STATUS_DE		0x00004000	/* Descriptor Error */
-#define RDES0_STATUS_SAF	0x00002000	/* Source Address filter Fail */
-#define RDES0_STATUS_LENGTH_ERROR 0x00001000	/* Length Error */
-#define RDES0_STATUS_OE		0x00000800	/* Overflow Error */
-#define RDES0_STATUS_VLAN	0x00000400	/* VLAN tag */
-#define RDES0_STATUS_IPC	0x00000080	/* Checksum Error */
-#define RDES0_STATUS_LC		0x00000040	/* Collision Seen */
-#define RDES0_STATUS_FT		0x00000020	/* Frame Type */
-#define RDES0_STATUS_RWT	0x00000010	/* Receive Watchdog */
-#define RDES0_STATUS_RE		0x00000008	/* Receive Error  */
-#define RDES0_STATUS_DRIBBLE	0x00000004	/* Dribbling Bit */
-#define RDES0_STATUS_CE		0x00000002	/* CRC Error */
-#define RDES0_STATUS_RX_GMAC_ADDR 0x00000001	/* RX GMAC ADDR. */
-
-/* Transmit Descriptor */
-#define TDES0_STATUS_JT		  0x00004000	/* jabber timeout */
-#define TDES0_STATUS_FF		  0x00002000	/* frame flushed */
-#define TDES0_STATUS_LOSS_CARRIER 0x00000800	/* Loss of Carrier */
-#define TDES0_STATUS_NO_CARRIER   0x00000400	/* No Carrier */
-#define TDES0_STATUS_LATE_COL     0x00000200	/* Late Collision */
-#define TDES0_STATUS_EX_COL	0x00000100	/* Excessive Collisions */
-#define TDES0_STATUS_VLAN	0x00000080	/* VLAN FRAME */
-#define TDES0_STATUS_COLCNT_MASK  0x00000078	/* Collision Count Mask */
-#define TDES0_STATUS_COLCNT_SHIFT 3	/* Collision Count Shift */
-#define TDES0_STATUS_EX_DEF	0x00000004	/* Excessive Deferrals */
-#define TDES0_STATUS_UF		0x00000002	/* Underflow Error */
-#define TDES0_STATUS_DF		0x00000001	/* Deferred */
+
+enum ttc_control {
+	DMA_CONTROL_TTC_64 = 0x00000000,
+	DMA_CONTROL_TTC_128 = 0x00040000,
+	DMA_CONTROL_TTC_192 = 0x00080000,
+	DMA_CONTROL_TTC_256 = 0x000c0000,
+	DMA_CONTROL_TTC_40 = 0x00100000,
+	DMA_CONTROL_TTC_32 = 0x00140000,
+	DMA_CONTROL_TTC_24 = 0x00180000,
+	DMA_CONTROL_TTC_16 = 0x001c0000,
+};
+
+#define DMA_CONTROL_EFC		0x00000100
+#define DMA_CONTROL_FEF		0x00000080
+#define DMA_CONTROL_FUF		0x00000040
+
+enum rtc_control {
+	DMA_CONTROL_RTC_64 = 0x00000000,
+	DMA_CONTROL_RTC_32 = 0x00000010,
+	DMA_CONTROL_RTC_96 = 0x00000020,
+	DMA_CONTROL_RTC_128 = 0x00000030,
+};
+
+#define DMA_CONTROL_OSF	0x00000004	/* operate on second frame */
+
+/* Transmit COE type 2 cannot be done in cut-through mode */
+#undef GMAC_TX_STORE_AND_FORWARD
+#define GMAC_TX_STORE_AND_FORWARD
+#undef GMAC_RX_STORE_AND_FORWARD
+/*#define GMAC_RX_STORE_AND_FORWARD*/
diff -uprN linux.orig/drivers/net/stmmac/mac100.c linux/drivers/net/stmmac/mac100.c
--- linux.orig/drivers/net/stmmac/mac100.c	2008-03-07 14:51:51.000000000 +0100
+++ linux/drivers/net/stmmac/mac100.c	2008-03-18 08:25:26.270000000 +0100
@@ -7,7 +7,6 @@
  * Copyright (C) 2007 by STMicroelectronics
  * Author: Giuseppe Cavallaro <peppe.cavallaro@st.com>
  *
- *
 */
 #include <linux/module.h>
 #include <linux/kernel.h>
@@ -24,7 +23,25 @@
 #include "common.h"
 #include "mac100.h"
 
-static void mac100_mac_registers(unsigned long ioaddr)
+static void mac100_core_init(unsigned long ioaddr)
+{
+	unsigned int value = 0;
+
+	printk(KERN_DEBUG "mac100_core_init");
+
+	/* Set the MAC control register with our default value */
+	value = (unsigned int)readl(ioaddr + MAC_CONTROL);
+	writel((value | MAC_CORE_INIT), ioaddr + MAC_CONTROL);
+
+#if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)
+	/* VLAN1 Tag identifier register is programmed to 
+	 * the 802.1Q VLAN Extended Header (0x8100). */
+	writel(ETH_P_8021Q, ioaddr + MAC_VLAN1);
+#endif
+	return;
+}
+
+static void mac100_dump_mac_regs(unsigned long ioaddr)
 {
 	printk("\t----------------------------------------------\n"
 	       "\t  MAC100 CSR (base addr = 0x%8x)\n"
@@ -60,33 +77,55 @@ static void mac100_mac_registers(unsigne
 	return;
 }
 
+static int mac100_dma_init(unsigned long ioaddr, int pbl, u32 dma_tx,
+			   u32 dma_rx)
+{
+	unsigned int value;
+
+	printk(KERN_DEBUG "GMAC: DMA Core setup\n");
+
+	/* DMA SW reset */
+	value = (unsigned int)readl(ioaddr + DMA_BUS_MODE);
+	value |= DMA_BUS_MODE_SFT_RESET;
+	writel(value, ioaddr + DMA_BUS_MODE);
+	while ((readl(ioaddr + DMA_BUS_MODE) & DMA_BUS_MODE_SFT_RESET)) {
+	}
+
+	/* Enable Application Access by writing to DMA CSR0 */
+	writel(DMA_BUS_MODE_DEFAULT | (pbl << DMA_BUS_MODE_PBL_SHIFT),
+	       ioaddr + DMA_BUS_MODE);
+
+	/* Mask interrupts by writing to CSR7 */
+	writel(DMA_INTR_DEFAULT_MASK, ioaddr + DMA_INTR_ENA);
+
+	/* The base address of the RX/TX descriptor lists must be written into
+	 * DMA CSR3 and CSR4, respectively. */
+	writel(dma_tx, ioaddr + DMA_TX_BASE_ADDR);
+	writel(dma_rx, ioaddr + DMA_RCV_BASE_ADDR);
+
+	return 0;
+}
+
 /* Store and Forward capability is not used.
  * The transmit threshold can be programmed by
  * setting the TTC bits in the DMA control register.*/
-static void mac100_dma_ttc(unsigned long ioaddr, int value)
+static void mac100_dma_operation_mode(unsigned long ioaddr, int ttc)
 {
-	unsigned int csr6;
-	csr6 = (unsigned int)readl(ioaddr + DMA_CONTROL);
-
-	/* Operating on second frame seems to improve a 
-	 * little bit the performance.
-	csr6 |= DMA_CONTROL_OSF; */ 
+	unsigned int csr6 = (unsigned int)readl(ioaddr + DMA_CONTROL);
 
-	if (value <= 32)
+	if (ttc <= 32)
 		csr6 |= DMA_CONTROL_TTC_32;
-	else if (value <= 64)
+	else if (ttc <= 64)
 		csr6 |= DMA_CONTROL_TTC_64;
-	else if (value <= 128)
-		csr6 |= DMA_CONTROL_TTC_128;
 	else
-		csr6 |= DMA_CONTROL_TTC_256;
+		csr6 |= DMA_CONTROL_TTC_128;
 
 	writel(csr6, ioaddr + DMA_CONTROL);
 
 	return;
 }
 
-static void mac100_dma_registers(unsigned long ioaddr)
+static void mac100_dump_dma_regs(unsigned long ioaddr)
 {
 	int i;
 
@@ -103,39 +142,71 @@ static void mac100_dma_registers(unsigne
 	return;
 }
 
-static int mac100_tx_hw_error(void *p, struct stmmac_extra_stats *x,
-				unsigned int status)
+/* The DMA controller maintains two counters to track the number of
+   the receive missed frames. */
+static void mac100_dma_diagnostic_fr(void *data, struct stmmac_extra_stats *x,
+				     unsigned long ioaddr)
+{
+	unsigned long csr8;
+	struct net_device_stats *stats = (struct net_device_stats *)data;
+
+	csr8 = readl(ioaddr + DMA_MISSED_FRAME_CTR);
+
+	if (unlikely(csr8)) {
+		if (csr8 & DMA_MISSED_FRAME_OVE) {
+			stats->rx_over_errors += 0x800;
+			x->rx_overflow_cntr += 0x800;
+		} else {
+			unsigned int ove_cntr;
+			ove_cntr = ((csr8 & DMA_MISSED_FRAME_OVE_CNTR) >> 17);
+			stats->rx_over_errors += ove_cntr;
+			x->rx_overflow_cntr += ove_cntr;
+		}
+
+		if (csr8 & DMA_MISSED_FRAME_OVE_M) {
+			stats->rx_missed_errors += 0xffff;
+			x->rx_missed_cntr += 0xffff;
+		} else {
+			unsigned int miss_f = (csr8 & DMA_MISSED_FRAME_M_CNTR);
+			stats->rx_missed_errors += miss_f;
+			x->rx_missed_cntr += miss_f;
+		}
+	}
+	return;
+}
+
+static int mac100_get_tx_frame_status(void *data, struct stmmac_extra_stats *x,
+				      dma_desc * p, unsigned long ioaddr)
 {
 	int ret = 0;
-	struct net_device_stats *stats = (struct net_device_stats *)p;
+	struct net_device_stats *stats = (struct net_device_stats *)data;
 
-	if (unlikely(status & TDES0_STATUS_ES)) {
-		if (unlikely(status & TDES0_STATUS_UF)) {
+	if (unlikely(p->des01.tx.error_summary)) {
+		if (unlikely(p->des01.tx.underflow_error)) {
 			x->tx_underflow++;
 			stats->tx_fifo_errors++;
 		}
-		if (unlikely(status & TDES0_STATUS_NO_CARRIER)) {
+		if (unlikely(p->des01.tx.no_carrier)) {
 			x->tx_carrier++;
 			stats->tx_carrier_errors++;
 		}
-		if (unlikely(status & TDES0_STATUS_LOSS_CARRIER)) {
+		if (unlikely(p->des01.tx.loss_carrier)) {
 			x->tx_losscarrier++;
+			stats->tx_carrier_errors++;
 		}
-		if (unlikely((status & TDES0_STATUS_EX_DEF) ||
-		    (status & TDES0_STATUS_EX_COL) ||
-		    (status & TDES0_STATUS_LATE_COL))) {
-			stats->collisions +=
-			    ((status & TDES0_STATUS_COLCNT_MASK) >>
-			     TDES0_STATUS_COLCNT_SHIFT);
+		if (unlikely((p->des01.tx.excessive_deferral) ||
+			     (p->des01.tx.excessive_collisions) ||
+			     (p->des01.tx.late_collision))) {
+			stats->collisions += p->des01.tx.collision_count;
 		}
 		ret = -1;
 	}
-	if (unlikely(status & TDES0_STATUS_HRTBT_FAIL)) {
+	if (unlikely(p->des01.tx.heartbeat_fail)) {
 		x->tx_heartbeat++;
 		stats->tx_heartbeat_errors++;
 		ret = -1;
 	}
-	if (unlikely(status & TDES0_STATUS_DF)) {
+	if (unlikely(p->des01.tx.deferred)) {
 		x->tx_deferred++;
 		ret = -1;
 	}
@@ -145,86 +216,65 @@ static int mac100_tx_hw_error(void *p, s
 
 /* This function verifies if the incoming frame has some errors 
  * and, if required, updates the multicast statistics. */
-static int mac100_rx_hw_error(void *p, struct stmmac_extra_stats *x,
-				unsigned int status)
+static int mac100_get_rx_frame_status(void *data, struct stmmac_extra_stats *x,
+				      dma_desc * p)
 {
 	int ret = 0;
-	struct net_device_stats *stats = (struct net_device_stats *)p;
+	struct net_device_stats *stats = (struct net_device_stats *)data;
+
+	if (unlikely(p->des01.rx.last_descriptor == 0)) {
+		printk(KERN_WARNING "mac100 Error: Oversized Ethernet "
+		       "frame spanned multiple buffers\n");
+		stats->rx_length_errors++;
+		return -1;
+	}
 
-	if (unlikely(status & RDES0_STATUS_ES)) {
-		if (unlikely(status & RDES0_STATUS_DE)) {
+	if (unlikely(p->des01.rx.error_summary)) {
+		if (unlikely(p->des01.rx.descriptor_error)) {
 			x->rx_desc++;
 		}
-		if (unlikely(status & RDES0_STATUS_PFE)) {
+		if (unlikely(p->des01.rx.partial_frame_error)) {
 			x->rx_partial++;
 		}
-		if (unlikely(status & RDES0_STATUS_RUNT_FRM)) {
+		if (unlikely(p->des01.rx.run_frame)) {
 			x->rx_runt++;
 		}
-		if (unlikely(status & RDES0_STATUS_TL)) {
+		if (unlikely(p->des01.rx.frame_too_long)) {
 			x->rx_toolong++;
 		}
-		if (unlikely(status & RDES0_STATUS_COL_SEEN)) {
+		if (unlikely(p->des01.rx.collision)) {
 			x->rx_collision++;
 			stats->collisions++;
 		}
-		if (unlikely(status & RDES0_STATUS_CE)) {
+		if (unlikely(p->des01.rx.crc_error)) {
 			x->rx_crc++;
 			stats->rx_crc_errors++;
 		}
 		ret = -1;
 	}
-	if (unlikely(status & RDES0_STATUS_LENGTH_ERROR)){
+	if (unlikely(p->des01.rx.dribbling))
+		ret = -1;
+
+	if (unlikely(p->des01.rx.length_error)) {
 		x->rx_lenght++;
 		ret = -1;
 	}
-	if (unlikely(status & RDES0_STATUS_MII_ERR)){
+	if (unlikely(p->des01.rx.mii_error)) {
 		x->rx_mii++;
 		ret = -1;
 	}
-	if (unlikely(status & RDES0_STATUS_MULTICST_FRM)){
+	if (p->des01.rx.multicast_frame) {
 		x->rx_multicast++;
 		stats->multicast++;
+		/*no error!*/
 	}
 	return (ret);
 }
 
-static void mac100_tx_checksum(struct sk_buff *skb)
+static int mac100_rx_checksum(dma_desc * p)
 {
-	/* Verify the csum via software... it' necessary, because the
-	 * hardware doesn't support a complete csum calculation. */
-	if (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {
-		const int offset = skb_transport_offset(skb);
-		unsigned int csum =
-		    skb_checksum(skb, offset, skb->len - offset, 0);
-		*(u16 *) (skb->data + offset + skb->csum_offset) =
-		    csum_fold(csum);
-	}
-	return;
-}
-
-static void mac100_rx_checksum(struct sk_buff *skb, int status)
-{
-	skb->ip_summed = CHECKSUM_NONE;
-	return;
-}
-
-static void mac100_core_init(unsigned long ioaddr)
-{
-	unsigned int value = 0;
-
-	printk(KERN_DEBUG "mac100_core_init");
-
-	/* Set the MAC control register with our default value */
-	value = (unsigned int)readl(ioaddr + MAC_CONTROL);
-	writel((value | MAC_CORE_INIT), ioaddr + MAC_CONTROL);
-
-#if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)
-	/* VLAN1 Tag identifier register is programmed to 
-	 * the 802.1Q VLAN Extended Header (0x8100). */
-	writel(ETH_P_8021Q, ioaddr + MAC_VLAN1);
-#endif
-	return;
+	/* The device is not able to compute the csum in HW. */
+	return -1;
 }
 
 static void mac100_set_filter(struct net_device *dev)
@@ -275,9 +325,9 @@ static void mac100_set_filter(struct net
 	writel(value, ioaddr + MAC_CONTROL);
 
 	printk(KERN_DEBUG "%s: CTRL reg: 0x%08x Hash regs: "
-		"HI 0x%08x, LO 0x%08x\n",
-		__FUNCTION__, readl(ioaddr + MAC_CONTROL),
-		readl(ioaddr + MAC_HASH_HIGH), readl(ioaddr + MAC_HASH_LOW));
+	       "HI 0x%08x, LO 0x%08x\n",
+	       __FUNCTION__, readl(ioaddr + MAC_CONTROL),
+	       readl(ioaddr + MAC_HASH_HIGH), readl(ioaddr + MAC_HASH_LOW));
 	return;
 }
 
@@ -293,7 +343,7 @@ static void mac100_flow_ctrl(unsigned lo
 	return;
 }
 
-static void mac100_enable_wol(unsigned long ioaddr, unsigned long mode)
+static void mac100_pmt(unsigned long ioaddr, unsigned long mode)
 {
 	/* There is no PMT module in the stb7109 so no wake-up-on-Lan hw feature
 	 * is supported. 
@@ -301,18 +351,117 @@ static void mac100_enable_wol(unsigned l
 	return;
 }
 
+static void mac100_init_rx_desc(dma_desc * p, unsigned int ring_size,
+				int rx_irq_threshold)
+{
+	int i;
+	for (i = 0; i < ring_size; i++) {
+		p->des01.rx.own = 1;
+		p->des01.rx.buffer1_size = DMA_BUFFER_SIZE - 1;
+		if (i % rx_irq_threshold)
+			p->des01.rx.disable_ic = 1;
+		if (i == ring_size - 1) {
+			p->des01.rx.end_ring = 1;
+		}
+		p++;
+	}
+	return;
+}
+
+static void mac100_init_tx_desc(dma_desc * p, unsigned int ring_size)
+{
+	int i;
+	for (i = 0; i < ring_size; i++) {
+		p->des01.tx.own = 0;
+		if (i == ring_size - 1) {
+			p->des01.tx.end_ring = 1;
+		}
+		p++;
+	}
+	return;
+}
+
+static int mac100_read_tx_owner(dma_desc * p)
+{
+	return p->des01.tx.own;
+}
+
+static int mac100_read_rx_owner(dma_desc * p)
+{
+	return p->des01.rx.own;
+}
+
+static void mac100_set_tx_owner(dma_desc * p)
+{
+	p->des01.tx.own = 1;
+}
+
+static void mac100_set_rx_owner(dma_desc * p)
+{
+	p->des01.rx.own = 1;
+}
+
+static int mac100_get_tx_ls(dma_desc * p)
+{
+	return p->des01.tx.last_segment;
+}
+
+static void mac100_release_tx_desc(dma_desc * p)
+{
+	int ter = p->des01.tx.end_ring;
+
+	memset(p, 0, sizeof(dma_desc));
+	p->des01.tx.end_ring = ter;
+
+	return;
+}
+static void mac100_prepare_tx_desc(dma_desc * p, int is_fs, int len,
+				   unsigned int csum_flags)
+{
+	p->des01.tx.first_segment = is_fs;
+	p->des01.tx.buffer1_size = len;
+}
+
+static void mac100_set_tx_ic(dma_desc * p, int value)
+{
+	p->des01.tx.interrupt = value;
+}
+
+static void mac100_set_tx_ls(dma_desc * p)
+{
+	p->des01.tx.last_segment = 1;
+}
+
+static int mac100_get_rx_frame_len(dma_desc * p)
+{
+	return p->des01.rx.frame_length;
+}
+
 struct device_ops mac100_driver = {
 	.core_init = mac100_core_init,
-	.mac_registers = mac100_mac_registers,
-	.dma_registers = mac100_dma_registers,
-	.dma_ttc = mac100_dma_ttc,
-	.tx_err = mac100_tx_hw_error,
-	.rx_err = mac100_rx_hw_error,
-	.tx_checksum = mac100_tx_checksum,
+	.dump_mac_regs = mac100_dump_mac_regs,
+	.dma_init = mac100_dma_init,
+	.dump_dma_regs = mac100_dump_dma_regs,
+	.dma_operation_mode = mac100_dma_operation_mode,
+	.dma_diagnostic_fr = mac100_dma_diagnostic_fr,
+	.tx_status = mac100_get_tx_frame_status,
+	.rx_status = mac100_get_rx_frame_status,
 	.rx_checksum = mac100_rx_checksum,
 	.set_filter = mac100_set_filter,
 	.flow_ctrl = mac100_flow_ctrl,
-	.enable_wol = mac100_enable_wol,
+	.pmt = mac100_pmt,
+	.init_rx_desc = mac100_init_rx_desc,
+	.init_tx_desc = mac100_init_tx_desc,
+	.read_tx_owner = mac100_read_tx_owner,
+	.read_rx_owner = mac100_read_rx_owner,
+	.release_tx_desc = mac100_release_tx_desc,
+	.prepare_tx_desc = mac100_prepare_tx_desc,
+	.set_tx_ic = mac100_set_tx_ic,
+	.set_tx_ls = mac100_set_tx_ls,
+	.get_tx_ls = mac100_get_tx_ls,
+	.set_tx_owner = mac100_set_tx_owner,
+	.set_rx_owner = mac100_set_rx_owner,
+	.get_rx_frame_len = mac100_get_rx_frame_len,
 };
 
 struct device_info_t *mac100_setup(unsigned long ioaddr)
@@ -326,6 +475,7 @@ struct device_info_t *mac100_setup(unsig
 
 	mac->ops = &mac100_driver;
 	mac->hw.pmt = PMT_NOT_SUPPORTED;
+	mac->hw.csum = NO_HW_CSUM;
 	mac->hw.addr_high = MAC_ADDR_HIGH;
 	mac->hw.addr_low = MAC_ADDR_LOW;
 	mac->hw.link.port = MAC_CONTROL_PS;
diff -uprN linux.orig/drivers/net/stmmac/mac100.h linux/drivers/net/stmmac/mac100.h
--- linux.orig/drivers/net/stmmac/mac100.h	2008-03-07 14:51:51.000000000 +0100
+++ linux/drivers/net/stmmac/mac100.h	2008-03-14 08:22:37.869998000 +0100
@@ -67,58 +67,37 @@
 /*----------------------------------------------------------------------------
  * 				DMA BLOCK defines
  *---------------------------------------------------------------------------*/
-/*  DMA Bus Mode register defines */
+
+/* DMA Bus Mode register defines */
 #define DMA_BUS_MODE_DBO	0x00100000	/* Descriptor Byte Ordering */
 #define DMA_BUS_MODE_BLE	0x00000080	/* Big Endian/Little Endian */
+#define DMA_BUS_MODE_PBL_MASK	0x00003f00	/* Programmable Burst Len */
+#define DMA_BUS_MODE_PBL_SHIFT	8
+#define DMA_BUS_MODE_DSL_MASK	0x0000007c	/* Descriptor Skip Length */
+#define DMA_BUS_MODE_DSL_SHIFT	2	/*   (in DWORDS)      */
+#define DMA_BUS_MODE_BAR_BUS	0x00000002	/* Bar-Bus Arbitration */
+#define DMA_BUS_MODE_SFT_RESET	0x00000001	/* Software Reset */
+#define DMA_BUS_MODE_DEFAULT	0x00000000
 
 /* DMA Control register defines */
 #define DMA_CONTROL_SF		0x00200000	/* Store And Forward */
+
 /* Transmit Threshold Control */
-#define DMA_CONTROL_TTC_DEFAULT	0x00000000	/* Threshold is 32 DWORDS */
-#define DMA_CONTROL_TTC_64	0x00004000	/* Threshold is 64 DWORDS */
-#define DMA_CONTROL_TTC_128	0x00008000	/* Threshold is 128 DWORDS */
-#define DMA_CONTROL_TTC_256	0x0000c000	/* Threshold is 256 DWORDS */
-#define DMA_CONTROL_TTC_18	0x00400000	/* Threshold is 18 DWORDS [22:1] */
-#define DMA_CONTROL_TTC_24	0x00404000	/* Threshold is 24 DWORDS [22:1] */
-#define DMA_CONTROL_TTC_32	0x00408000	/* Threshold is 32 DWORDS [22:1] */
-#define DMA_CONTROL_TTC_40	0x0040c000	/* Threshold is 40 DWORDS [22:1] */
-#define DMA_CONTROL_SE		0x00000008	/* Stop On Empty */
-#define DMA_CONTROL_OSF		0x00000004	/* Operate On 2nd Frame */
+enum ttc_control {
+	DMA_CONTROL_TTC_DEFAULT = 0x00000000,	/* Threshold is 32 DWORDS */
+	DMA_CONTROL_TTC_64 = 0x00004000,	/* Threshold is 64 DWORDS */
+	DMA_CONTROL_TTC_128 = 0x00008000,	/* Threshold is 128 DWORDS */
+	DMA_CONTROL_TTC_256 = 0x0000c000,	/* Threshold is 256 DWORDS */
+	DMA_CONTROL_TTC_18 = 0x00400000,	/* Threshold is 18 DWORDS [22:1] */
+	DMA_CONTROL_TTC_24 = 0x00404000,	/* Threshold is 24 DWORDS [22:1] */
+	DMA_CONTROL_TTC_32 = 0x00408000,	/* Threshold is 32 DWORDS [22:1] */
+	DMA_CONTROL_TTC_40 = 0x0040c000,	/* Threshold is 40 DWORDS [22:1] */
+	DMA_CONTROL_SE = 0x00000008,	/* Stop On Empty */
+	DMA_CONTROL_OSF = 0x00000004,	/* Operate On 2nd Frame */
+};
 
 /* STMAC110 DMA Missed Frame Counter register defines */
 #define DMA_MISSED_FRAME_OVE	0x10000000	/* FIFO Overflow Overflow */
 #define DMA_MISSED_FRAME_OVE_CNTR 0x0ffe0000	/* Overflow Frame Counter */
 #define DMA_MISSED_FRAME_OVE_M	0x00010000	/* Missed Frame Overflow */
 #define DMA_MISSED_FRAME_M_CNTR	0x0000ffff	/* Missed Frame Couinter */
-
-/*----------------------------------------------------------------------------
- * 		    	    Descriptor defines
- *---------------------------------------------------------------------------*/
-
-/* Receive Descriptor */
-#define RDES0_STATUS_FILTER_FAIL	0x40000000	/* Filtering Fail */
-#define RDES0_STATUS_DE		0x00004000	/* Descriptor Error */
-#define RDES0_STATUS_PFE	0x00002000	/* Partial Frame Error */
-#define RDES0_STATUS_LENGTH_ERROR 0x00001000	/* Length Error */
-#define RDES0_STATUS_RUNT_FRM	0x00000800	/* Runt Frame */
-#define RDES0_STATUS_MULTICST_FRM 0x00000400	/* Multicast Frame */
-#define RDES0_STATUS_TL	0x00000080	/* Frame Too Long */
-#define RDES0_STATUS_COL_SEEN	0x00000040	/* Collision Seen */
-#define RDES0_STATUS_FRM_TYPE	0x00000020	/* Frame Type */
-#define RDES0_STATUS_RX_WATCHDOG	0x00000010	/* Receive Watchdog */
-#define RDES0_STATUS_MII_ERR	0x00000008	/* Report on MII Error */
-#define RDES0_STATUS_DRIBBLE	0x00000004	/* Dribbling Bit */
-#define RDES0_STATUS_CE	0x00000002	/* CRC Error */
-#define RDES0_STATUS_0	0x00000000	/* Always tied to zero */
-
-/* Transmit Descriptor */
-#define TDES0_STATUS_LOSS_CARRIER 0x00000800	/* Loss of Carrier */
-#define TDES0_STATUS_NO_CARRIER 0x00000400	/* No Carrier */
-#define TDES0_STATUS_LATE_COL 0x00000200	/* Late Collision */
-#define TDES0_STATUS_EX_COL 0x00000100	/* Excessive Collisions */
-#define TDES0_STATUS_HRTBT_FAIL 0x00000080	/* Heartbeat Fail */
-#define TDES0_STATUS_COLCNT_MASK 0x00000078	/* Collision Count Mask */
-#define TDES0_STATUS_COLCNT_SHIFT 3	/* Collision Count Shift */
-#define TDES0_STATUS_EX_DEF 0x00000004	/* Excessive Deferrals */
-#define TDES0_STATUS_UF	0x00000002	/* Underflow Error */
-#define TDES0_STATUS_DF	0x00000001	/* Deferred */
diff -uprN linux.orig/drivers/net/stmmac/Makefile linux/drivers/net/stmmac/Makefile
--- linux.orig/drivers/net/stmmac/Makefile	2008-03-07 14:51:40.000000000 +0100
+++ linux/drivers/net/stmmac/Makefile	2008-03-13 16:29:46.079999000 +0100
@@ -1,3 +1,4 @@
 obj-$(CONFIG_STMMAC_ETH) += stmmac.o 
+obj-$(CONFIG_STMMAC_TIMER) += stmmac_timer.o 
 stmmac-objs:= stmmac_main.o stmmac_ethtool.o stmmac_mdio.o \
 		mac100.o  gmac.o
diff -uprN linux.orig/drivers/net/stmmac/stmmac_ethtool.c linux/drivers/net/stmmac/stmmac_ethtool.c
--- linux.orig/drivers/net/stmmac/stmmac_ethtool.c	2008-03-07 14:51:51.000000000 +0100
+++ linux/drivers/net/stmmac/stmmac_ethtool.c	2008-03-14 08:22:37.899998000 +0100
@@ -22,7 +22,7 @@
 #define REG_SPACE_SIZE	0x1054
 
 void stmmac_ethtool_getdrvinfo(struct net_device *dev,
-				struct ethtool_drvinfo *info)
+			       struct ethtool_drvinfo *info)
 {
 	strcpy(info->driver, ETH_RESOURCE_NAME);
 	strcpy(info->version, DRV_MODULE_VERSION);
@@ -37,13 +37,13 @@ int stmmac_ethtool_getsettings(struct ne
 	int rc;
 	if (phy == NULL) {
 		printk(KERN_ERR "%s: %s: PHY is not registered\n",
-			__FUNCTION__, dev->name);
+		       __FUNCTION__, dev->name);
 		return -ENODEV;
 	}
 
 	if (!netif_running(dev)) {
 		printk(KERN_ERR "%s: interface is disabled: we cannot track "
-			"link speed / duplex setting\n", dev->name);
+		       "link speed / duplex setting\n", dev->name);
 		return -EBUSY;
 	}
 
@@ -105,7 +105,8 @@ void stmmac_ethtool_gregs(struct net_dev
 	}
 	/* DMA registers */
 	for (i = 0; i < 9; i++) {
-		reg_space[i+12] = readl(dev->base_addr + (DMA_BUS_MODE + (i * 4)));
+		reg_space[i + 12] =
+		    readl(dev->base_addr + (DMA_BUS_MODE + (i * 4)));
 	}
 	reg_space[22] = readl(dev->base_addr + DMA_CUR_TX_BUF_ADDR);
 	reg_space[23] = readl(dev->base_addr + DMA_CUR_RX_BUF_ADDR);
@@ -130,18 +131,6 @@ u32 stmmac_ethtool_get_rx_csum(struct ne
 	return (lp->rx_csum);
 }
 
-int stmmac_ethtool_set_rx_csum(struct net_device *dev, u32 data)
-{
-	struct eth_driver_local *lp = netdev_priv(dev);
-
-	if (data)
-		lp->rx_csum = 1;
-	else
-		lp->rx_csum = 0;
-
-	return 0;
-}
-
 static void
 stmmac_get_pauseparam(struct net_device *netdev,
 		      struct ethtool_pauseparam *pause)
@@ -195,8 +184,8 @@ stmmac_set_pauseparam(struct net_device 
 		}
 	} else {
 		unsigned long ioaddr = netdev->base_addr;
-		lp->mac->ops->flow_ctrl(ioaddr, phy->duplex,
-					lp->flow_ctrl, lp->pause);
+		lp->mac_type->ops->flow_ctrl(ioaddr, phy->duplex,
+					     lp->flow_ctrl, lp->pause);
 	}
 	spin_unlock(&lp->lock);
 	return ret;
@@ -205,70 +194,78 @@ stmmac_set_pauseparam(struct net_device 
 static struct {
 	const char str[ETH_GSTRING_LEN];
 } ethtool_stats_keys[] = {
-	{ "tx_underflow" },
-	{ "tx_carrier" },
-	{ "tx_losscarrier" },
-	{ "tx_heartbeat" },
-	{ "tx_deferred" },
-	{ "tx_vlan" },
-	{ "tx_jabber" },
-	{ "tx_frame_flushed" },
-	{ "rx_desc" },
-	{ "rx_partial" },
-	{ "rx_runt" },
-	{ "rx_toolong" },
-	{ "rx_collision" },
-	{ "rx_crc" },
-	{ "rx_lenght" },
-	{ "rx_mii" },
-	{ "rx_multicast" },
-	{ "rx_overflow" },
-	{ "rx_watchdog" },
-	{ "rx_filter" },
-	{ "rx_dropped" },
-	{ "rx_bytes" },
-	{ "tx_bytes" },
-	{ "tx_irq_n" },
-	{ "rx_irq_n" },
-	{ "tx_undeflow_irq" },
-	{ "tx_threshold" },
-	{ "tx_process_stopped_irq" },
-	{ "tx_jabber_irq" },
-	{ "rx_overflow_irq" },
-	{ "rx_buf_unav_irq" },
-	{ "rx_process_stopped_irq" },
-	{ "rx_watchdog_irq" },
-	{ "tx_early_irq" },
-	{ "fatal_bus_error_irq" },
-	{ "rx_poll_n" },
-};
+	{
+	"tx_underflow"}, {
+	"tx_carrier"}, {
+	"tx_losscarrier"}, {
+	"tx_heartbeat"}, {
+	"tx_deferred"}, {
+	"tx_vlan"}, {
+	"tx_jabber"}, {
+	"tx_frame_flushed"}, {
+	"rx_desc"}, {
+	"rx_partial"}, {
+	"rx_runt"}, {
+	"rx_toolong"}, {
+	"rx_collision"}, {
+	"rx_crc"}, {
+	"rx_lenght"}, {
+	"rx_mii"}, {
+	"rx_multicast"}, {
+	"rx_gmac_overflow"}, {
+	"rx_watchdog"}, {
+	"rx_filter"}, {
+	"rx_dropped"}, {
+	"rx_bytes"}, {
+	"tx_bytes"}, {
+	"tx_irq_n"}, {
+	"rx_irq_n"}, {
+	"tx_undeflow_irq"}, {
+	"threshold"}, {
+	"tx_process_stopped_irq"}, {
+	"tx_jabber_irq"}, {
+	"rx_overflow_irq"}, {
+	"rx_buf_unav_irq"}, {
+	"rx_process_stopped_irq"}, {
+	"rx_watchdog_irq"}, {
+	"tx_early_irq"}, {
+	"fatal_bus_error_irq"}, {
+	"rx_poll_n"}, {
+	"tx_payload_error"}, {
+	"tx_ip_header_error"}, {
+	"rx_missed_cntr"}, {
+"rx_overflow_cntr"},};
 
 static int stmmac_stats_count(struct net_device *dev)
 {
 	return EXTRA_STATS;
 }
 
-static void stmmac_ethtool_stats(struct net_device *dev, 
-		struct ethtool_stats *dummy, u64 * buf)
+static void stmmac_ethtool_stats(struct net_device *dev,
+				 struct ethtool_stats *dummy, u64 * buf)
 {
 	struct eth_driver_local *lp = netdev_priv(dev);
+	unsigned long ioaddr = dev->base_addr;
+	u32 *extra;
 	int i;
-	u32 *extra = (u32 *) &lp->xstats;
+
+	lp->mac_type->ops->dma_diagnostic_fr(&lp->stats, &lp->xstats, ioaddr);
+
+	extra = (u32 *) & lp->xstats;
+
 	for (i = 0; i < EXTRA_STATS; i++)
 		buf[i] = extra[i];
 	return;
 }
 
-static void stmmac_get_strings(struct net_device *dev, 
-				u32 stringset, u8 *buf)
+static void stmmac_get_strings(struct net_device *dev, u32 stringset, u8 * buf)
 {
 	switch (stringset) {
-		case ETH_SS_STATS:
-			memcpy(buf, &ethtool_stats_keys, 
-				sizeof(ethtool_stats_keys));
-			break;
-		default:
-			WARN_ON(1);
+	case ETH_SS_STATS:
+		memcpy(buf, &ethtool_stats_keys, sizeof(ethtool_stats_keys));
+		break;
+	default:
+		WARN_ON(1);
 		break;
 	}
 	return;
@@ -280,7 +277,7 @@ static void stmmac_get_wol(struct net_de
 
 	spin_lock_irq(&lp->lock);
 	if (lp->wolenabled == PMT_SUPPORTED) {
-		wol->supported = WAKE_MAGIC;
+		wol->supported = WAKE_MAGIC | WAKE_UCAST;
 		wol->wolopts = lp->wolopts;
 	}
 	spin_unlock_irq(&lp->lock);
@@ -315,7 +312,6 @@ struct ethtool_ops stmmac_ethtool_ops = 
 	.get_regs_len = stmmac_ethtool_get_regs_len,
 	.get_link = ethtool_op_get_link,
 	.get_rx_csum = stmmac_ethtool_get_rx_csum,
-	.set_rx_csum = stmmac_ethtool_set_rx_csum,
 	.get_tx_csum = ethtool_op_get_tx_csum,
 	.set_tx_csum = stmmac_ethtool_set_tx_csum,
 	.get_sg = ethtool_op_get_sg,
diff -uprN linux.orig/drivers/net/stmmac/stmmac.h linux/drivers/net/stmmac/stmmac.h
--- linux.orig/drivers/net/stmmac/stmmac.h	2008-03-07 14:51:51.000000000 +0100
+++ linux/drivers/net/stmmac/stmmac.h	2008-03-14 08:22:37.919998000 +0100
@@ -1,6 +1,6 @@
 #define ETH_RESOURCE_NAME	"stmmaceth"
 #define PHY_RESOURCE_NAME	"stmmacphy"
-#define DRV_MODULE_VERSION	"Jan_08"
+#define DRV_MODULE_VERSION	"March_08"
 
 #if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)
 #define STMMAC_VLAN_TAG_USED
@@ -8,16 +8,6 @@
 
 #include "common.h"
 
-/* This structure is common for both receive and transmit DMA descriptors.
- * A descriptor should not be used for storing more than one frame. */
-struct dma_desc_t {
-	unsigned int des0;	/* Status */
-	unsigned int des1;	/* Ctrl bits, Buffer 2 length, Buffer 1 length */
-	unsigned int des2;	/* Buffer 1 */
-	unsigned int des3;	/* Buffer 2 */
-};
-typedef struct dma_desc_t dma_desc;
-
 /* Struct private for the STMMAC driver */
 struct eth_driver_local {
 	int bus_id;
@@ -40,31 +30,32 @@ struct eth_driver_local {
 	u32 msg_enable;
 	spinlock_t lock;
 	spinlock_t tx_lock;
-	dma_desc *dma_tx;	/* virtual DMA TX addr */
-	dma_addr_t dma_tx_phy;	/* bus DMA TX addr */
-	unsigned int cur_tx, dirty_tx;	/* Producer/consumer ring indices */
+	dma_desc *dma_tx;
+	dma_desc *dma_rx;
+	dma_addr_t dma_tx_phy;
+	unsigned int cur_tx, dirty_tx;
 	struct sk_buff **tx_skbuff;
-	dma_desc *dma_rx;	/* virtual DMA RX addr */
-	dma_addr_t dma_rx_phy;	/* bus DMA RX addr */
+	dma_addr_t dma_rx_phy;
 	int dma_buf_sz;
-	unsigned int rx_buff;	/* Last rx buffer owned by the DMA */
+	unsigned int rx_buff;
 	int rx_csum;
-	unsigned int cur_rx, dirty_rx;	/* Producer/consumer ring indices */
+	unsigned int cur_rx, dirty_rx;
 	struct sk_buff **rx_skbuff;
 	dma_addr_t *rx_skbuff_dma;
 	struct device *device;
 	unsigned int dma_tx_size;
 	unsigned int dma_rx_size;
-	int ttc;
-	struct device_info_t *mac;
-	unsigned int flow_ctrl;	/* FC [on/off] - [RX/TX/AUTO] */
+	struct device_info_t *mac_type;
+	unsigned int flow_ctrl;
 	unsigned int pause;
 #ifdef STMMAC_VLAN_TAG_USED
 	struct vlan_group *vlgrp;
 #endif
 	struct net_device *dev;
-	struct stmmac_extra_stats xstats; /* Extra stats */
+	struct stmmac_extra_stats xstats;
 	int wolopts;
 	int wolenabled;
 	int tx_aggregation;
+	int max_refill_threshold;
+	int has_timer;
 };
diff -uprN linux.orig/drivers/net/stmmac/stmmac_main.c linux/drivers/net/stmmac/stmmac_main.c
--- linux.orig/drivers/net/stmmac/stmmac_main.c	2008-03-07 14:51:51.000000000 +0100
+++ linux/drivers/net/stmmac/stmmac_main.c	2008-03-18 08:26:29.390001000 +0100
@@ -11,6 +11,12 @@
  * ----------------------------------------------------------------------------
  *
  * Changelog:
+ * March 2008:
+ *	- Added Rx timer optimization (also mitigated by using the normal
+ *	  interrupt on completion). See stmmac_timer.c file.
+ *	- Added hardware csum for the Gigabit Ethernet device.
+ *	- Reviewed the descriptor structures and added a new header file
+ *	  (descs.h). 
  * Jan 2008:
  *	- First GMAC working.
  *	- Reviewed stmmac_poll in order to make easier the NAPI v5 porting.
@@ -52,7 +58,7 @@
 #include "stmmac.h"
 
 #undef STMMAC_DEBUG
-//#define STMMAC_DEBUG
+/*#define STMMAC_DEBUG*/
 #ifdef STMMAC_DEBUG
 #define DBG(nlevel, klevel, fmt, args...) \
 		(void)(netif_msg_##nlevel(lp) && \
@@ -62,7 +68,7 @@
 #endif
 
 #undef STMMAC_RX_DEBUG
-//#define STMMAC_RX_DEBUG
+/*#define STMMAC_RX_DEBUG*/
 #ifdef STMMAC_RX_DEBUG
 #define RX_DBG(fmt,args...)  printk(fmt, ## args)
 #else
@@ -70,16 +76,17 @@
 #endif
 
 #undef STMMAC_XMIT_DEBUG
-//#define STMMAC_XMIT_DEBUG
+/*#define STMMAC_XMIT_DEBUG*/
 
 #define MIN_MTU 46
 #define MAX_MTU ETH_DATA_LEN
 
-#define DMA_BUFFER_SIZE	2048
-
 #define STMMAC_ALIGN(x)	ALIGN((x), dma_get_cache_alignment())
 #define STMMAC_IP_ALIGN NET_IP_ALIGN
 
+#define TX_BUFFS_AVAIL(lp) \
+	(lp->dirty_tx + lp->dma_tx_size - lp->cur_tx - 1)
+
 /* Module Arguments */
 #define TX_TIMEO (5*HZ)
 static int watchdog = TX_TIMEO;
@@ -87,7 +94,7 @@ module_param(watchdog, int, S_IRUGO | S_
 MODULE_PARM_DESC(watchdog, "Transmit Timeout (in milliseconds)");
 
 static int debug = -1;		/* -1: default, 0: no output, 16:  all */
-module_param(debug, int, S_IRUGO);
+module_param(debug, int, S_IRUGO | S_IWUSR);
 MODULE_PARM_DESC(debug, "Message Level (0: no output, 16: all)");
 
 static int rx_copybreak = 0;
@@ -116,55 +123,54 @@ static int pause = PAUSE_TIME;
 module_param(pause, int, S_IRUGO);
 MODULE_PARM_DESC(pause, "Flow Control Pause Time");
 
-static int tx_aggregation = -1; /* No mitigtion by default */
+static int tx_aggregation = -1;	/* No mitigtion by default */
 module_param(tx_aggregation, int, S_IRUGO | S_IWUSR);
-MODULE_PARM_DESC(rx_copybreak, "Tx aggregation threshold");
+MODULE_PARM_DESC(tx_aggregation, "Tx aggregation threshold");
 
-#define TX_BUFFS_AVAIL(lp) \
-	(lp->dirty_tx + lp->dma_tx_size - lp->cur_tx - 1)
-
-static const char version[] = "STMMAC - (C) STMicroelectronics\n";
+#define TTC_DEFAULT 0x40
+static int threshold_ctrl = TTC_DEFAULT;
+module_param(threshold_ctrl, int, S_IRUGO);
+MODULE_PARM_DESC(threshold_ctrl, "tranfer threshold control");
+
+#ifdef CONFIG_STMMAC_TIMER
+/* Using timer optimization, it's worth having some interrupts on frame 
+ * reception. That makes safe the network activity especially for TCP traffic.*/
+#define RX_IRQ_THRESHOLD 10
+/* Please pay attention to tune the timer irq frequency; take care of both RTC
+ * hardware capability and network stabitily/performance impact. */
+#define DEFAULT_PERIODIC_RATE	256
+static int periodic_rate = DEFAULT_PERIODIC_RATE;
+module_param(periodic_rate, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(periodic_rate, "Timer periodic rate (default: 256Hz)");
+#else
+#define RX_IRQ_THRESHOLD 1
+#endif
+static int rx_irq_mitigation = RX_IRQ_THRESHOLD;	/* use it with timer on */
+module_param(rx_irq_mitigation, int, S_IRUGO);
+MODULE_PARM_DESC(rx_irq_mitigation, "Rx irq mitigation threshold");
 
 static const u32 default_msg_level = (NETIF_MSG_DRV | NETIF_MSG_PROBE |
 				      NETIF_MSG_LINK | NETIF_MSG_IFUP |
 				      NETIF_MSG_IFDOWN | NETIF_MSG_TIMER);
 
-extern int stmmac_mdio_unregister(struct net_device *ndev);
-extern int stmmac_mdio_register(struct net_device *ndev);
-extern struct ethtool_ops stmmac_ethtool_ops;
 static irqreturn_t stmmac_interrupt(int irq, void *dev_id);
-/* STb7109 embedded MAC / GMAC device setup */
+
+extern struct ethtool_ops stmmac_ethtool_ops;
 extern struct device_info_t *gmac_setup(unsigned long addr);
 extern struct device_info_t *mac100_setup(unsigned long addr);
-
-static __inline__ int validate_buffer_size(unsigned int size)
-{
-	unsigned int tbs = size;
-
-	/* According to the TBS1/2 RBS1/2 bits the maximum 
-		 * buffer size is 0x7ff */
-	if (unlikely(tbs >= DMA_BUFFER_SIZE))
-		tbs = 0x7ff;
-
-	return tbs;
-
-}
-
-static int tdes1_buf1_size(unsigned int len)
-{
-	return ((validate_buffer_size(len) << DES1_RBS1_SIZE_SHIFT) 
-		& DES1_RBS1_SIZE_MASK);
-}
-
-static int tdes1_buf2_size(unsigned int len)
-{
-	return ((validate_buffer_size(len) << DES1_RBS2_SIZE_SHIFT) 
-		& DES1_RBS2_SIZE_MASK);
-}
+extern int stmmac_mdio_unregister(struct net_device *ndev);
+extern int stmmac_mdio_register(struct net_device *ndev);
+extern int stmmac_mdio_reset(struct mii_bus *bus);
+#ifdef CONFIG_STMMAC_TIMER
+extern int stmmac_timer_close(void);
+extern int stmmac_timer_stop(void);
+extern int stmmac_timer_start(unsigned int freq);
+extern int stmmac_timer_open(struct net_device *dev, unsigned int freq);
+#endif
 
 static __inline__ void stmmac_verify_args(void)
 {
-	/* Wrong parameters are forced with the default values */
+	/* Wrong parameters are replaced with the default values */
 	if (watchdog < 0)
 		watchdog = TX_TIMEO;
 	if (rx_copybreak < 0)
@@ -173,15 +179,21 @@ static __inline__ void stmmac_verify_arg
 		dma_rx_size_param = DMA_RX_SIZE;
 	if (dma_tx_size_param < 0)
 		dma_tx_size_param = DMA_TX_SIZE;
-	if (flow_ctrl > 1) {
+
+	if (flow_ctrl > 1)
 		flow_ctrl = FLOW_AUTO;
-	if (tx_aggregation >= (dma_tx_size_param))
-		tx_aggregation = -1;
-	} else if (flow_ctrl < 0) {
+	else if (flow_ctrl < 0)
 		flow_ctrl = FLOW_OFF;
-	}
+
 	if ((pause < 0) || (pause > 0xffff))
 		pause = PAUSE_TIME;
+
+	if (tx_aggregation >= (dma_tx_size_param))
+		tx_aggregation = -1;
+
+	if (rx_irq_mitigation > (dma_rx_size_param))
+		rx_irq_mitigation = RX_IRQ_THRESHOLD;
+
 	return;
 }
 
@@ -219,53 +231,52 @@ static void stmmac_adjust_link(struct ne
 
 	spin_lock_irqsave(&lp->lock, flags);
 	if (phydev->link) {
-		unsigned int ctrl =
-		    (unsigned int)readl(ioaddr + MAC_CTRL_REG);
+		unsigned int ctrl = (unsigned int)readl(ioaddr + MAC_CTRL_REG);
 
 		/* Now we make sure that we can be in full duplex mode.
 		 * If not, we operate in half-duplex mode. */
 		if (phydev->duplex != lp->oldduplex) {
 			new_state = 1;
 			if (!(phydev->duplex)) {
-				ctrl &= ~lp->mac->hw.link.duplex;
+				ctrl &= ~lp->mac_type->hw.link.duplex;
 			} else {
-				ctrl |= lp->mac->hw.link.duplex;
+				ctrl |= lp->mac_type->hw.link.duplex;
 			}
 			lp->oldduplex = phydev->duplex;
 		}
 		/* Flow Control operation */
 		if (phydev->pause)
-			lp->mac->ops->flow_ctrl(ioaddr, phydev->duplex,
-						fc, pause_time);
+			lp->mac_type->ops->flow_ctrl(ioaddr, phydev->duplex,
+						     fc, pause_time);
 
 		if (phydev->speed != lp->speed) {
 			new_state = 1;
 			switch (phydev->speed) {
 			case 1000:
 				if (likely(lp->is_gmac))
-					ctrl &= lp->mac->hw.link.port;/* GMII */
+					ctrl &= ~lp->mac_type->hw.link.port;
 			case 100:
 			case 10:
 				if (lp->is_gmac) {
-					ctrl |= lp->mac->hw.link.port;/* MII */
+					ctrl |= lp->mac_type->hw.link.port;
 					if (phydev->speed == SPEED_100) {
-						ctrl |= lp->mac->hw.link.speed;
+						ctrl |=
+						    lp->mac_type->hw.link.speed;
 					} else {
-						ctrl &= ~(lp->mac->hw.link.speed);
+						ctrl &=
+						    ~(lp->mac_type->hw.link.
+						      speed);
 					}
 				} else {
-					ctrl &= ~lp->mac->hw.link.port;/* MII */
-#if 0
-					lp->fix_mac_speed(lp->bsp_priv, 
-						phydev->speed); /*RMII*/
-#endif
+					ctrl &= ~lp->mac_type->hw.link.port;
 				}
 				break;
 			default:
 				if (netif_msg_link(lp))
 					printk(KERN_WARNING
-					       "%s: Ack!  Speed (%d) is not 10 or 100!\n",
-					       dev->name, phydev->speed);
+					       "%s: Ack!  Speed (%d) is not 10"
+					       " or 100!\n", dev->name,
+					       phydev->speed);
 				break;
 			}
 
@@ -442,65 +453,23 @@ static void stmmac_mac_disable_tx(struct
 	return;
 }
 
-static void display_dma_desc_ring(dma_desc * p, int size)
+static void display_ring(dma_desc * p, int size)
 {
+	struct tmp_s {
+		u64 a;
+		unsigned int b;
+		unsigned int c;
+	};
 	int i;
 	for (i = 0; i < size; i++) {
-		printk("\t%d [0x%x]: "
-			"desc0=0x%x desc1=0x%x buffer1=0x%x, buffer2=0x%x", i,
-			(unsigned int)virt_to_phys(&p[i].des0), p[i].des0,
-			p[i].des1, (unsigned int)p[i].des2,
-			(unsigned int)p[i].des3);
+		struct tmp_s *x = (struct tmp_s *)(p + i);
+		printk("\t%d [0x%x]: des0=0x%x des1=0x%x buff=0x%x", i,
+		       (unsigned int)virt_to_phys(&p[i]), (unsigned int)(x->a),
+		       (unsigned int)((x->a) >> 32), x->b);
 		printk("\n");
 	}
 }
 
-/*
- * This function clears both RX and TX descriptors (MAC 10/100).
- * Note that the driver uses the 'implicit' scheme for implementing
- * the TX/RX DMA linked lists. So the second buffer doesn't point
- * to the next descriptor.  */
-static void reset_mac_descs(dma_desc * p, unsigned int ring_size,
-			    unsigned int own_bit)
-{
-	int i;
-	for (i = 0; i < ring_size; i++) {
-		p->des0 = own_bit;
-		if (!(own_bit)) {
-			p->des1 = 0;
-		} else {
-			p->des1 = tdes1_buf1_size(DMA_BUFFER_SIZE);
-			/*p->des1 |= RDES1_CONTROL_DIC;*/
-		}
-		if (i == ring_size - 1) {
-			p->des1 |= MAC_CTRL_DESC_TER;
-		}
-		p++;
-	}
-	return;
-}
-
-/* This function clears both RX and TX GMAC descriptors.*/
-static void reset_gmac_descs(dma_desc * p, unsigned int ring_size,
-			    unsigned int own_bit)
-{
-	int i;
-	for (i = 0; i < ring_size; i++) {
-		p->des0 = own_bit;
-		if (!(own_bit)) { // TX 
-			p->des1 = 0;
-			if (i == ring_size - 1)
-				p->des0 |= GMAC_TX_CONTROL_TER;
-		} else { // RX
-			p->des1 = tdes1_buf1_size(DMA_BUFFER_SIZE);
-			if (i == ring_size - 1)
-				p->des1 |= GMAC_RX_CONTROL_TER;
-		}
-		p++;
-	}
-	return;
-}
-
 /**
  * init_dma_desc_rings - init the RX/TX descriptor rings
  * @dev: net device structure
@@ -579,24 +548,18 @@ static void init_dma_desc_rings(struct n
 	for (i = 0; i < txsize; i++) {
 		lp->tx_skbuff[i] = NULL;
 		lp->dma_tx[i].des2 = 0;
-		lp->dma_tx[i].des3 = 0;
 	}
 	lp->dirty_tx = lp->cur_tx = 0;
 
 	/* Clear the Rx/Tx descriptors */
-	if (lp->is_gmac) {
-		reset_gmac_descs(lp->dma_rx, rxsize, OWN_BIT);
-		reset_gmac_descs(lp->dma_tx, txsize, 0);
-	} else {
-		reset_mac_descs(lp->dma_rx, rxsize, OWN_BIT);
-		reset_mac_descs(lp->dma_tx, txsize, 0);
-	}
+	lp->mac_type->ops->init_rx_desc(lp->dma_rx, rxsize, rx_irq_mitigation);
+	lp->mac_type->ops->init_tx_desc(lp->dma_tx, txsize);
 
 	if (netif_msg_hw(lp)) {
 		printk("RX descriptor ring:\n");
-		display_dma_desc_ring(lp->dma_rx, rxsize);
+		display_ring(lp->dma_rx, rxsize);
 		printk("TX descriptor ring:\n");
-		display_dma_desc_ring(lp->dma_tx, txsize);
+		display_ring(lp->dma_tx, txsize);
 	}
 	return;
 }
@@ -636,16 +599,7 @@ static void dma_free_tx_skbufs(struct ne
 		if (lp->tx_skbuff[i] != NULL) {
 			if ((lp->dma_tx + i)->des2) {
 				dma_unmap_single(lp->device, p->des2,
-						 ((p->
-						   des1 & DES1_RBS1_SIZE_MASK)
-						  >> DES1_RBS1_SIZE_SHIFT),
-						 DMA_TO_DEVICE);
-			}
-			if ((lp->dma_tx + i)->des3) {
-				dma_unmap_single(lp->device, p->des3,
-						 ((p->
-						   des1 & DES1_RBS1_SIZE_MASK)
-						  >> DES1_RBS1_SIZE_SHIFT),
+						 DMA_BUFFER_SIZE,
 						 DMA_TO_DEVICE);
 			}
 			dev_kfree_skb_any(lp->tx_skbuff[i]);
@@ -684,26 +638,6 @@ static void free_dma_desc_resources(stru
 }
 
 /**
- * stmmac_dma_reset - STMAC DMA SW reset
- * @ioaddr: device I/O address
- * Description:  this function performs the DMA SW reset.
- *  NOTE1: the MII_TxClk and the MII_RxClk must be active before this
- *	   SW reset otherwise the MAC core won't exit the reset state.
- *  NOTE2: after a SW reset all interrupts are disabled
- */
-static void stmmac_dma_reset(unsigned long ioaddr)
-{
-	unsigned int value;
-
-	value = (unsigned int)readl(ioaddr + DMA_BUS_MODE);
-	value |= DMA_BUS_MODE_SFT_RESET;
-	writel(value, ioaddr + DMA_BUS_MODE);
-	while ((readl(ioaddr + DMA_BUS_MODE) & DMA_BUS_MODE_SFT_RESET)) {
-	}
-	return;
-}
-
-/**
  * stmmac_dma_start_tx
  * @ioaddr: device I/O address
  * Description:  this function starts the DMA tx process
@@ -758,46 +692,12 @@ static __inline__ void stmmac_dma_enable
 	return;
 }
 
-static __inline__ void stmmac_dma_disable_irq_rx(unsigned long ioaddr)
+void stmmac_dma_disable_irq_rx(unsigned long ioaddr)
 {
 	writel(DMA_INTR_NO_RX, ioaddr + DMA_INTR_ENA);
 	return;
 }
 
-/**
- * stmmac_dma_init - DMA init function
- * @dev: net device structure
- * Description: the DMA init function performs:
- * - the DMA RX/TX SW descriptors initialization
- * - the DMA HW controller initialization
- * NOTE: the DMA TX/RX processes will be started in the 'open' method.
- */
-static int stmmac_dma_init(struct net_device *dev)
-{
-	unsigned long ioaddr = dev->base_addr;
-	struct eth_driver_local *lp = netdev_priv(dev);
-
-	DBG(probe, DEBUG, "STMMAC: DMA Core setup\n");
-
-	/* DMA SW reset */
-	stmmac_dma_reset(ioaddr);
-
-	/* Enable Application Access by writing to DMA CSR0 */
-	DBG(probe, DEBUG, "\t(PBL: %d)\n", lp->pbl);
-	writel(DMA_BUS_MODE_DEFAULT | ((lp->pbl) << DMA_BUS_MODE_PBL_SHIFT),
-	       ioaddr + DMA_BUS_MODE);
-
-	/* Mask interrupts by writing to CSR7 */
-	writel(DMA_INTR_DEFAULT_MASK, ioaddr + DMA_INTR_ENA);
-
-	/* The base address of the RX/TX descriptor lists must be written into
-	 * DMA CSR3 and CSR4, respectively. */
-	writel((unsigned long)lp->dma_tx_phy, ioaddr + DMA_TX_BASE_ADDR);
-	writel((unsigned long)lp->dma_rx_phy, ioaddr + DMA_RCV_BASE_ADDR);
-
-	return 0;
-}
-
 #ifdef STMMAC_DEBUG
 /**
  * show_tx_process_state
@@ -889,66 +789,46 @@ static __inline__ void stmmac_tx(struct 
 {
 	struct eth_driver_local *lp = netdev_priv(dev);
 	unsigned int txsize = lp->dma_tx_size;
-	int entry = lp->dirty_tx % txsize, is_gmac = lp->is_gmac;
+	unsigned long ioaddr = dev->base_addr;
+	int entry = lp->dirty_tx % txsize;
 
 	while (lp->dirty_tx != lp->cur_tx) {
+		int last;
 		dma_desc *p = lp->dma_tx + entry;
-		int txstatus = p->des0, last;
 
-		if (txstatus & OWN_BIT)
+		if (lp->mac_type->ops->read_tx_owner(p))
 			break;
-
-		if (is_gmac) /* GMAC*/
-			last = (p->des0 & GMAC_TX_LAST_SEGMENT);
-		else
-			last = (p->des1 & TDES1_CONTROL_LS);
-
+		/* verify tx error by looking at the last segment */
+		last = lp->mac_type->ops->get_tx_ls(p);
 		if (likely(last)) {
-			int tx_error = lp->mac->ops->tx_err(&lp->stats,
-							    &lp->xstats,
-							    txstatus);
+			int tx_error = lp->mac_type->ops->tx_status(&lp->stats,
+								    &lp->xstats,
+								    p, ioaddr);
 			if (likely(tx_error == 0)) {
 				lp->stats.tx_packets++;
 			} else {
 				lp->stats.tx_errors++;
-				DBG(intr, ERR,
-				    "Tx Error (%d):des0 0x%x, des1 0x%x,"
-				    "[buf: 0x%08x] [buf: 0x%08x]\n",
-				    entry, p->des0, p->des1, p->des2, p->des3);
 			}
 		}
 		DBG(intr, DEBUG, "stmmac_tx: curr %d, dirty %d\n", lp->cur_tx,
 		    lp->dirty_tx);
 
-		/* clear descriptors */
-		if (is_gmac) { /* GMAC*/
-			p->des0 &= GMAC_TX_CONTROL_TER;
-			p->des1 = 0;
-		} else {
-			p->des0 = 0;
-			p->des1 &= MAC_CTRL_DESC_TER;
-		}
 		if (likely(p->des2)) {
-			dma_unmap_single(lp->device, p->des2,
-					 (p->des1 & DES1_RBS1_SIZE_MASK) >>
-					 DES1_RBS1_SIZE_SHIFT, DMA_TO_DEVICE);
-			p->des2 = 0;
-		}
-		if (likely(p->des3)) {
-			dma_unmap_single(lp->device, p->des3,
-					 (p->des1 & DES1_RBS2_SIZE_MASK) >>
-					 DES1_RBS2_SIZE_SHIFT, DMA_TO_DEVICE);
-			p->des3 = 0;
+			dma_unmap_single(lp->device, p->des2, DMA_BUFFER_SIZE,
+					 DMA_TO_DEVICE);
 		}
 		if (likely(lp->tx_skbuff[entry] != NULL)) {
 			dev_kfree_skb_irq(lp->tx_skbuff[entry]);
 			lp->tx_skbuff[entry] = NULL;
 		}
+
+		lp->mac_type->ops->release_tx_desc(p);
+
 		entry = (++lp->dirty_tx) % txsize;
 	}
 	spin_lock(&lp->tx_lock);
 	if (unlikely(netif_queue_stopped(dev) &&
-	    TX_BUFFS_AVAIL(lp) > (MAX_SKB_FRAGS + 1)))
+		     TX_BUFFS_AVAIL(lp) > (MAX_SKB_FRAGS + 1)))
 		netif_wake_queue(dev);
 
 	spin_unlock(&lp->tx_lock);
@@ -956,85 +836,28 @@ static __inline__ void stmmac_tx(struct 
 }
 
 /**
- * stmmac_restart_tx:
+ * stmmac_tx_err: 
  * @dev: net device structure
- * Description: although this should be a rare event, will try
- * to bump up the tx threshold in the DMA ctrl register (only 
- * for the TLI) and restart transmission again.
+ * Description: clean descriptors and restart the transmission.
  */
-static __inline__ void stmmac_restart_tx(struct net_device *dev)
+static __inline__ void stmmac_tx_err(struct net_device *dev)
 {
 	struct eth_driver_local *lp = netdev_priv(dev);
-	unsigned int txsize = lp->dma_tx_size;
-	unsigned int ioaddr = dev->base_addr;
-	int entry = (lp->dirty_tx % txsize), curr = lp->cur_tx % txsize;
-	dma_desc *p = lp->dma_tx + entry;
-	dma_desc *n = lp->dma_tx + curr;
-
-	/* Bump up the threshold */
-	if (lp->ttc <= 0x100) {
-		lp->ttc += 0x20;
-		lp->xstats.tx_threshold = lp->ttc;
-		lp->mac->ops->dma_ttc(ioaddr, lp->ttc);
-	}
 
 	spin_lock(&lp->tx_lock);
 
-	/* Keep the frame and try retransmitting it again */
-	while (!(p->des0 & 0x2)) {
-		entry++;
-		entry %= txsize;
-		p = lp->dma_tx + entry;
-	}
-
-	DBG(intr, INFO,
-	    "stmmac: Tx Underflow: (%d) des0 0x%x, des1 0x%x"
-	    " [buf: 0x%08x] (current=%d, dirty=%d)\n",
-	    entry, p->des0, p->des1, readl(ioaddr + DMA_CUR_TX_BUF_ADDR),
-	    curr, (lp->dirty_tx % txsize));
-
-	/* Place the frame in the next free position
-	 * and clean the descriptor where the underflow happened */
-	if (!lp->is_gmac){
-		n->des0 = OWN_BIT;
-		n->des1 |= (p->des1 & ~MAC_CTRL_DESC_TER);
-		n->des1 |= TDES1_CONTROL_IC;
-	} else { /*GMAC -- written but (fortunately) never met and test! */
-		n->des0 |= (p->des0 & GMAC_TX_CONTROL_TER);
-		n->des0 |= (OWN_BIT | GMAC_TX_IC);
-		n->des1 = p->des1;
-	}
-	n->des2 = p->des2;
-	p->des0 = 0;
-	p->des2 = 0;
-	lp->cur_tx++;
-
-	writel(1, ioaddr + DMA_XMT_POLL_DEMAND);
-	/* stop the queue as well */
 	netif_stop_queue(dev);
-	spin_unlock(&lp->tx_lock);
-	return;
-}
-
-/**
- * stmmac_tx_err: 
- * @dev: net device structure
- * Description: clean descriptors and restart the transmission.
- */
-static __inline__ void stmmac_tx_err(struct net_device *dev)
-{
-	struct eth_driver_local *lp = netdev_priv(dev);
 
 	stmmac_dma_stop_tx(dev->base_addr);
-	if (lp->is_gmac) {
-		reset_gmac_descs(lp->dma_rx, lp->dma_rx_size, OWN_BIT);
-		reset_gmac_descs(lp->dma_tx, lp->dma_tx_size, 0);
-	} else {
-		reset_mac_descs(lp->dma_rx, lp->dma_rx_size, OWN_BIT);
-		reset_mac_descs(lp->dma_tx, lp->dma_tx_size, 0);
-	}
-	lp->stats.tx_errors++;
+	dma_free_tx_skbufs(dev);
+	lp->mac_type->ops->init_tx_desc(lp->dma_tx, lp->dma_tx_size);
+	lp->dirty_tx = lp->cur_tx = 0;
 	stmmac_dma_start_tx(dev->base_addr);
+
+	lp->stats.tx_errors++;
+	netif_wake_queue(dev);
+
+	spin_unlock(&lp->tx_lock);
 	return;
 }
 
@@ -1047,7 +870,7 @@ static __inline__ void stmmac_tx_err(str
 static void stmmac_dma_interrupt(struct net_device *dev)
 {
 	unsigned int intr_status;
-	unsigned int ioaddr = dev->base_addr;
+	unsigned long ioaddr = dev->base_addr;
 	struct eth_driver_local *lp = netdev_priv(dev);
 
 	/* read the status register (CSR5) */
@@ -1069,27 +892,41 @@ static void stmmac_dma_interrupt(struct 
 	if (unlikely(intr_status & DMA_STATUS_AIS)) {
 		DBG(intr, INFO, "CSR5[15] DMA ABNORMAL IRQ: ");
 		if (unlikely(intr_status & DMA_STATUS_UNF)) {
-			stmmac_restart_tx(dev);
+			DBG(intr, INFO, "transmit underflow\n");
+			stmmac_tx_err(dev);
 			lp->xstats.tx_undeflow_irq++;
 		}
-		if (unlikely(intr_status & DMA_STATUS_TJT))
+		if (unlikely(intr_status & DMA_STATUS_TJT)) {
+			DBG(intr, INFO, "transmit jabber\n");
 			lp->xstats.tx_jabber_irq++;
-		if (unlikely(intr_status & DMA_STATUS_OVF))
+		}
+		if (unlikely(intr_status & DMA_STATUS_OVF)) {
+			DBG(intr, INFO, "recv overflow\n");
 			lp->xstats.rx_overflow_irq++;
-		if (unlikely(intr_status & DMA_STATUS_RU))
+		}
+		if (unlikely(intr_status & DMA_STATUS_RU)) {
+			DBG(intr, INFO, "receive buffer unavailable\n");
 			lp->xstats.rx_buf_unav_irq++;
-		if (unlikely(intr_status & DMA_STATUS_RPS))
+		}
+		if (unlikely(intr_status & DMA_STATUS_RPS)) {
+			DBG(intr, INFO, "receive process stopped\n");
 			lp->xstats.rx_process_stopped_irq++;
-		if (unlikely(intr_status & DMA_STATUS_RWT))
+		}
+		if (unlikely(intr_status & DMA_STATUS_RWT)) {
+			DBG(intr, INFO, "receive watchdog\n");
 			lp->xstats.rx_watchdog_irq++;
+		}
 		if (unlikely(intr_status & DMA_STATUS_ETI)) {
+			DBG(intr, INFO, "transmit early interrupt\n");
 			lp->xstats.tx_early_irq++;
 		}
 		if (unlikely(intr_status & DMA_STATUS_TPS)) {
+			DBG(intr, INFO, "transmit process stopped\n");
 			lp->xstats.tx_process_stopped_irq++;
 			stmmac_tx_err(dev);
 		}
 		if (unlikely(intr_status & DMA_STATUS_FBI)) {
+			DBG(intr, INFO, "fatal bus error\n");
 			lp->xstats.fatal_bus_error_irq++;
 			stmmac_tx_err(dev);
 		}
@@ -1098,7 +935,7 @@ static void stmmac_dma_interrupt(struct 
 	/* NORMAL interrupts */
 	if (likely(intr_status & DMA_STATUS_NIS)) {
 		DBG(intr, INFO, " CSR5[16]: DMA NORMAL IRQ: ");
-		if (likely(intr_status & (DMA_STATUS_RI | DMA_STATUS_ERI))) {
+		if (likely(intr_status & DMA_STATUS_RI)) {
 
 			RX_DBG("Receive irq [buf: 0x%08x]\n",
 			       readl(ioaddr + DMA_CUR_RX_BUF_ADDR));
@@ -1115,12 +952,6 @@ static void stmmac_dma_interrupt(struct 
 			stmmac_tx(dev);
 		}
 	}
-#if 0
-	if ((lp->wolenabled == PMT_SUPPORTED) && 
-		(intr_status & DMA_STATUS_PMT)){
-		readl(ioaddr + MAC_PMT);
-	}
-#endif
 	DBG(intr, INFO, "\n\n");
 
 	return;
@@ -1140,6 +971,14 @@ static int stmmac_enable(struct net_devi
 	unsigned long ioaddr = dev->base_addr;
 	int ret;
 
+	/* Attach the PHY */
+	ret = stmmac_init_phy(dev);
+	if (ret) {
+		printk(KERN_ERR "%s: Cannot attach to PHY (error: %d)\n",
+		       __FUNCTION__, ret);
+		return -ENODEV;
+	}
+
 	/* Request the IRQ lines */
 	ret = request_irq(dev->irq, &stmmac_interrupt,
 			  IRQF_SHARED, dev->name, dev);
@@ -1149,25 +988,31 @@ static int stmmac_enable(struct net_devi
 		       __FUNCTION__, dev->irq, ret);
 		return ret;
 	}
+#ifdef CONFIG_STMMAC_TIMER
+	lp->has_timer = stmmac_timer_open(dev, periodic_rate);
+	if (unlikely(lp->has_timer < 0)) {
+		printk(KERN_WARNING "stmmac: timer opt disabled\n");
+		rx_irq_mitigation = 1;	/* always interrupt on completion */
+	}
+#endif
 
 	/* Create and initialize the TX/RX descriptors rings */
 	init_dma_desc_rings(dev);
 
-	/* Note: the DMA initialization (and SW reset) 
-	 * must be after we have successfully initialised the PHY
-	 * (see comment in stmmac_dma_reset). */
-	if (stmmac_dma_init(dev) < 0) {
+	/* DMA initialization and SW reset */
+	if (lp->mac_type->ops->dma_init(ioaddr, lp->pbl, lp->dma_tx_phy,
+					lp->dma_rx_phy) < 0) {
 		printk(KERN_ERR "%s: DMA initialization failed\n",
 		       __FUNCTION__);
 		return -1;
 	}
 
 	/* Copy the MAC addr into the HW (in case we have set it with nwhw) */
-	set_mac_addr(ioaddr, dev->dev_addr, lp->mac->hw.addr_high,
-		     lp->mac->hw.addr_low);
+	set_mac_addr(ioaddr, dev->dev_addr, lp->mac_type->hw.addr_high,
+		     lp->mac_type->hw.addr_low);
 
 	/* Initialize the MAC Core */
-	lp->mac->ops->core_init(ioaddr);
+	lp->mac_type->ops->core_init(ioaddr);
 	lp->tx_aggregation = 0;
 
 	/* Enable the MAC Rx/Tx */
@@ -1176,20 +1021,30 @@ static int stmmac_enable(struct net_devi
 
 	/* Extra statistics */
 	memset(&lp->xstats, 0, sizeof(struct stmmac_extra_stats));
-	lp->xstats.tx_threshold = lp->ttc = 0x20;	/* 32 DWORDS */
-	lp->mac->ops->dma_ttc(ioaddr, lp->ttc);
+	lp->max_refill_threshold = 0;
+	lp->xstats.threshold = threshold_ctrl;
+
+	/* Estabish the tx/rx operating modes and commands */
+	lp->mac_type->ops->dma_operation_mode(ioaddr, threshold_ctrl);
 
 	/* Start the ball rolling... */
 	DBG(probe, DEBUG, "%s: DMA RX/TX processes started...\n",
 	    ETH_RESOURCE_NAME);
-	stmmac_dma_start_rx(ioaddr);
 	stmmac_dma_start_tx(ioaddr);
+	stmmac_dma_start_rx(ioaddr);
+#ifdef CONFIG_STMMAC_TIMER
+	if (likely(lp->has_timer == 0))
+		stmmac_timer_start(periodic_rate);
+#endif
 
-	/* Dump registers */
+	/* Dump DMA/MAC registers */
 	if (netif_msg_hw(lp)) {
-		lp->mac->ops->mac_registers((unsigned int)ioaddr);
-		lp->mac->ops->dma_registers(ioaddr);
+		lp->mac_type->ops->dump_mac_regs(ioaddr);
+		lp->mac_type->ops->dump_dma_regs(ioaddr);
 	}
+
+	phy_start(lp->phydev);
+
 	return 0;
 }
 
@@ -1204,37 +1059,37 @@ static int stmmac_enable(struct net_devi
  */
 static int stmmac_open(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-	int ret;
-
 	/* Check that the MAC address is valid.  If its not, refuse
 	 * to bring the device up. The user must specify an
 	 * address using the following linux command:
 	 *      ifconfig eth0 hw ether xx:xx:xx:xx:xx:xx  */
 	if (!is_valid_ether_addr(dev->dev_addr)) {
-		DBG(probe, ERR, "%s: no valid eth hw addr\n", __FUNCTION__);
+		printk(KERN_ERR "%s: no valid eth hw addr\n", __FUNCTION__);
 		return -EINVAL;
 	}
 
-	/* Attach the PHY */
-	ret = stmmac_init_phy(dev);
-	if (ret) {
-		printk(KERN_ERR "%s: Cannot attach to PHY (error: %d)\n",
-		       __FUNCTION__, ret);
-		return -ENODEV;
-	}
-
 	/* Enable MAC/DMA, call irq_request and allocate the rings */
 	stmmac_enable(dev);
 
-	phy_start(lp->phydev);
-
 	netif_start_queue(dev);
 	return 0;
 }
 
 static int stmmac_shutdown(struct net_device *dev)
 {
+	struct eth_driver_local *lp = netdev_priv(dev);
+
+	/* Stop and disconnect the PHY */
+	phy_stop(lp->phydev);
+	phy_disconnect(lp->phydev);
+	lp->phydev = NULL;
+
+#ifdef CONFIG_STMMAC_TIMER
+	if (likely(lp->has_timer == 0)) {
+		stmmac_timer_stop();
+		stmmac_timer_close();
+	}
+#endif
 	netif_stop_queue(dev);
 	/* Free the IRQ lines */
 	free_irq(dev->irq, dev);
@@ -1253,6 +1108,18 @@ static int stmmac_shutdown(struct net_de
 	return 0;
 }
 
+static void stmmac_tx_checksum(struct sk_buff *skb)
+{
+	if (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {
+		const int offset = skb_transport_offset(skb);
+		unsigned int csum =
+		    skb_checksum(skb, offset, skb->len - offset, 0);
+		*(u16 *) (skb->data + offset + skb->csum_offset) =
+		    csum_fold(csum);
+	}
+	return;
+}
+
 /**
  *  stmmac_release - close entry point of the driver
  *  @dev : device pointer.
@@ -1264,13 +1131,6 @@ static int stmmac_shutdown(struct net_de
  */
 static int stmmac_release(struct net_device *dev)
 {
-	struct eth_driver_local *lp = netdev_priv(dev);
-
-	/* Stop and disconnect the PHY */
-	phy_stop(lp->phydev);
-	phy_disconnect(lp->phydev);
-	lp->phydev = NULL;
-
 	stmmac_shutdown(dev);
 
 	netif_carrier_off(dev);
@@ -1288,57 +1148,51 @@ static int stmmac_xmit(struct sk_buff *s
 {
 	struct eth_driver_local *lp = netdev_priv(dev);
 	unsigned long flags;
-	unsigned int txsize = lp->dma_tx_size,
+	unsigned int txsize = lp->dma_tx_size, hwcsum,
 	    nfrags = skb_shinfo(skb)->nr_frags,
 	    entry = lp->cur_tx % txsize, i, nopaged_len, first = entry;
 	dma_desc *p = lp->dma_tx;
-	int is_gmac;
 
 	/* This is a hard error log it. */
 	if (unlikely(TX_BUFFS_AVAIL(lp) < nfrags + 1)) {
 		netif_stop_queue(dev);
-		printk(KERN_ERR "%s: BUG! Tx Ring full when queue awake!\n",
+		printk(KERN_ERR "%s: BUG! Tx Ring full when queue awake\n",
 		       dev->name);
 		return NETDEV_TX_BUSY;
 	}
 
-#ifdef STMMAC_XMIT_DEBUG
-	if (nfrags>0)
-		printk("stmmac xmit: len: %d, nopaged_len: %d n_frags: %d\n", 
-			skb->len, nopaged_len, nfrags);
-#endif
 	spin_lock_irqsave(&lp->tx_lock, flags);
 
 	if (unlikely((lp->tx_skbuff[entry] != NULL))) {
-		/* This should never happen! */
-		printk(KERN_ERR "%s: BUG! Inconsistent Tx skb utilization!\n",
+		printk(KERN_ERR "%s: BUG! Inconsistent Tx skb utilization\n",
 		       dev->name);
-		dev_kfree_skb(skb);
+		dev_kfree_skb_any(skb);
+		lp->stats.tx_dropped += 1;
 		return -1;
 	}
-	lp->tx_skbuff[entry] = skb;
 
-	/* Verify the checksum */
-	lp->mac->ops->tx_checksum(skb);
+	hwcsum = 0;
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		if (lp->mac_type->hw.csum == NO_HW_CSUM)
+			stmmac_tx_checksum(skb);
+		else
+			hwcsum = 1;
+	}
 
 	/* Get the amount of non-paged data (skb->data). */
 	nopaged_len = skb_headlen(skb);
-
-	is_gmac = lp->is_gmac;
+#ifdef STMMAC_XMIT_DEBUG
+	if (nfrags > 0)
+		printk("stmmac xmit: len: %d, nopaged_len: %d n_frags: %d\n",
+		       skb->len, nopaged_len, nfrags);
+#endif
 
 	/* Handle non-paged data (skb->data) */
-	if (!is_gmac) {
-		p[entry].des1 = (p[entry].des1 & MAC_CTRL_DESC_TER);
-		p[entry].des1 |= (TDES1_CONTROL_FS | tdes1_buf1_size(nopaged_len));
-	} else { /* GMAC*/
-		p[entry].des0 &= (p[entry].des0 & GMAC_TX_CONTROL_TER);
-		p[entry].des0 |= GMAC_TX_FIRST_SEGMENT;
-		p[entry].des1 = nopaged_len; // size buf 1 (FIXME)
-	}
-	/* Fill buffer 1 */
+	lp->mac_type->ops->prepare_tx_desc((p + entry), 1, nopaged_len, hwcsum);
+	lp->tx_skbuff[entry] = skb;
 	p[entry].des2 = dma_map_single(lp->device, skb->data,
-					STMMAC_ALIGN(nopaged_len), 
-					DMA_TO_DEVICE);
+				       STMMAC_ALIGN(nopaged_len),
+				       DMA_TO_DEVICE);
 	/* Handle paged fragments */
 	for (i = 0; i < nfrags; i++) {
 		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
@@ -1348,42 +1202,21 @@ static int stmmac_xmit(struct sk_buff *s
 		entry = lp->cur_tx % txsize;
 
 #ifdef STMMAC_XMIT_DEBUG
-		if (nfrags>0)
-			printk("\t[entry %d] segment len: %d\n", entry, len);
+		printk("\t[entry %d] segment len: %d\n", entry, len);
 #endif
-		p[entry].des0 = OWN_BIT;
-		if (!is_gmac) {
-			p[entry].des1 = (p[entry].des1 & MAC_CTRL_DESC_TER);
-			p[entry].des1 |= tdes1_buf1_size(len);
-		} else {
-			p[entry].des0 &= (p[entry].des0 & GMAC_TX_CONTROL_TER);
-			p[entry].des1 =  tdes1_buf1_size(len);
-		}
+		lp->mac_type->ops->prepare_tx_desc((p + entry), 0, len, hwcsum);
+		lp->mac_type->ops->set_tx_owner(p + entry);
 		p[entry].des2 = dma_map_page(lp->device, frag->page,
-					     frag->page_offset, 
-					     lp->dma_buf_sz,
-					     DMA_TO_DEVICE);
-
-		if (len > DMA_BUFFER_SIZE) {	/* Fill the second buffer */
-			int b2size = len - DMA_BUFFER_SIZE;
-			p[entry].des1 |= tdes1_buf2_size(b2size);
-			p[entry].des3 = dma_map_page(lp->device, 
-					     frag->page,
-					     frag->page_offset+DMA_BUFFER_SIZE+1, 
+					     frag->page_offset,
 					     lp->dma_buf_sz, DMA_TO_DEVICE);
-		}
 		lp->tx_skbuff[entry] = NULL;
 	}
 
 	/* If there are more than one fragment, we set the interrupt
-	 * on completition field in the latest fragment (where we also set 
-	 * the LS bit. */
-	if (!is_gmac)
-		p[entry].des1 |= TDES1_CONTROL_LS | TDES1_CONTROL_IC;
-	else
-		p[entry].des0 |= GMAC_TX_LAST_SEGMENT | GMAC_TX_IC;
-
-	p[first].des0 |= OWN_BIT;	/* to avoid race condition */
+	 * on completition bit in the latest segment. */
+	lp->mac_type->ops->set_tx_owner(p + first);	/* to avoid raise condition */
+	lp->mac_type->ops->set_tx_ls(p + entry);
+	lp->mac_type->ops->set_tx_ic(p + entry, 1);
 
 	lp->cur_tx++;
 
@@ -1393,20 +1226,20 @@ static int stmmac_xmit(struct sk_buff *s
 		       "first=%d, nfrags=%d\n",
 		       (lp->cur_tx % txsize), (lp->dirty_tx % txsize), entry,
 		       first, nfrags);
-		display_dma_desc_ring(lp->dma_tx, txsize);
+		display_ring(lp->dma_tx, txsize);
 		printk(">>> frame to be transmitted: ");
 		print_pkt(skb->data, skb->len);
 	}
 #endif
 
-	if (TX_BUFFS_AVAIL(lp) <= (MAX_SKB_FRAGS + 1)){
+	if (TX_BUFFS_AVAIL(lp) <= (MAX_SKB_FRAGS + 1) ||
+	    (!(lp->mac_type->hw.link.duplex) && hwcsum)) {
 		netif_stop_queue(dev);
 	} else {
-		/* Allow aggregation of Tx interrupts and clear 
-		   TDES1[31] */
+		/* Aggregation of Tx interrupts */
 		if (lp->tx_aggregation <= tx_aggregation) {
 			lp->tx_aggregation++;
-			p[entry].des1 &= ~TDES1_CONTROL_IC;
+			lp->mac_type->ops->set_tx_ic(p + entry, 0);
 		} else {
 			lp->tx_aggregation = 0;
 		}
@@ -1429,7 +1262,7 @@ static __inline__ void stmmac_rx_refill(
 	struct eth_driver_local *lp = netdev_priv(dev);
 	unsigned int rxsize = lp->dma_rx_size;
 	int bfsize = lp->dma_buf_sz;
-	dma_desc *drx = lp->dma_rx;
+	dma_desc *p = lp->dma_rx;
 
 	for (; lp->cur_rx - lp->dirty_rx > 0; lp->dirty_rx++) {
 		int entry = lp->dirty_rx % rxsize;
@@ -1437,18 +1270,19 @@ static __inline__ void stmmac_rx_refill(
 			struct sk_buff *skb = netdev_alloc_skb(dev, bfsize);
 			if (unlikely(skb == NULL)) {
 				printk(KERN_ERR "%s: skb is NULL\n",
-					__FUNCTION__);
+				       __FUNCTION__);
 				break;
 			}
 			skb_reserve(skb, STMMAC_IP_ALIGN);
 			lp->rx_skbuff[entry] = skb;
 			lp->rx_skbuff_dma[entry] = dma_map_single(lp->device,
-							  skb->data, bfsize,
-							  DMA_FROM_DEVICE);
-			(drx + entry)->des2 = lp->rx_skbuff_dma[entry];
+								  skb->data,
+								  bfsize,
+								  DMA_FROM_DEVICE);
+			(p + entry)->des2 = lp->rx_skbuff_dma[entry];
 			RX_DBG("\trefill entry #%d\n", entry);
 		}
-		(drx + entry)->des0 = OWN_BIT;
+		lp->mac_type->ops->set_rx_owner(p + entry);
 	}
 	return;
 }
@@ -1461,58 +1295,59 @@ static int stmmac_rx(struct net_device *
 
 #ifdef STMMAC_RX_DEBUG
 	printk(">>> stmmac_rx: descriptor ring:\n");
-	display_dma_desc_ring(lp->dma_rx, rxsize);
+	display_ring(lp->dma_rx, rxsize);
 #endif
 	lp->xstats.rx_poll_n++;
 
 	for (count = 0; count < limit; ++count) {
-		dma_desc *drx = lp->dma_rx + entry;
-		unsigned int status = drx->des0;
+		dma_desc *p = lp->dma_rx + entry;
 
-		if (status & OWN_BIT)
+		if (lp->mac_type->ops->read_tx_owner(p))
 			break;
-
-		if (unlikely (((lp->mac->ops->rx_err(&lp->stats, 
-			&lp->xstats, status) < 0)) ||
-				(!(status & RDES0_STATUS_LS)))) {
-
+		/* read the status of the incoming frame */
+		if (unlikely((lp->mac_type->ops->rx_status(&lp->stats,
+							   &lp->xstats,
+							   p) < 0))) {
 			lp->stats.rx_errors++;
-
-			if (unlikely(!(status & RDES0_STATUS_LS))) {
-				printk(KERN_WARNING "%s: Oversized Ethernet "
-				       "frame spanned multiple buffers, entry "
-				       "%#x status %8.8x!\n", dev->name, entry,
-				       status);
-				lp->stats.rx_length_errors++;
-			}
 		} else {
 			struct sk_buff *skb;
 			/* Length should omit the CRC */
-			int frame_len = (((status & RDES0_STATUS_FL_MASK) >>
-					  RDES0_STATUS_FL_SHIFT) - 4);
+			int frame_len =
+			    lp->mac_type->ops->get_rx_frame_len(p) - 4;
 
 			RX_DBG
-			    ("\tquota %d, desc: 0x%0x [entry %d] buff=0x%x\n",
-			     limit, (unsigned int)drx, entry,
-			     drx->des2);
+			    ("\tdesc: 0x%0x [entry %d] buff=0x%x\n",
+			     (unsigned int)p, entry, p->des2);
 
 			/* Check if the packet is long enough to accept without
 			   copying to a minimally-sized skbuff. */
-			if (unlikely(frame_len < rx_copybreak) &&
-			    (skb = netdev_alloc_skb(dev,
-					    STMMAC_ALIGN(frame_len + 2))) != NULL) {
+			if (unlikely(frame_len < rx_copybreak)) {
+				skb =
+				    dev_alloc_skb(STMMAC_ALIGN(frame_len + 2));
+				if (unlikely(!skb)) {
+					if (printk_ratelimit())
+						printk(KERN_NOTICE
+						       "%s: low memory, "
+						       "packet dropped.\n",
+						       dev->name);
+					lp->stats.rx_dropped++;
+					break;
+				}
 
 				skb_reserve(skb, STMMAC_IP_ALIGN);
 				dma_sync_single_for_cpu(lp->device,
-							lp->rx_skbuff_dma[entry],
+							lp->
+							rx_skbuff_dma[entry],
 							frame_len,
 							DMA_FROM_DEVICE);
-				skb_copy_to_linear_data(skb, lp->rx_skbuff[entry]->data, 
-							frame_len);
+				skb_copy_to_linear_data(skb,
+							lp->rx_skbuff[entry]->
+							data, frame_len);
 
 				skb_put(skb, frame_len);
 				dma_sync_single_for_device(lp->device,
-							   lp->rx_skbuff_dma[entry],
+							   lp->
+							   rx_skbuff_dma[entry],
 							   frame_len,
 							   DMA_FROM_DEVICE);
 			} else {	/* zero-copy */
@@ -1539,8 +1374,10 @@ static int stmmac_rx(struct net_device *
 			}
 #endif
 			skb->protocol = eth_type_trans(skb, dev);
-			lp->mac->ops->rx_checksum(skb, status);
-
+			if (lp->mac_type->ops->rx_checksum(p) < 0)
+				skb->ip_summed = CHECKSUM_NONE;
+			else
+				skb->ip_summed = CHECKSUM_UNNECESSARY;
 			netif_receive_skb(skb);
 
 			lp->stats.rx_packets++;
@@ -1549,10 +1386,15 @@ static int stmmac_rx(struct net_device *
 			dev->last_rx = jiffies;
 		}
 		entry = (++lp->cur_rx) % rxsize;
-		drx = lp->dma_rx + entry;
+		p = lp->dma_rx + entry;
 	}
 
-	stmmac_rx_refill(dev);
+	lp->max_refill_threshold += count;
+	if (lp->max_refill_threshold >= (rxsize / 2)) {
+		RX_DBG("\t Rx Fill threshold: %d\n", lp->max_refill_threshold);
+		lp->max_refill_threshold = 0;
+		stmmac_rx_refill(dev);
+	}
 
 	return count;
 }
@@ -1570,6 +1412,9 @@ static int stmmac_rx(struct net_device *
 static int stmmac_poll(struct net_device *dev, int *budget)
 {
 	int work_done;
+#ifdef CONFIG_STMMAC_TIMER
+	struct eth_driver_local *lp = netdev_priv(dev);
+#endif
 
 	work_done = stmmac_rx(dev, dev->quota);
 	dev->quota -= work_done;
@@ -1579,6 +1424,10 @@ static int stmmac_poll(struct net_device
 		RX_DBG(">>> rx work completed.\n");
 		__netif_rx_complete(dev);
 		stmmac_dma_enable_irq_rx(dev->base_addr);
+#ifdef CONFIG_STMMAC_TIMER
+		if (likely(lp->has_timer == 0))
+			stmmac_timer_start(periodic_rate);
+#endif
 		return 0;
 	}
 	return 1;
@@ -1600,22 +1449,20 @@ static void stmmac_tx_timeout(struct net
 	       dev->name, jiffies, (jiffies - dev->trans_start));
 
 #ifdef STMMAC_DEBUG
-	printk("(current=%d, dirty=%d)\n", (lp->cur_tx % lp->dma_tx_size),
+	printk("(current=%d, dirty=%d)\n",
+	       (lp->cur_tx % lp->dma_tx_size),
 	       (lp->dirty_tx % lp->dma_tx_size));
 	printk("DMA tx ring status: \n");
-	display_dma_desc_ring(lp->dma_tx, lp->dma_tx_size);
+	display_ring(lp->dma_tx, lp->dma_tx_size);
 #endif
-	netif_stop_queue(dev);
-
-	spin_lock(&lp->tx_lock);
+	/* Remove tx optmizarion */
 	tx_aggregation = -1;
 	lp->tx_aggregation = 0;
-	/* Clear Tx resources */
+
+	/* Clear Tx resources and restart transmitting again */
 	stmmac_tx_err(dev);
-	dev->trans_start = jiffies;
-	netif_wake_queue(dev);
 
-	spin_unlock(&lp->tx_lock);
+	dev->trans_start = jiffies;
 
 	return;
 }
@@ -1628,6 +1475,10 @@ static void stmmac_tx_timeout(struct net
 struct net_device_stats *stmmac_stats(struct net_device *dev)
 {
 	struct eth_driver_local *lp = netdev_priv(dev);
+	unsigned long ioaddr = dev->base_addr;
+
+	lp->mac_type->ops->dma_diagnostic_fr(&lp->stats, &lp->xstats, ioaddr);
+
 	return &lp->stats;
 }
 
@@ -1669,7 +1520,7 @@ static void stmmac_multicast_list(struct
 	struct eth_driver_local *lp = netdev_priv(dev);
 
 	/* Calling the hw function. */
-	lp->mac->ops->set_filter(dev);
+	lp->mac_type->ops->set_filter(dev);
 
 	return;
 }
@@ -1688,8 +1539,8 @@ static void stmmac_multicast_list(struct
 static int stmmac_change_mtu(struct net_device *dev, int new_mtu)
 {
 	if (netif_running(dev)) {
-		printk(KERN_ERR "%s: must be stopped to change its MTU\n",
-		       dev->name);
+		printk(KERN_ERR
+		       "%s: must be stopped to change its MTU\n", dev->name);
 		return -EBUSY;
 	}
 
@@ -1795,9 +1646,7 @@ static int stmmac_probe(struct net_devic
 	dev->set_config = stmmac_config;
 
 	dev->hard_start_xmit = stmmac_xmit;
-	if (!lp->is_gmac) /*FIXME*/
-		dev->features |= (NETIF_F_SG | NETIF_F_HW_CSUM | 
-					NETIF_F_HIGHDMA);
+	dev->features |= (NETIF_F_SG | NETIF_F_HW_CSUM | NETIF_F_HIGHDMA);
 
 	dev->get_stats = stmmac_stats;
 	dev->tx_timeout = stmmac_tx_timeout;
@@ -1817,7 +1666,8 @@ static int stmmac_probe(struct net_devic
 
 	lp->msg_enable = netif_msg_init(debug, default_msg_level);
 
-	lp->rx_csum = 0;
+	if (lp->is_gmac)
+		lp->rx_csum = 1;
 
 	/* Just to keep aligned values. */
 	lp->dma_tx_size = STMMAC_ALIGN(dma_tx_size_param);
@@ -1834,7 +1684,7 @@ static int stmmac_probe(struct net_devic
 
 	/* Get the MAC address */
 	get_mac_address(dev->base_addr, dev->dev_addr,
-			lp->mac->hw.addr_high, lp->mac->hw.addr_low);
+			lp->mac_type->hw.addr_high, lp->mac_type->hw.addr_low);
 
 	if (!is_valid_ether_addr(dev->dev_addr)) {
 		printk(KERN_WARNING "\tno valid MAC address; "
@@ -1847,6 +1697,10 @@ static int stmmac_probe(struct net_devic
 		return -ENODEV;
 	}
 
+	DBG(probe, DEBUG, "%s: Scatter/Gather: %s - HW checksums: %s\n",
+	    dev->name, (dev->features & NETIF_F_SG) ? "on" : "off",
+	    (dev->features & NETIF_F_HW_CSUM) ? "on" : "off");
+
 	spin_lock_init(&lp->lock);
 	spin_lock_init(&lp->tx_lock);
 
@@ -1870,8 +1724,8 @@ static __inline__ void stmmac_mac_device
 		device = gmac_setup(ioaddr);
 	else
 		device = mac100_setup(ioaddr);
-	lp->mac = device;
-	lp->wolenabled = lp->mac->hw.pmt; // PMT supported
+	lp->mac_type = device;
+	lp->wolenabled = lp->mac_type->hw.pmt;	// PMT supported
 
 	return;
 }
@@ -2046,7 +1900,7 @@ static int stmmac_dvr_probe(struct platf
 	/* MDIO bus Registration */
 	printk(KERN_DEBUG "registering MDIO bus...\n");
 	ret = stmmac_mdio_register(ndev);
-	printk(KERN_DEBUG "registering MDIO bus done\n");
+	printk(KERN_DEBUG "MDIO bus registered!\n");
 	ndev = __dev_get_by_name("eth0");
 
       out:
@@ -2108,24 +1962,20 @@ static void stmmac_powerdown(struct net_
 	stmmac_mac_disable_rx(dev);
 
 	/* Sanity state for the rings */
-	if (lp->is_gmac) {
-		reset_gmac_descs(lp->dma_rx, lp->dma_rx_size, OWN_BIT);
-		reset_gmac_descs(lp->dma_tx, lp->dma_tx_size, 0);
-	} else {
-		reset_mac_descs(lp->dma_rx, lp->dma_rx_size, OWN_BIT);
-		reset_mac_descs(lp->dma_tx, lp->dma_tx_size, 0);
-	}
+	lp->mac_type->ops->init_rx_desc(lp->dma_rx, lp->dma_rx_size,
+					rx_irq_mitigation);
+	lp->mac_type->ops->init_tx_desc(lp->dma_tx, lp->dma_tx_size);
 
 	/* Enable Power down mode by programming the PMT regs */
 	if (lp->wolenabled == PMT_SUPPORTED)
-		lp->mac->ops->enable_wol(dev->base_addr, lp->wolopts);
+		lp->mac_type->ops->pmt(dev->base_addr, lp->wolopts);
 
 	/* Enable receiver */
 	stmmac_mac_enable_rx(dev);
 
 	return;
 }
- 
+
 static int stmmac_suspend(struct platform_device *pdev, pm_message_t state)
 {
 	struct net_device *dev = platform_get_drvdata(pdev);
@@ -2136,7 +1986,7 @@ static int stmmac_suspend(struct platfor
 	if (!dev || !netif_running(dev))
 		return 0;
 
-	if (state.event==PM_EVENT_SUSPEND && device_may_wakeup(&(pdev->dev))){
+	if (state.event == PM_EVENT_SUSPEND && device_may_wakeup(&(pdev->dev))) {
 		stmmac_powerdown(dev);
 		return 0;
 	}
@@ -2152,11 +2002,15 @@ static int stmmac_suspend(struct platfor
 static int stmmac_resume(struct platform_device *pdev)
 {
 	struct net_device *dev = platform_get_drvdata(pdev);
+	struct eth_driver_local *lp = netdev_priv(dev);
 
 	spin_lock(&lp->lock);
 	if (!netif_running(dev))
 		return 0;
 
+	if (lp->mii->reset)
+		stmmac_mdio_reset(lp->mii);
+
 	netif_device_attach(dev);
 
 	stmmac_enable(dev);
@@ -2227,8 +2081,16 @@ static int __init stmmac_cmdline_opt(cha
 			flow_ctrl = simple_strtoul(opt + 10, NULL, 0);
 		} else if (!strncmp(opt, "pause:", 6)) {
 			pause = simple_strtoul(opt + 6, NULL, 0);
-		} else if (!strncmp(opt, "txopt:", 6)) {
+		} else if (!strncmp(opt, "tc:", 3)) {
+			threshold_ctrl = simple_strtoul(opt + 3, NULL, 0);
+		} else if (!strncmp(opt, "txmit:", 6)) {
 			tx_aggregation = simple_strtoul(opt + 6, NULL, 0);
+		} else if (!strncmp(opt, "rxmit:", 6)) {
+			rx_irq_mitigation = simple_strtoul(opt + 6, NULL, 0);
+#ifdef CONFIG_STMMAC_TIMER
+		} else if (!strncmp(opt, "period:", 7)) {
+			periodic_rate = simple_strtoul(opt + 7, NULL, 0);
+#endif
 		}
 	}
 	return 0;
@@ -2240,5 +2102,5 @@ module_init(stmmac_init_module);
 module_exit(stmmac_cleanup_module);
 
 MODULE_DESCRIPTION("STMMAC 10/100/1000 Ethernet driver");
-MODULE_AUTHOR("Giuseppe Cavallaro");
+MODULE_AUTHOR("Giuseppe Cavallaro <peppe.cavallaro@st.com>");
 MODULE_LICENSE("GPL");
diff -uprN linux.orig/drivers/net/stmmac/stmmac_mdio.c linux/drivers/net/stmmac/stmmac_mdio.c
--- linux.orig/drivers/net/stmmac/stmmac_mdio.c	2008-03-18 07:25:12.000000000 +0100
+++ linux/drivers/net/stmmac/stmmac_mdio.c	2008-03-13 16:29:46.639999000 +0100
@@ -41,13 +41,13 @@ int stmmac_mdio_read(struct mii_bus *bus
 	struct net_device *ndev = bus->priv;
 	struct eth_driver_local *lp = netdev_priv(ndev);
 	unsigned long ioaddr = ndev->base_addr;
-	unsigned int mii_address = lp->mac->hw.mii.addr;
-	unsigned int mii_data = lp->mac->hw.mii.data;
+	unsigned int mii_address = lp->mac_type->hw.mii.addr;
+	unsigned int mii_data = lp->mac_type->hw.mii.data;
 
 	int data;
 	u16 regValue = (((phyaddr << 11) & (0x0000F800)) |
 			((phyreg << 6) & (0x000007C0)));
-	regValue |= MII_BUSY; // GMAC
+	regValue |= MII_BUSY;	// GMAC
 
 	while (((readl(ioaddr + mii_address)) & MII_BUSY) == 1) {
 	}
@@ -75,14 +75,14 @@ int stmmac_mdio_write(struct mii_bus *bu
 	struct net_device *ndev = bus->priv;
 	struct eth_driver_local *lp = netdev_priv(ndev);
 	unsigned long ioaddr = ndev->base_addr;
-	unsigned int mii_address = lp->mac->hw.mii.addr;
-	unsigned int mii_data = lp->mac->hw.mii.data;
+	unsigned int mii_address = lp->mac_type->hw.mii.addr;
+	unsigned int mii_data = lp->mac_type->hw.mii.data;
 
 	u16 value =
 	    (((phyaddr << 11) & (0x0000F800)) | ((phyreg << 6) & (0x000007C0)))
 	    | MII_WRITE;
 
-	value |= MII_BUSY; // GMAC
+	value |= MII_BUSY;	// GMAC
 
 	/* Wait until any existing MII operation is complete */
 	while (((readl(ioaddr + mii_address)) & MII_BUSY) == 1) {
@@ -108,7 +108,7 @@ int stmmac_mdio_reset(struct mii_bus *bu
 	struct net_device *ndev = bus->priv;
 	struct eth_driver_local *lp = netdev_priv(ndev);
 	unsigned long ioaddr = ndev->base_addr;
-	unsigned int mii_address = lp->mac->hw.mii.addr;
+	unsigned int mii_address = lp->mac_type->hw.mii.addr;
 
 	printk(KERN_DEBUG "stmmac_mdio_reset: called!\n");
 
@@ -144,14 +144,15 @@ int stmmac_mdio_register(struct net_devi
 	/* Assign IRQ to phy at address phy_addr */
 	irqlist[lp->phy_addr] = lp->phy_irq;
 
-	new_bus->name = "STMMAC MII Bus",
-	    new_bus->read = &stmmac_mdio_read,
-	    new_bus->write = &stmmac_mdio_write,
-	    new_bus->reset = &stmmac_mdio_reset, new_bus->id = (int)lp->bus_id;
+	new_bus->name = "STMMAC MII Bus";
+	new_bus->read = &stmmac_mdio_read;
+	new_bus->write = &stmmac_mdio_write;
+	new_bus->reset = &stmmac_mdio_reset;
+	new_bus->id = (int)lp->bus_id;
 	new_bus->priv = ndev;
 	new_bus->irq = irqlist;
 	new_bus->phy_mask = lp->phy_mask;
-	new_bus->dev = 0;	/* FIXME */
+	new_bus->dev = lp->device;
 	printk(KERN_DEBUG "calling mdiobus_register\n");
 	err = mdiobus_register(new_bus);
 	printk(KERN_DEBUG "calling mdiobus_register done\n");
diff -uprN linux.orig/drivers/net/stmmac/stmmac_timer.c linux/drivers/net/stmmac/stmmac_timer.c
--- linux.orig/drivers/net/stmmac/stmmac_timer.c	1970-01-01 01:00:00.000000000 +0100
+++ linux/drivers/net/stmmac/stmmac_timer.c	2008-03-14 08:22:37.989999000 +0100
@@ -0,0 +1,80 @@
+/* 
+ * drivers/net/stmmac/stmmac_timer.c
+ *
+ * Timer-driver-interrupt optimization
+ *
+ * Copyright (C) 2007 by STMicroelectronics
+ * Author: Giuseppe Cavallaro <peppe.cavallaro@st.com>
+ *
+*/
+
+#include <linux/kernel.h>
+#include <linux/etherdevice.h>
+#include <linux/rtc.h>
+
+struct rtc_device *stmmac_rtc;
+rtc_task_t stmmac_task;
+
+extern void stmmac_dma_disable_irq_rx(unsigned long ioaddr);
+
+int stmmac_timer_close(void)
+{
+	rtc_irq_unregister(stmmac_rtc, &stmmac_task);
+	rtc_class_close(stmmac_rtc);
+	return 0;
+}
+int stmmac_timer_start(unsigned int freq)
+{
+	rtc_irq_set_freq(stmmac_rtc, &stmmac_task, freq);
+	rtc_irq_set_state(stmmac_rtc, &stmmac_task, 1);
+	return 0;
+}
+
+int stmmac_timer_stop(void)
+{
+	rtc_irq_set_state(stmmac_rtc, &stmmac_task, 0);
+	return 0;
+}
+
+/*
+ * Use periodic interrupt for scheduling the reception process
+ */
+static void stmmac_rtc_handler(void *priv)
+{
+	struct net_device *dev = (struct net_device *)priv;
+	unsigned long ioaddr = dev->base_addr;
+
+	if (likely(netif_rx_schedule_prep(dev))) {
+		stmmac_timer_stop();
+		stmmac_dma_disable_irq_rx(ioaddr);
+		__netif_rx_schedule(dev);
+	}
+	return;
+}
+
+int stmmac_timer_open(struct net_device *dev, unsigned int freq)
+{
+	stmmac_task.private_data = dev;
+	stmmac_task.func = stmmac_rtc_handler;
+
+	stmmac_rtc = rtc_class_open(CONFIG_RTC_HCTOSYS_DEVICE);
+	if (stmmac_rtc == NULL){
+		printk(KERN_ERR "open rtc device failed\n");
+		return -ENODEV;
+	}
+
+	rtc_irq_register(stmmac_rtc, &stmmac_task);
+
+	/* Periodic mode is not supported */
+	if ((rtc_irq_set_freq(stmmac_rtc, &stmmac_task, freq) < 0)) {
+		printk(KERN_ERR "set periodic failed\n");
+		rtc_irq_unregister(stmmac_rtc, &stmmac_task);
+		rtc_class_close(stmmac_rtc);
+		return -1;
+	}
+
+	printk(KERN_INFO "stmmac_timer enabled - %s (freq %dHz)\n",
+	       CONFIG_RTC_HCTOSYS_DEVICE, freq);
+
+	return 0;
+}
--- linux.orig/drivers/net/Kconfig	2008-03-07 14:51:50.000000000 +0100
+++ linux/drivers/net/Kconfig	2008-03-13 16:38:14.879999000 +0100
@@ -2506,6 +2506,24 @@ config STMMAC_ETH
 	  This driver also supports the old embedded on-chip Ethernet in the
 	  Stb7109 CPU.
 
+config STMMAC_DA
+	depends on STMMAC_ETH
+	bool "STMMAC DMA arbitration scheme"
+	default n
+	---help---
+	  Selecting this option, rx has priority over Tx only for Giga Ethernet device,
+	  By default, the DMA arbitration scheme is based on Round-robin 
+	  (rx:tx priority is 1:1).
+
+config STMMAC_TIMER
+	depends on STMMAC_ETH && RTC_CLASS && EXPERIMENTAL
+	bool "STMMAC Timer optimization (EXPERIMENTAL)"
+	default n
+	---help---
+	  Real time clock device generates an interrupt at regular 
+	  intervals in order to notify the Ethernet driver about frame 
+	  receptions.
+
 endif # NETDEV_1000
 
 #
