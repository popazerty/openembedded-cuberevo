From 0701aa5ec99f29fc985f2250a422767716f1265b Mon Sep 17 00:00:00 2001
From: Pawel Moll <pawel.moll@st.com>
Date: Wed, 11 Feb 2009 13:46:25 +0000
Subject: [PATCH] stm_fdma: driver code clean-up and bug fix

This patch cleans up the fdma code by using approved code
conventions, cleaner naming and interface unification.

Bug fixes:
o  Fix case when CONFIG_MIN_STM_DMA_CHANNEL_NR != 0
o  fdma_irq() was returning wrong value in case of
out-of-interest interrupts pending...

Signed-off-by: Pawel Moll <pawel.moll@st.com>
---
 drivers/stm/710x_fdma2.c | 1303 +++++++++++++++++++++++-----------------------
 drivers/stm/fdma.h       |  119 ++---
 2 files changed, 695 insertions(+), 727 deletions(-)

diff --git a/drivers/stm/710x_fdma2.c b/drivers/stm/710x_fdma2.c
index edbe0f1..57b690a 100644
--- a/drivers/stm/710x_fdma2.c
+++ b/drivers/stm/710x_fdma2.c
@@ -4,7 +4,7 @@
  *          Stuart Menefy <stuart.menefy@st.com>
  *
  * May be copied or modified under the terms of the GNU General Public
- * License.  See linux/COPYING for more information.
+ * License. See linux/COPYING for more information.
  */
 
 #include <linux/interrupt.h>
@@ -14,166 +14,161 @@
 #include <linux/dmapool.h>
 #include <linux/stm/fdma-plat.h>
 #include <linux/stm/stm-dma.h>
-
 #include "fdma.h"
 
 
 
-static int setup_freerunning_node(struct stm_dma_params *params,
-				  struct fdma_llu_entry* llu)
+static int fdma_setup_freerunning_node(struct stm_dma_params *params,
+		struct fdma_llu_entry *llu)
 {
 	memset(llu, 0, sizeof(*llu));
 
 	if (params->node_pause)
-		llu->control |=  SET_NODE_COMP_PAUSE | SET_NODE_COMP_IRQ;
+		llu->control |= SET_NODE_COMP_PAUSE | SET_NODE_COMP_IRQ;
 
 	if (params->node_interrupt)
 		llu->control |= SET_NODE_COMP_IRQ;
 
-	if (DIM_SRC(params->dim) == 0) {
-		llu->control |= NODE_ADDR_STATIC <<SOURCE_ADDR;
-	} else {
-		llu->control |= NODE_ADDR_INCR <<SOURCE_ADDR;
-	}
+	if (DIM_SRC(params->dim) == 0)
+		llu->control |= NODE_ADDR_STATIC << SOURCE_ADDR;
+	else
+		llu->control |= NODE_ADDR_INCR << SOURCE_ADDR;
 
-	if (DIM_DST(params->dim) == 0) {
-		llu->control |= NODE_ADDR_STATIC <<DEST_ADDR;
-	} else {
-		llu->control |= NODE_ADDR_INCR <<DEST_ADDR;
-	}
+	if (DIM_DST(params->dim) == 0)
+		llu->control |= NODE_ADDR_STATIC << DEST_ADDR;
+	else
+		llu->control |= NODE_ADDR_INCR << DEST_ADDR;
 
-	llu->line_len		= params->line_len;
-	llu->sstride 		= params->sstride;
-	llu->dstride 		= params->dstride;
+	llu->line_len = params->line_len;
+	llu->sstride = params->sstride;
+	llu->dstride = params->dstride;
 	return 0;
 }
 
-static int setup_paced_node(struct stm_dma_params *params,
-			    fdma_llu_entry* llu)
+static int fdma_setup_paced_node(struct stm_dma_params *params,
+		struct fdma_llu_entry *llu)
 
 {
 	memset(llu, 0, sizeof(*llu));
 
 	/* Moved this into the extrapolate functions so that we can
 	 * change channel in the same way as address. Yech */
-	/* llu->control= params->req_line; */
-	llu->size_bytes= params->node_bytes;
+	/* llu->control = params->req_line; */
+	llu->size_bytes = params->node_bytes;
 	llu->line_len = params->node_bytes;
 
 	if (params->node_pause)
 		/* In order to recieve the pause interrupt
 		 * we must also enable end of node interrupts. */
-		llu->control |=  SET_NODE_COMP_PAUSE | SET_NODE_COMP_IRQ;
+		llu->control |= SET_NODE_COMP_PAUSE | SET_NODE_COMP_IRQ;
 
 	if (params->node_interrupt)
 		llu->control |= SET_NODE_COMP_IRQ;
 
-	if (DIM_SRC(params->dim) == 0) {
-		llu->control |= NODE_ADDR_STATIC <<SOURCE_ADDR;
-	} else {
-		llu->control |= NODE_ADDR_INCR <<SOURCE_ADDR;
-	}
+	if (DIM_SRC(params->dim) == 0)
+		llu->control |= NODE_ADDR_STATIC << SOURCE_ADDR;
+	else
+		llu->control |= NODE_ADDR_INCR << SOURCE_ADDR;
 
-	if (DIM_DST(params->dim) == 0) {
-		llu->control |= NODE_ADDR_STATIC <<DEST_ADDR;
-	} else {
-		llu->control |= NODE_ADDR_INCR <<DEST_ADDR;
-	}
+	if (DIM_DST(params->dim) == 0)
+		llu->control |= NODE_ADDR_STATIC << DEST_ADDR;
+	else
+		llu->control |= NODE_ADDR_INCR << DEST_ADDR;
 
 	return 0;
 }
 
-static struct llu_node* extrapolate_simple(
-	struct stm_dma_params *params,
-	struct dma_xfer_descriptor *desc,
-	struct llu_node* llu_node)
+static struct fdma_llu_node *fdma_extrapolate_simple(
+		struct stm_dma_params *params,
+		struct fdma_xfer_descriptor *desc,
+		struct fdma_llu_node *llu_node)
 {
-	struct fdma_llu_entry* dest_llu = llu_node->virt_addr;
+	struct fdma_llu_entry *dest_llu = llu_node->virt_addr;
 
-	dest_llu->control	= desc->template_llu.control |
-		(params->req ? params->req->local_req_line : 0);
-	dest_llu->size_bytes	= params->node_bytes;
-	dest_llu->saddr		= params->sar;
-	dest_llu->daddr		= params->dar;
+	dest_llu->control = desc->template_llu.control |
+			(params->req ? params->req->local_req_line : 0);
+	dest_llu->size_bytes = params->node_bytes;
+	dest_llu->saddr	 = params->sar;
+	dest_llu->daddr	 = params->dar;
 	if (desc->extrapolate_line_len)
 		dest_llu->line_len = params->node_bytes;
 	else
 		dest_llu->line_len = desc->template_llu.line_len;
-	dest_llu->sstride	= desc->template_llu.sstride;
-	dest_llu->dstride	= desc->template_llu.dstride;
+	dest_llu->sstride = desc->template_llu.sstride;
+	dest_llu->dstride = desc->template_llu.dstride;
 
 	return llu_node;
 }
 
-static struct llu_node* extrapolate_sg_src(
-	struct stm_dma_params *params,
-	struct dma_xfer_descriptor *desc,
-	struct llu_node* llu_node)
+static struct fdma_llu_node *fdma_extrapolate_sg_src(
+		struct stm_dma_params *params,
+		struct fdma_xfer_descriptor *desc,
+		struct fdma_llu_node *llu_node)
 {
 	int i;
-	struct scatterlist * sg = params->srcsg;
-	struct llu_node* last_llu_node = llu_node;
+	struct scatterlist *sg = params->srcsg;
+	struct fdma_llu_node *last_llu_node = llu_node;
 
-	for (i=0; i<params->sglen; i++) {
-		struct fdma_llu_entry* dest_llu = llu_node->virt_addr;
+	for (i = 0; i < params->sglen; i++) {
+		struct fdma_llu_entry *dest_llu = llu_node->virt_addr;
 
-		dest_llu->control	= desc->template_llu.control;
-		dest_llu->size_bytes	= sg_dma_len(sg);
-		dest_llu->saddr		= sg_dma_address(sg);
-		dest_llu->daddr		= params->dar;
+		dest_llu->control = desc->template_llu.control;
+		dest_llu->size_bytes = sg_dma_len(sg);
+		dest_llu->saddr	= sg_dma_address(sg);
+		dest_llu->daddr	= params->dar;
 		if (desc->extrapolate_line_len)
 			dest_llu->line_len = sg_dma_len(sg);
 		else
 			dest_llu->line_len = desc->template_llu.line_len;
-		dest_llu->sstride	= desc->template_llu.sstride;
-		dest_llu->dstride	= 0;
+		dest_llu->sstride = desc->template_llu.sstride;
+		dest_llu->dstride = 0;
 
 		last_llu_node = llu_node++;
-		dest_llu->next_item	= llu_node->dma_addr;
+		dest_llu->next_item = llu_node->dma_addr;
 		sg++;
 	}
 
 	return last_llu_node;
 }
 
-static struct llu_node* extrapolate_sg_dst(
-	struct stm_dma_params *params,
-	struct dma_xfer_descriptor *desc,
-	struct llu_node* llu_node)
+static struct fdma_llu_node *fdma_extrapolate_sg_dst(
+		struct stm_dma_params *params,
+		struct fdma_xfer_descriptor *desc,
+		struct fdma_llu_node *llu_node)
 {
 	int i;
-	struct scatterlist * sg = params->dstsg;
-	struct llu_node* last_llu_node = llu_node;
+	struct scatterlist *sg = params->dstsg;
+	struct fdma_llu_node *last_llu_node = llu_node;
 
-	for (i=0; i<params->sglen; i++) {
-		struct fdma_llu_entry* dest_llu = llu_node->virt_addr;
+	for (i = 0; i < params->sglen; i++) {
+		struct fdma_llu_entry *dest_llu = llu_node->virt_addr;
 
-		dest_llu->control	= desc->template_llu.control;
-		dest_llu->size_bytes	= sg_dma_len(sg);
-		dest_llu->saddr		= params->sar;
-		dest_llu->daddr		= sg_dma_address(sg);
+		dest_llu->control = desc->template_llu.control;
+		dest_llu->size_bytes = sg_dma_len(sg);
+		dest_llu->saddr	 = params->sar;
+		dest_llu->daddr	 = sg_dma_address(sg);
 		if (desc->extrapolate_line_len)
 			dest_llu->line_len = sg_dma_len(sg);
 		else
 			dest_llu->line_len = desc->template_llu.line_len;
-		dest_llu->sstride	= 0;
-		dest_llu->dstride	= desc->template_llu.dstride;
+		dest_llu->sstride = 0;
+		dest_llu->dstride = desc->template_llu.dstride;
 
 		last_llu_node = llu_node++;
-		dest_llu->next_item	= llu_node->dma_addr;
+		dest_llu->next_item = llu_node->dma_addr;
 		sg++;
 	}
 
 	return last_llu_node;
 }
 
-static int resize_nodelist_mem(struct fdma_dev * fd,
-			       struct dma_xfer_descriptor *desc,
-			       unsigned int new_nnodes, gfp_t context)
+static int fdma_resize_nodelist_mem(struct fdma *fdma,
+		struct fdma_xfer_descriptor *desc, unsigned int new_nnodes,
+		gfp_t context)
 {
 	int old_list_size, new_list_size;
 	unsigned int cur_nnodes;
-	struct llu_node* new_nodes;
+	struct fdma_llu_node *new_nodes;
 
 	/* This holds the number of allocated nodes, which may differ
 	 * from the old or new size. It must be maintained so that
@@ -181,12 +176,11 @@ static int resize_nodelist_mem(struct fdma_dev * fd,
 	cur_nnodes = desc->alloced_nodes;
 
 	/* The only resize down we need to support is freeing everything. */
-	if (new_nnodes == 0) {
+	if (new_nnodes == 0)
 		goto free_list;
-	}
 
-	old_list_size = sizeof(struct llu_node)*desc->alloced_nodes;
-	new_list_size = sizeof(struct llu_node)*new_nnodes;
+	old_list_size = sizeof(struct fdma_llu_node) * desc->alloced_nodes;
+	new_list_size = sizeof(struct fdma_llu_node) * new_nnodes;
 	new_nodes = kmalloc(new_list_size, context);
 	if (new_nodes == NULL)
 		goto free_list;
@@ -198,13 +192,10 @@ static int resize_nodelist_mem(struct fdma_dev * fd,
 
 	desc->llu_nodes = new_nodes;
 
-	for (new_nodes += desc->alloced_nodes;
-	     cur_nnodes < new_nnodes;
-	     cur_nnodes++, new_nodes++) {
-		new_nodes->virt_addr = dma_pool_alloc(
-					fd->llu_pool,
-					context,
-					&new_nodes->dma_addr);
+	for (new_nodes += desc->alloced_nodes; cur_nnodes < new_nnodes;
+			cur_nnodes++, new_nodes++) {
+		new_nodes->virt_addr = dma_pool_alloc(fdma->llu_pool,
+				context, &new_nodes->dma_addr);
 		if (new_nodes->virt_addr == NULL)
 			goto free_list;
 	}
@@ -213,12 +204,10 @@ static int resize_nodelist_mem(struct fdma_dev * fd,
 	return 0;
 
 free_list:
-	new_nodes = desc->llu_nodes;
-	for( ; cur_nnodes; cur_nnodes--, new_nodes++) {
-		dma_pool_free(fd->llu_pool,
-			      new_nodes->virt_addr,
-			      new_nodes->dma_addr);
-	}
+	for (new_nodes = desc->llu_nodes; cur_nnodes;
+			cur_nnodes--, new_nodes++)
+		dma_pool_free(fdma->llu_pool, new_nodes->virt_addr,
+				new_nodes->dma_addr);
 	if (desc->llu_nodes)
 		kfree(desc->llu_nodes);
 
@@ -228,87 +217,88 @@ free_list:
 	return -ENOMEM;
 }
 
-static void fdma_start_channel(struct fdma_dev * fd,
-			      int ch_num,
-			      unsigned long start_addr,
-			       unsigned long initial_count)
+static void fdma_start_channel(struct fdma_channel *channel,
+		unsigned long start_addr, unsigned long initial_count)
 {
+	struct fdma *fdma = channel->fdma;
 	u32 cmd_sta_value = (start_addr | CMDSTAT_FDMA_START_CHANNEL);
 
-	/* See comment in stb710x_fdma_get_residue() for why we do this. */
-	writel(initial_count,
-	       fd->io_base + (ch_num * NODE_DATA_OFFSET) + fd->regs.fdma_cntn);
+	/* See comment in fdma_get_residue() for why we do this. */
+	writel(initial_count, fdma->io_base + (channel->chan_num *
+			NODE_DATA_OFFSET) + fdma->regs.fdma_cntn);
 
-	writel(cmd_sta_value,CMD_STAT_REG(ch_num));
-	writel(MBOX_STR_CMD(ch_num),fd->io_base +fd->regs.fdma_cmd_set);
+	writel(cmd_sta_value, CMD_STAT_REG(channel->chan_num));
+	writel(MBOX_CMD_START_CHANNEL << (channel->chan_num * 2),
+			fdma->io_base + fdma->regs.fdma_cmd_set);
 }
 
-static int stb710x_get_engine_status(struct fdma_dev * fd,int channel)
+static int fdma_get_engine_status(struct fdma_channel *channel)
 {
-	return readl(CMD_STAT_REG(channel))&3;
+	struct fdma *fdma = channel->fdma;
+
+	return readl(CMD_STAT_REG(channel->chan_num)) & 3;
 }
 
-static inline void __handle_fdma_err_irq(struct fdma_dev *fd, int chan_num)
+static inline void fdma_handle_fdma_err_irq(struct fdma_channel *channel)
 {
-	struct channel_status *chan = &fd->channel[chan_num];
-	void (*err_cb)(unsigned long) = chan->params->err_cb;
-	unsigned long err_cb_parm = chan->params->err_cb_parm;
+	struct fdma *fdma = channel->fdma;
+	void (*err_cb)(unsigned long) = channel->params->err_cb;
+	unsigned long err_cb_parm = channel->params->err_cb_parm;
 
-	spin_lock(&fd->channel_lock);
+	spin_lock(&fdma->channels_lock);
 
-	/*err is bits 2-4*/
-	fdma_dbg(fd, "%s: FDMA error %d on channel %d\n", __FUNCTION__,
+	/* err is bits 2-4 */
+	fdma_dbg(fdma, "%s: FDMA error %d on channel %d\n", __FUNCTION__,
 			(readl(CMD_STAT_REG(chan_num)) >> 2) & 0x7, chan_num);
 
 	/* According to the spec, in case of error transfer "may be
 	 * aborted" (or may not be, sigh) so let's make the situation
 	 * clear and stop it explicitly now. */
-	writel(MBOX_CMD_PAUSE_CHANNEL << (chan_num * 2),
-			fd->io_base + fd->regs.fdma_cmd_set);
-	chan->sw_state = FDMA_STOPPING;
+	writel(MBOX_CMD_PAUSE_CHANNEL << (channel->chan_num * 2),
+			fdma->io_base + fdma->regs.fdma_cmd_set);
+	channel->sw_state = FDMA_STOPPING;
 
-	spin_unlock(&fd->channel_lock);
+	spin_unlock(&fdma->channels_lock);
 
-	wake_up(&chan->cur_cfg->wait_queue);
+	wake_up(&channel->dma_chan->wait_queue);
 
 	if (err_cb) {
-		if (chan->params->err_cb_isr)
+		if (channel->params->err_cb_isr)
 			err_cb(err_cb_parm);
 		else
-			tasklet_schedule(&chan->fdma_error);
+			tasklet_schedule(&channel->fdma_error);
 	}
 }
 
-static inline void __handle_fdma_completion_irq(struct fdma_dev *fd,
-		int chan_num)
+static inline void fdma_handle_fdma_completion_irq(struct fdma_channel *channel)
 {
-	struct channel_status *chan = &fd->channel[chan_num];
-	void (*comp_cb)(unsigned long) = chan->params->comp_cb;
-	unsigned long comp_cb_parm = chan->params->comp_cb_parm;
+	struct fdma *fdma = channel->fdma;
+	void (*comp_cb)(unsigned long) = channel->params->comp_cb;
+	unsigned long comp_cb_parm = channel->params->comp_cb_parm;
 
-	spin_lock(&fd->channel_lock);
+	spin_lock(&fdma->channels_lock);
 
-	switch (stb710x_get_engine_status(fd, chan_num)) {
+	switch (fdma_get_engine_status(channel)) {
 	case FDMA_CHANNEL_PAUSED:
-		switch (chan->sw_state) {
+		switch (channel->sw_state) {
 		case FDMA_RUNNING:	/* Hit a pause node */
 		case FDMA_PAUSING:
-			chan->sw_state = FDMA_PAUSED;
+			channel->sw_state = FDMA_PAUSED;
 			break;
 		case FDMA_STOPPING:
-			writel(0, CMD_STAT_REG(chan_num));
-			chan->sw_state = FDMA_IDLE;
+			writel(0, CMD_STAT_REG(channel->chan_num));
+			channel->sw_state = FDMA_IDLE;
 			break;
 		default:
 			BUG();
 		}
 		break;
 	case FDMA_CHANNEL_IDLE:
-		switch (chan->sw_state) {
+		switch (channel->sw_state) {
 		case FDMA_RUNNING:
 		case FDMA_PAUSING:
 		case FDMA_STOPPING:
-			chan->sw_state = FDMA_IDLE;
+			channel->sw_state = FDMA_IDLE;
 			break;
 		default:
 			BUG();
@@ -317,61 +307,60 @@ static inline void __handle_fdma_completion_irq(struct fdma_dev *fd,
 	case FDMA_CHANNEL_RUNNING:
 		break;
 	default:
-		fdma_dbg(fd, "ERR::FDMA2 unknown interrupt status \n");
+		fdma_dbg(fdma, "ERR::FDMA2 unknown interrupt status \n");
 	}
 
-	spin_unlock(&fd->channel_lock);
+	spin_unlock(&fdma->channels_lock);
 
-	wake_up(&chan->cur_cfg->wait_queue);
+	wake_up(&channel->dma_chan->wait_queue);
 
 	if (comp_cb) {
-		if (chan->params->comp_cb_isr)
+		if (channel->params->comp_cb_isr)
 			comp_cb(comp_cb_parm);
 		else
-			tasklet_schedule(&chan->fdma_complete);
+			tasklet_schedule(&channel->fdma_complete);
 	}
 }
 
 static irqreturn_t fdma_irq(int irq, void *dev_id)
 {
-	struct fdma_dev * fd = (struct fdma_dev *)dev_id;
+	struct fdma *fdma = dev_id;
 	int chan_num;
-	u32 int_stat_val = readl(fd->io_base + fd->regs.fdma_int_sta);
-	u32 cur_val = int_stat_val & fd->ch_status_mask;
-
-	writel(cur_val, fd->io_base +fd->regs.fdma_int_clr);
-	for (cur_val >>= fd->ch_min * 2, chan_num=fd->ch_min;
-	     cur_val != 0;
-	     cur_val >>= 2, chan_num++) {
-		/*error interrupts will raise boths bits, so check
-		 * the err bit first*/
-		if(unlikely(cur_val & 2))
-			__handle_fdma_err_irq(fd,chan_num);
-		else if (cur_val & 1)
-			__handle_fdma_completion_irq(fd, chan_num);
+	u32 status = readl(fdma->io_base + fdma->regs.fdma_int_sta);
+	u32 masked = status & fdma->ch_status_mask;
+
+	writel(masked, fdma->io_base + fdma->regs.fdma_int_clr);
+	for (masked >>= fdma->ch_min * 2, chan_num = fdma->ch_min;
+			masked != 0; masked >>= 2, chan_num++) {
+		struct fdma_channel *channel = &fdma->channels[chan_num];
+		/* error interrupts will raise boths bits, so check
+		 * the err bit first */
+		if (unlikely(masked & 2))
+			fdma_handle_fdma_err_irq(channel);
+		else if (masked & 1)
+			fdma_handle_fdma_completion_irq(channel);
 	}
 
-	/*here we check to see if there is still pending ints for the other dmac, if so
-	 * rely on it to signal IRQ_HANDLED once all vectors are cleared, we return IRQ_NONE.
-	 * otherwise we have handled everything so we can now safely returnd IRQ_HANDLED
-	 * to lower the IRQ.*/
-	return IRQ_RETVAL( !(cur_val & (~fd->ch_status_mask)) );
+	/* Here we check to see if there is still pending ints for the other
+	 * dmac, if so rely on it to signal IRQ_HANDLED once all vectors are
+	 * cleared, we return IRQ_NONE. Otherwise we have handled everything
+	 * so we can now safely returnd IRQ_HANDLED to lower the IRQ. */
+	return IRQ_RETVAL(!(status & (~fdma->ch_status_mask)));
 }
 
 /* Paced channel handling */
 
 #ifdef CONFIG_CPU_SUBTYPE_STB7100
 
-static struct stm_dma_req fdma_reqs[STB7100_REQ_LINES];
+static struct stm_dma_req fdma_reqs[FDMA_7100_REQ_LINES];
 
 /* This is the dummy xbar for 710x devices */
-static int xbar_local_req(int req_line,
-			  struct channel_status *chan)
+static int xbar_local_req(int req_line, struct fdma_channel *channel)
 {
 	return req_line;
 }
 
-static void xbar_local_free(struct channel_status *chan, int local_req_line)
+static void xbar_local_free(struct fdma_channel *channel, int local_req_line)
 {
 }
 
@@ -385,43 +374,41 @@ module_init(xbar_init)
 
 /* Real xbar device */
 
-static struct stm_dma_req fdma_reqs[STB7200_REQ_LINES];
+static struct stm_dma_req fdma_reqs[FDMA_7200_REQ_LINES];
 
 struct xbar_dev {
 	struct resource *phys_mem;
-	void* io_base;
+	void *io_base;
 };
 
 /* Gross hack, we use a global static so the FDMA code can find the
  * xbar. */
-static struct xbar_dev* xbar_dev;
+static struct xbar_dev *xbar_dev;
 
 /* Needs to be called with both the channel and xbar locks taken. */
-static int xbar_local_req(int req_line,
-			  struct channel_status *chan)
+static int xbar_local_req(int req_line, struct fdma_channel *channel)
 {
-	struct fdma_dev *fd = chan->fd;
+	struct fdma *fdma = channel->fdma;
 	int local_req_line;
-	void* xbar_addr;
+	void *xbar_addr;
 
-	if (fd->req_lines_inuse == ~0UL)
+	if (fdma->req_lines_inuse == ~0UL)
 		return -1;
 
-	local_req_line = ffz(fd->req_lines_inuse);
-	fd->req_lines_inuse |= 1<<local_req_line;
+	local_req_line = ffz(fdma->req_lines_inuse);
+	fdma->req_lines_inuse |= 1 << local_req_line;
 
-	xbar_addr = xbar_dev->io_base +
-		(fd->fdma_num * 0x80) +
-		(local_req_line * 4);
+	xbar_addr = xbar_dev->io_base + (fdma->fdma_num * 0x80) +
+			(local_req_line * 4);
 	writel(req_line, xbar_addr);
 
 	return local_req_line;
 }
 
-static void xbar_local_free(struct channel_status *chan, int local_req_line)
+static void xbar_local_free(struct fdma_channel *channel, int local_req_line)
 {
-	struct fdma_dev *fd = chan->fd;
-	fd->req_lines_inuse &= ~(1<<local_req_line);
+	struct fdma *fdma = channel->fdma;
+	fdma->req_lines_inuse &= ~(1 << local_req_line);
 }
 
 static int __init xbar_driver_probe(struct platform_device *pdev)
@@ -435,14 +422,14 @@ static int __init xbar_driver_probe(struct platform_device *pdev)
 		return -ENOMEM;
 	}
 
-	mem_res = platform_get_resource(pdev,IORESOURCE_MEM,0);
-        phys_base = mem_res->start;
-        phys_size = mem_res->end - mem_res->start + 1;
+	mem_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	phys_base = mem_res->start;
+	phys_size = mem_res->end - mem_res->start + 1;
 
-        xd->phys_mem = request_mem_region(phys_base, phys_size, "xbar");
+	xd->phys_mem = request_mem_region(phys_base, phys_size, "xbar");
 	if (xd->phys_mem == NULL) {
 		kfree(xd);
-                return -EBUSY;
+		return -EBUSY;
 	}
 
 	xd->io_base = ioremap_nocache(phys_base, phys_size);
@@ -454,7 +441,7 @@ static int __init xbar_driver_probe(struct platform_device *pdev)
 	platform_set_drvdata(pdev, xd);
 	xbar_dev = xd;
 
-       	return 0;
+	return 0;
 }
 
 static int xbar_driver_remove(struct platform_device *pdev)
@@ -463,9 +450,7 @@ static int xbar_driver_remove(struct platform_device *pdev)
 }
 
 static struct platform_driver xbar_driver = {
-	.driver = {
-		.name = "fdma-xbar",
-	},
+	.driver.name = "fdma-xbar",
 	.probe = xbar_driver_probe,
 	.remove = xbar_driver_remove,
 };
@@ -487,27 +472,27 @@ module_exit(xbar_exit)
 
 static DEFINE_SPINLOCK(fdma_req_lock);
 
-static struct stm_dma_req *fdma_req_allocate(unsigned int req_line, struct channel_status *chan)
+static struct stm_dma_req *fdma_req_allocate(unsigned int req_line,
+		struct fdma_channel *channel)
 {
-	struct stm_dma_req* req = NULL;
+	struct stm_dma_req *req = NULL;
 	int local_req_line;
 
 	if ((req_line < 0) || (req_line >= ARRAY_SIZE(fdma_reqs)))
 		return NULL;
 
 	spin_lock(&fdma_req_lock);
-	if (fdma_reqs[req_line].chan != NULL) {
+	if (fdma_reqs[req_line].channel != NULL)
 		goto out;
-	}
 
 	req = &fdma_reqs[req_line];
 
-	local_req_line = xbar_local_req(req_line, chan);
+	local_req_line = xbar_local_req(req_line, channel);
 	if (local_req_line == -1) {
 		goto out;
 	}
 
-	req->chan = chan;
+	req->channel = channel;
 	req->local_req_line = local_req_line;
 out:
 	spin_unlock(&fdma_req_lock);
@@ -518,10 +503,10 @@ static void fdma_req_free(struct stm_dma_req *req)
 {
 	spin_lock(&fdma_req_lock);
 
-	if (req->chan)
-		xbar_local_free(req->chan, req->local_req_line);
+	if (req->channel)
+		xbar_local_free(req->channel, req->local_req_line);
 
-	req->chan = NULL;
+	req->channel = NULL;
 
 	spin_unlock(&fdma_req_lock);
 }
@@ -532,125 +517,132 @@ static void fdma_req_free(struct stm_dma_req *req)
  *---------------------------------------------------------------------*
  *---------------------------------------------------------------------*/
 
-static void fdma_initialise(struct fdma_dev * fd)
+static void fdma_initialise(struct fdma *fdma)
 {
-/*These pokes come from the current STAPI tree.
+/* These pokes come from the current STAPI tree.
  * The three magic vals are pokes to undocumented regs so
  * we don't know what they mean.
  *
  * The effect is to turn on and initialise the clocks
- * and set all channels off*/
+ * and set all channels off */
 
-	/*clear the status regs MBOX & IRQ*/
-	writel(CLEAR_WORD, fd->io_base+fd->regs.fdma_int_clr);
-	writel(CLEAR_WORD, fd->io_base+fd->regs.fdma_cmd_clr);
+	/* clear the status regs MBOX & IRQ */
+	writel(CLEAR_WORD, fdma->io_base + fdma->regs.fdma_int_clr);
+	writel(CLEAR_WORD, fdma->io_base + fdma->regs.fdma_cmd_clr);
 
 	/* Enable the FDMA block */
-	writel(1,fd->io_base+fd->regs.fdma_sync_reg);
-	writel(5,fd->io_base+fd->regs.fdma_clk_gate);
-	writel(0,fd->io_base+fd->regs.fdma_clk_gate);
+	writel(1, fdma->io_base + fdma->regs.fdma_sync_reg);
+	writel(5, fdma->io_base + fdma->regs.fdma_clk_gate);
+	writel(0, fdma->io_base + fdma->regs.fdma_clk_gate);
 
 }
-/*this function enables messaging and intr generation for all channels &
- * starts the fdma running*/
-static int fdma_enable_all_channels(struct fdma_dev * fd)
+/* this function enables messaging and intr generation for all channels &
+ * starts the fdma running */
+static int fdma_enable_all_channels(struct fdma *fdma)
 {
-	writel(CLEAR_WORD,fd->io_base + fd->regs.fdma_int_mask);
-	writel(CLEAR_WORD,fd->io_base + fd->regs.fdma_cmd_mask);
-	writel(1,fd->io_base +fd->regs.fdma_en);
-	return (readl(fd->io_base + fd->regs.fdma_en) &1);
+	writel(CLEAR_WORD, fdma->io_base + fdma->regs.fdma_int_mask);
+	writel(CLEAR_WORD, fdma->io_base + fdma->regs.fdma_cmd_mask);
+	writel(1, fdma->io_base + fdma->regs.fdma_en);
+	return readl(fdma->io_base + fdma->regs.fdma_en) & 1;
 }
-static int fdma_disable_all_channels(struct fdma_dev * fd)
+static int fdma_disable_all_channels(struct fdma *fdma)
 {
-	writel(0x00,fd->io_base + fd->regs.fdma_int_mask);
-	writel(0x00,fd->io_base + fd->regs.fdma_cmd_mask);
-	writel(0,fd->io_base + fd->regs.fdma_en);
-	return (readl(fd->io_base + fd->regs.fdma_en) &~1);
+	writel(0, fdma->io_base + fdma->regs.fdma_int_mask);
+	writel(0, fdma->io_base + fdma->regs.fdma_cmd_mask);
+	writel(0, fdma->io_base + fdma->regs.fdma_en);
+	return readl(fdma->io_base + fdma->regs.fdma_en) & ~1;
 }
 
-static void fdma_reset_channels(struct fdma_dev * fd)
+static void fdma_reset_channels(struct fdma *fdma)
 {
-	int channel;
+	int chan_num;
 
-	for (channel = fd->ch_min; channel <= fd->ch_max; channel++)
-		writel(0, CMD_STAT_REG(channel));
+	for (chan_num = fdma->ch_min; chan_num <= fdma->ch_max; chan_num++)
+		writel(0, CMD_STAT_REG(chan_num));
 }
 
-static struct stm_dma_req *stb710x_configure_pace_channel(struct fdma_dev *fd,
-	struct dma_channel *channel,
-	struct stm_dma_req_config *req_config)
+static struct stm_dma_req *fdma_configure_pace_channel(
+		struct fdma_channel *channel,
+		struct stm_dma_req_config *req_config)
 {
-	struct channel_status *chan = FDMA_CHAN(channel);
-	void __iomem *req_base_reg = fd->io_base+fd->regs.fdma_req_ctln;
-	struct stm_dma_req *fdma_req;
-	u32 req_ctl;
+	struct fdma *fdma = channel->fdma;
+	void __iomem *req_base_reg = fdma->io_base + fdma->regs.fdma_req_ctln;
+	struct stm_dma_req *req;
 
-	fdma_req = fdma_req_allocate(req_config->req_line, chan);
-	if (fdma_req == NULL) {
-		return NULL;
-	}
+	req = fdma_req_allocate(req_config->req_line, channel);
 
-	req_ctl = 0;
-	req_ctl |= (req_config->hold_off	& 0x0f) <<  0;/*Bits 3.0*/
-	req_ctl |= (req_config->opcode		& 0x0f) <<  4;/*7..4*/
-	req_ctl |= (req_config->rw		& 0x01) << 14;/*14*/
-	req_ctl |= (req_config->initiator	& 0x03) << 22;/*23..22*/
-	req_ctl |= ((req_config->count-1)	& 0x1F) << 24;/*28..24*/
-	req_ctl |= (req_config->increment	& 0x01) << 29;/*29*/
+	if (req) {
+		u32 req_ctl = 0;
 
-	writel(req_ctl, req_base_reg + (fdma_req->local_req_line * CMD_STAT_OFFSET));
+		req_ctl |= (req_config->hold_off & 0x0f) <<  0; /* Bits 3..0 */
+		req_ctl |= (req_config->opcode & 0x0f) <<  4; /* 7..4 */
+		req_ctl |= (req_config->rw & 0x01) << 14; /* 14 */
+		req_ctl |= (req_config->initiator & 0x03) << 22; /* 23..22 */
+		req_ctl |= ((req_config->count - 1) & 0x1f) << 24; /* 28..24 */
+		req_ctl |= (req_config->increment & 0x01) << 29; /* 29 */
+
+		writel(req_ctl, req_base_reg +
+				(req->local_req_line * CMD_STAT_OFFSET));
+	}
 
-	return fdma_req;
+	return req;
 }
 
-static int fdma_register_caps(struct fdma_dev * fd)
+static int fdma_register_caps(struct fdma *fdma)
 {
-	int channel;
-	int res=0;
-	int num_caps = fd->ch_max - fd->ch_min + 1;
-	struct dma_chan_caps  dmac_caps[num_caps];
-	static const char* hb_caps[] = {STM_DMA_CAP_HIGH_BW,NULL};
-	static const char* lb_caps[] = {STM_DMA_CAP_LOW_BW,NULL};
-	static const char* eth_caps[] = {STM_DMA_CAP_ETH_BUF,NULL};
-
-	for (channel = fd->ch_min; channel <= fd->ch_max; channel++) {
-		dmac_caps[channel-fd->ch_min].ch_num = channel;
-		switch (channel) {
+	int chan_num, dma_chan_num;
+	int err;
+	int num_caps = fdma->ch_max - fdma->ch_min + 1;
+	struct dma_chan_caps dmac_caps[num_caps];
+	static const char *hb_caps[] = {STM_DMA_CAP_HIGH_BW, NULL};
+	static const char *lb_caps[] = {STM_DMA_CAP_LOW_BW, NULL};
+	static const char *eth_caps[] = {STM_DMA_CAP_ETH_BUF, NULL};
+
+	for (chan_num = fdma->ch_min, dma_chan_num = 0;
+			chan_num <= fdma->ch_max;
+			chan_num++, dma_chan_num++) {
+		dmac_caps[dma_chan_num].ch_num = dma_chan_num;
+		switch (chan_num) {
 		case 0 ... 3:
-			dmac_caps[channel-fd->ch_min].caplist = hb_caps;
+			dmac_caps[dma_chan_num].caplist = hb_caps;
 			break;
 		case 11:
-			dmac_caps[channel-fd->ch_min].caplist = eth_caps;
+			dmac_caps[dma_chan_num].caplist = eth_caps;
 			break;
 		default:
-			dmac_caps[channel-fd->ch_min].caplist = lb_caps;
+			dmac_caps[dma_chan_num].caplist = lb_caps;
 			break;
 		}
 	}
-	res= register_chan_caps(fd->name, &dmac_caps[0]);
 
-	if(res!=0){
-		fdma_dbg(fd, "%s %s failed to register capabilities err-%d\n",
-			__FUNCTION__, fd->name, res);
+	err = register_chan_caps(fdma->name, dmac_caps);
+	if (err != 0) {
+		fdma_dbg(fdma, "%s %s failed to register capabilities err-%d\n",
+				__FUNCTION__, fdma->name, err);
 		return -ENODEV;
 	}
-	else return 0;
+
+	return 0;
 }
 
-static int fdma_run_initialise_sequence(struct fdma_dev *fd)
+static int fdma_run_initialise_sequence(struct fdma *fdma)
 {
-	fd->llu_pool = dma_pool_create(fd->name, NULL,
-					sizeof(struct fdma_llu_entry),32,0);
-	if (fd->llu_pool == NULL) {
-		fdma_dbg(fd, "%s Can't allocate dma_pool memory",__FUNCTION__);
+	fdma->llu_pool = dma_pool_create(fdma->name, NULL,
+			sizeof(struct fdma_llu_entry), 32, 0);
+
+	if (fdma->llu_pool == NULL) {
+		fdma_dbg(fdma, "%s Can't allocate dma_pool memory",
+				__FUNCTION__);
 		return -ENOMEM;
 	}
-	fdma_initialise(fd);
-	fdma_reset_channels(fd);
 
-	if(!fdma_enable_all_channels(fd))
+	fdma_initialise(fdma);
+	fdma_reset_channels(fdma);
+
+	if (!fdma_enable_all_channels(fdma))
 		return -ENODEV;
-	else return  0;
+
+	return 0;
 }
 
 /*---------------------------------------------------------------------*
@@ -659,54 +651,57 @@ static int fdma_run_initialise_sequence(struct fdma_dev *fd)
  *---------------------------------------------------------------------*
  *---------------------------------------------------------------------*/
 
-static void fdma_get_fw_revision(struct fdma_dev * fd, int *major, int *minor)
+static void fdma_get_fw_revision(struct fdma *fdma,
+		int *major, int *minor)
 {
-	int reg = readl(fd->io_base + fd->regs.fdma_dmem_region);
-	*major  = (reg & 0xff0000) >> 16;
-	*minor  = (reg & 0xff00) >> 8;
+	int reg = readl(fdma->io_base + fdma->regs.fdma_dmem_region);
+
+	*major = (reg & 0xff0000) >> 16;
+	*minor = (reg & 0xff00) >> 8;
 }
 
-static void fdma_get_hw_revision(struct fdma_dev * fd, int *major, int *minor)
+static void fdma_get_hw_revision(struct fdma *fdma,
+		int *major, int *minor)
 {
-	*major = readl(fd->io_base + fd->regs.fdma_id);
-	*minor = readl(fd->io_base + fd->regs.fdma_ver);
+	*major = readl(fdma->io_base + fdma->regs.fdma_id);
+	*minor = readl(fdma->io_base + fdma->regs.fdma_ver);
 }
 
-#if  defined(CONFIG_STM_DMA_FW_KERNEL)
+#if defined(CONFIG_STM_DMA_FW_KERNEL)
 
-static int fdma_do_bootload(struct fdma_dev * fd)
+static int fdma_do_bootload(struct fdma *fdma)
 {
-	device_t* ptr=0;
-	struct fdma_fw fw=fd->fw;
+	device_t *ptr = 0;
+	struct fdma_fw fw = fdma->fw;
 	unsigned long unused_ibytes;
 	unsigned long unused_dbytes;
 	unsigned long irqflags;
-	void * addr =(char*)fd->io_base;
-
-	fdma_dbg(fd, "FDMA: Loading Firmware...");
-	unused_ibytes= fw.imem_len - fw.imem_fw_sz;
-	unused_dbytes= fw.dmem_len - fw.dmem_fw_sz;
-
-	spin_lock_irqsave(&fd->channel_lock,irqflags);
-	ptr = (device_t*) ((char*) addr +fd->regs.fdma_dmem_region);
-	memcpy((void*)ptr,&fw.data_reg[0],fw.dmem_fw_sz * sizeof(u32));
-	if(unused_dbytes){
-		ptr =(device_t*) ((char*)addr +fd->regs.fdma_dmem_region
-				  +(fw.dmem_fw_sz*sizeof(u32)));
-		memset((void*)ptr ,0, unused_dbytes);
+	void *addr = (char *)fdma->io_base;
+
+	fdma_dbg(fdma, "FDMA: Loading Firmware...");
+	unused_ibytes = fw.imem_len - fw.imem_fw_sz;
+	unused_dbytes = fw.dmem_len - fw.dmem_fw_sz;
+
+	spin_lock_irqsave(&fdma->channels_lock, irqflags);
+	ptr = (device_t *)((char *)addr + fdma->regs.fdma_dmem_region);
+	memcpy((void *)ptr, &fw.data_reg[0], fw.dmem_fw_sz * sizeof(u32));
+	if (unused_dbytes) {
+		ptr = (device_t *)((char *)addr + fdma->regs.fdma_dmem_region +
+				(fw.dmem_fw_sz * sizeof(u32)));
+		memset((void *)ptr, 0, unused_dbytes);
 	}
 
-	ptr = (device_t*) ((char*) addr +fd->regs.fdma_imem_region);
-	memcpy((void*)ptr,&fw.imem_reg[0],fw.imem_fw_sz* sizeof(u32));
-	if(unused_ibytes){
-		ptr =(device_t*) ((char*)addr +fd->regs.fdma_imem_region
-				  +(fw.imem_fw_sz*sizeof(u32)));
-		memset((void*)ptr,0, unused_ibytes);
+	ptr = (device_t *)((char *)addr + fdma->regs.fdma_imem_region);
+	memcpy((void *)ptr, &fw.imem_reg[0], fw.imem_fw_sz * sizeof(u32));
+	if (unused_ibytes) {
+		ptr = (device_t *)((char *)addr + fdma->regs.fdma_imem_region +
+				(fw.imem_fw_sz * sizeof(u32)));
+		memset((void *)ptr, 0, unused_ibytes);
 	}
-	spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+	spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 
-	fd->firmware_loaded=1;
-	wake_up(&fd->fw_load_q);
+	fdma->firmware_loaded = 1;
+	wake_up(&fdma->fw_load_q);
 
 	return 0;
 }
@@ -721,145 +716,151 @@ static int fdma_do_bootload(struct fdma_dev * fd)
  * This also means the size parameter is incorrect
  * - Grrrr.
 */
-static void build_elf_imem(	struct fdma_dev * fd,
-				struct elf32_shdr * sect_hd,
-				struct firmware * slimcore_elf)
+static void fdma_build_elf_imem(struct fdma *fdma,
+		struct elf32_shdr *sect_hd,
+		struct firmware *slimcore_elf)
 {
-	int pos=0;
-	char * file_off=0;
-	int imem_sz = sect_hd->sh_size+ (sect_hd->sh_size /3);
-	u8 * imem_st=  kmalloc(imem_sz,GFP_KERNEL);
-	u8 * imem_ptr =imem_st;
-	char * imem_sect = (char*)fd->io_base + fd->regs.fdma_imem_region;
-
-	file_off =(u8*) &slimcore_elf->data[sect_hd->sh_offset];
-
-	do{
-		memcpy(imem_ptr,file_off,sizeof(char)*3);
-		imem_ptr+=3;
-		file_off+=3;
-		*imem_ptr=0x00;
+	int pos = 0;
+	char *file_off = 0;
+	int imem_sz = sect_hd->sh_size + (sect_hd->sh_size / 3);
+	u8 *imem_st = kmalloc(imem_sz, GFP_KERNEL);
+	u8 *imem_ptr = imem_st;
+	char *imem_sect = (char *)fdma->io_base + fdma->regs.fdma_imem_region;
+
+	file_off = (u8 *)&slimcore_elf->data[sect_hd->sh_offset];
+
+	do {
+		memcpy(imem_ptr, file_off, sizeof(char) * 3);
+		imem_ptr += 3;
+		file_off += 3;
+		*imem_ptr = 0x00;
 		imem_ptr++;
-	}while((pos+=3)< sect_hd->sh_size);
+	} while ((pos += 3) < sect_hd->sh_size);
 
-	memcpy(imem_sect,imem_st ,imem_sz);
+	memcpy(imem_sect, imem_st, imem_sz);
 	kfree(imem_ptr);
 }
 
-static void build_elf_dmem(	struct fdma_dev * fd,
-				struct elf32_shdr * sect_hd,
-				struct firmware * slimcore_elf)
+static void fdma_build_elf_dmem(struct fdma *fdma,
+		struct elf32_shdr *sect_hd,
+		struct firmware *slimcore_elf)
 {
-	char * dmem_sect = (char*)fd->io_base + fd->regs.fdma_dmem_region;
-	char * file_off=0;
+	char *dmem_sect = (char *)fdma->io_base + fdma->regs.fdma_dmem_region;
+	char *file_off = 0;
 
-	file_off = (char*)&slimcore_elf->data[sect_hd->sh_offset];
-	memcpy(dmem_sect,(char*)file_off ,sect_hd->sh_size);
+	file_off = (char *)&slimcore_elf->data[sect_hd->sh_offset];
+	memcpy(dmem_sect, (char *)file_off, sect_hd->sh_size);
 }
 
 
-static int fdma_do_bootload(struct fdma_dev * fd)
+static int fdma_do_bootload(struct fdma *fdma)
 {
-	int err=0;
-	int i=0,imem_loaded=0,dmem_loaded=0;
+	int err = 0;
+	int i = 0, imem_loaded = 0, dmem_loaded = 0;
 	char fw_revision[20];
 	char hw_revision[20];
-	int major=0,minor=0;
-	struct firmware *slimcore_elf={0};
+	int major = 0, minor = 0;
+	struct firmware *slimcore_elf = {0};
 	struct elf32_hdr hdr;
 
-	fdma_dbg(fd, "FDMA: Loading Firmware ELF...");
+	fdma_dbg(fdma, "FDMA: Loading Firmware ELF...");
 
 	err = request_firmware((const struct firmware **)&slimcore_elf,
-				fd->fw_name,&fdma_device_list[fd->hwid]);
-	if(err != 0 ){
-		fdma_dbg(fd, "%s Can't Locate/Load Firmware %s\n",
-		       __FUNCTION__, fd->fw_name);
+			fdma->fw_name, &fdma_device_list[fdma->hwid]);
+	if (err != 0) {
+		fdma_dbg(fdma, "%s Can't Locate/Load Firmware %s\n",
+				__FUNCTION__, fdma->fw_name);
 		return -ENOENT;
 	}
 
-	memcpy(&hdr,slimcore_elf->data,sizeof(struct elf32_hdr));
-
+	memcpy(&hdr, slimcore_elf->data, sizeof(struct elf32_hdr));
 
 	/* build the section header tbl */
-	for(i=0;i < hdr.e_shnum;i++){
+	for (i = 0; i < hdr.e_shnum; i++) {
 		struct elf32_shdr sect_hdr;
-		char* sh_addr = (char*)&slimcore_elf->data[hdr.e_shoff + (i * sizeof(struct elf32_shdr))];
-		memcpy(&sect_hdr,(char*)sh_addr ,sizeof(struct elf32_shdr));
-
-		if(SHT_PROGBITS== sect_hdr.sh_type){
-			if(sect_hdr.sh_flags & SHF_ALLOC){
-
-				if((sect_hdr.sh_flags & SHF_EXECINSTR) == SHF_EXECINSTR){
-					build_elf_imem(fd,&sect_hdr,slimcore_elf);
-					imem_loaded=1;
-				}
-				else if((sect_hdr.sh_flags & SHF_WRITE) == SHF_WRITE){
-					build_elf_dmem(fd,&sect_hdr,slimcore_elf);
-					dmem_loaded=1;
+		char *sh_addr = (char *)&slimcore_elf->data[hdr.e_shoff +
+				(i * sizeof(struct elf32_shdr))];
+		memcpy(&sect_hdr, (char *)sh_addr, sizeof(struct elf32_shdr));
+
+		if (SHT_PROGBITS == sect_hdr.sh_type) {
+			if (sect_hdr.sh_flags & SHF_ALLOC) {
+				if ((sect_hdr.sh_flags & SHF_EXECINSTR) ==
+						SHF_EXECINSTR) {
+					fdma_build_elf_imem(fdma, &sect_hdr,
+							slimcore_elf);
+					imem_loaded = 1;
+				} else if ((sect_hdr.sh_flags & SHF_WRITE) ==
+						SHF_WRITE) {
+					fdma_build_elf_dmem(fdma, &sect_hdr,
+							slimcore_elf);
+					dmem_loaded = 1;
 				}
 			}
-			if(dmem_loaded && imem_loaded){
-				/*we can discard the remainder of the elf now*/
+			if (dmem_loaded && imem_loaded) {
+				/* we can discard the remainder of the
+				 * elf now */
 				break;
 			}
 		}
 	}
 	release_firmware(slimcore_elf);
-	if(dmem_loaded && imem_loaded){
-		fd->firmware_loaded=1;
-		wake_up(&fd->fw_load_q);
+	if (dmem_loaded && imem_loaded) {
+		fdma->firmware_loaded = 1;
+		wake_up(&fdma->fw_load_q);
+	} else {
+		return -ENODEV;
 	}
-	else return -ENODEV;
 
-	fdma_get_fw_revision(fd,&fw_revision[0],major,minor);
-	fdma_get_hw_revision(fd,&hw_revision[0],major,minor);
-	fdma_dbg(fd, "STB_%dC%d %s %s OK\n",
-		 fd->cpu_subtype,fd->cpu_rev,hw_revision,fw_revision);
+	fdma_get_fw_revision(fdma, &fw_revision[0], major, minor);
+	fdma_get_hw_revision(fdma, &hw_revision[0], major, minor);
+	fdma_dbg(fdma, "STB_%dC%d %s %s OK\n", fdma->cpu_subtype, fdma->cpu_rev,
+			hw_revision, fw_revision);
 	return 0;
 }
 #endif
 
-static int fdma_load_firmware(struct fdma_dev * fd)
+static int fdma_load_firmware(struct fdma *fdma)
 {
-	unsigned long irqflags=0;
+	unsigned long irqflags = 0;
 	int hw_major, hw_minor;
 	int fw_major, fw_minor;
-	spin_lock_irqsave(&fd->channel_lock,irqflags);
-	switch ( fd->firmware_loaded ) {
-		case 0:
-			fd->firmware_loaded = -1;
-			spin_unlock_irqrestore(&fd->channel_lock,irqflags);
-			if (fdma_do_bootload(fd)!=0){
-				fd->firmware_loaded=0;
-				return  -ENOMEM;
-			}
-			fdma_get_hw_revision(fd, &hw_major, &hw_minor);
-			fdma_get_fw_revision(fd, &fw_major, &fw_minor);
-			fdma_info(fd, "SLIM hw %d.%d, FDMA fw %d.%d\n",
-				  hw_major, hw_minor, fw_major, fw_minor);
+	spin_lock_irqsave(&fdma->channels_lock, irqflags);
+	switch (fdma->firmware_loaded) {
+	case 0:
+		fdma->firmware_loaded = -1;
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
+		if (fdma_do_bootload(fdma) != 0) {
+			fdma->firmware_loaded = 0;
+			return -ENOMEM;
+		}
+		fdma_get_hw_revision(fdma, &hw_major, &hw_minor);
+		fdma_get_fw_revision(fdma, &fw_major, &fw_minor);
+		fdma_info(fdma, "SLIM hw %d.%d, FDMA fw %d.%d\n",
+				hw_major, hw_minor, fw_major, fw_minor);
 
-			if(fdma_run_initialise_sequence(fd)!=0)
-				return -ENODEV;
+		if (fdma_run_initialise_sequence(fdma) != 0)
+			return -ENODEV;
 
-			return (fd->firmware_loaded==1) ? 0:-ENODEV;
-		case 1:
-			spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+		return (fdma->firmware_loaded == 1) ? 0: -ENODEV;
+	case 1:
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
+		return 0;
+	default:
+	case -1:
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
+		wait_event_interruptible(fdma->fw_load_q,
+				(fdma->firmware_loaded == 1));
+		if (!fdma->firmware_loaded)
+			return -ENODEV;
+		else
 			return 0;
-		default:
-		case -1:
-			spin_unlock_irqrestore(&fd->channel_lock,irqflags);
-			wait_event_interruptible(fd->fw_load_q,(fd->firmware_loaded==1));
-			if(!fd->firmware_loaded)
-				return -ENODEV;
-			else return 0;
 	}
 	return 0;
 }
 
-static int fdma_check_firmware_state(struct fdma_dev * fd)
+static int fdma_check_firmware_state(struct fdma *fdma)
 {
-	return (fd->firmware_loaded) ? 0:fdma_load_firmware(fd);
+	return (fdma->firmware_loaded) ? 0 : fdma_load_firmware(fdma);
 }
 
 /*---------------------------------------------------------------------*
@@ -868,71 +869,65 @@ static int fdma_check_firmware_state(struct fdma_dev * fd)
  *---------------------------------------------------------------------*
  *---------------------------------------------------------------------*/
 
-/*returns the number of bytes left to transfer for the current node*/
-static int stb710x_fdma_get_residue(struct dma_channel *channel)
+/* returns the number of bytes left to transfer for the current node */
+static int fdma_get_residue(struct dma_channel *dma_chan)
 {
-	struct fdma_dev *fd = FDMA_DEV(channel);
-	struct channel_status *chan = FDMA_CHAN(channel);
-	struct stm_dma_params *params = chan->params;
+	struct fdma_channel *channel = dma_chan->priv_data;
+	struct fdma *fdma = channel->fdma;
+	struct stm_dma_params *params = channel->params;
 	unsigned long irqflags;
 	u32 count = 0;
 
-	spin_lock_irqsave(&fd->channel_lock, irqflags);
+	spin_lock_irqsave(&fdma->channels_lock, irqflags);
 
-	if (likely(chan->sw_state != FDMA_IDLE)) {
-		struct dma_xfer_descriptor *desc =
-			(struct dma_xfer_descriptor*)params->priv;
-		void __iomem *chan_base = fd->io_base +
-				(channel->chan * NODE_DATA_OFFSET);
+	if (likely(channel->sw_state != FDMA_IDLE)) {
+		struct fdma_xfer_descriptor *desc =
+			(struct fdma_xfer_descriptor *)params->priv;
+		void __iomem *chan_base = fdma->io_base +
+				(channel->chan_num * NODE_DATA_OFFSET);
 		unsigned long current_node_phys;
 		unsigned long stat1, stat2;
-		struct llu_node *current_node;
+		struct fdma_llu_node *current_node;
 		int node_num;
 
 		/* Get info about current node */
 		do {
-			stat1 = readl(CMD_STAT_REG(channel->chan));
-			count = readl(chan_base + fd->regs.fdma_cntn);
-			stat2 = readl(CMD_STAT_REG(channel->chan));
+			stat1 = readl(CMD_STAT_REG(channel->chan_num));
+			count = readl(chan_base + fdma->regs.fdma_cntn);
+			stat2 = readl(CMD_STAT_REG(channel->chan_num));
 		} while (stat1 != stat2);
 
 		current_node_phys = stat1 & ~0x1f;
-		for (node_num=0, current_node = desc->llu_nodes;
-		     current_node->dma_addr != current_node_phys;
-		     node_num++, current_node++)
+		for (node_num = 0, current_node = desc->llu_nodes;
+				current_node->dma_addr != current_node_phys;
+				node_num++, current_node++)
 			BUG_ON(node_num == desc->alloced_nodes);
 
 		switch (stat1 & 3) {
 		case FDMA_CHANNEL_IDLE:
-			/*
-			 * Channel has stopped, but we haven't taken
+			/* Channel has stopped, but we haven't taken
 			 * the interrupt to change the ->sw_state
 			 * field yet. We could legitimatly return zero
 			 * here, but instead pretend we haven't quite
 			 * finished yet. Is this the right thing to
-			 * do?
-			 */
+			 * do? */
 			count = 1;
 			goto unlock;
 
 		case FDMA_CHANNEL_RUNNING:
 		case FDMA_CHANNEL_PAUSED:
-			/*
-			 * Unfortuntaly the firmware appears to modify
+			/* Unfortuntaly the firmware appears to modify
 			 * CMD_STAT before it has modifed the COUNT.
 			 * However we write the count in
 			 * fdma_start_channel() so can assume it is
-			 * valid.
-			 */
+			 * valid. */
 			break;
 
 		case CMDSTAT_FDMA_START_CHANNEL:
-			/*
-			 * Channel hasn't started running yet, so count
+			/* Channel hasn't started running yet, so count
 			 * hasn't yet been loaded from the node. But again
 			 * the value was written in fdma_start_channel()
-			 * so the value read from hardware is valid.
-			 */
+			 * so the value read from hardware is valid. */
 			break;
 		}
 
@@ -946,71 +941,69 @@ static int stb710x_fdma_get_residue(struct dma_channel *channel)
 	}
 
 unlock:
-	spin_unlock_irqrestore(&fd->channel_lock, irqflags);
+	spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 
 	return count;
 }
 
-/*must only be called when channel is in paused state*/
-static int stb710x_fdma_unpause(struct fdma_dev * fd,struct dma_channel * channel)
+/* must only be called when channel is in paused state */
+static int fdma_unpause(struct fdma_channel *channel)
 {
-	struct channel_status *chan = FDMA_CHAN(channel);
-	unsigned long irqflags=0;
+	struct fdma *fdma = channel->fdma;
+	unsigned long irqflags = 0;
 	u32 cmd_sta_value;
 
-	spin_lock_irqsave(&fd->channel_lock,irqflags);
-	if (chan->sw_state != FDMA_PAUSED) {
-		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+	spin_lock_irqsave(&fdma->channels_lock, irqflags);
+	if (channel->sw_state != FDMA_PAUSED) {
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 		return -EBUSY;
 	}
 
-	cmd_sta_value = readl(CMD_STAT_REG(channel->chan));
+	cmd_sta_value = readl(CMD_STAT_REG(channel->chan_num));
 	cmd_sta_value &= ~CMDSTAT_FDMA_CMD_MASK;
 	cmd_sta_value |= CMDSTAT_FDMA_RESTART_CHANNEL;
-	writel(cmd_sta_value, CMD_STAT_REG(channel->chan));
+	writel(cmd_sta_value, CMD_STAT_REG(channel->chan_num));
 
-	writel(MBOX_CMD_START_CHANNEL << (channel->chan*2),
-	       fd->io_base + fd->regs.fdma_cmd_set);
-	chan->sw_state = FDMA_RUNNING;
+	writel(MBOX_CMD_START_CHANNEL << (channel->chan_num * 2),
+			fdma->io_base + fdma->regs.fdma_cmd_set);
+	channel->sw_state = FDMA_RUNNING;
 
-	spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+	spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 	return 0;
 }
 
-static int stb710x_fdma_pause(struct fdma_dev * fd,
-		struct dma_channel * channel,
-		int flush)
+static int fdma_pause(struct fdma_channel *channel, int flush)
 {
-	struct channel_status *chan = FDMA_CHAN(channel);
-	unsigned long irqflags=0;
+	struct fdma *fdma = channel->fdma;
+	unsigned long irqflags = 0;
 
-	spin_lock_irqsave(&fd->channel_lock,irqflags);
-	switch (chan->sw_state) {
+	spin_lock_irqsave(&fdma->channels_lock, irqflags);
+	switch (channel->sw_state) {
 	case FDMA_IDLE:
 	case FDMA_CONFIGURED:
 		/* Hardware isn't set up yet, so treat this as an error */
-		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 		return -EBUSY;
 	case FDMA_PAUSED:
 		/* Hardware is already paused */
-		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 		return 0;
 	case FDMA_RUNNING:
 		/* Hardware is running, send the command */
 		writel((flush ? MBOX_CMD_FLUSH_CHANNEL : MBOX_CMD_PAUSE_CHANNEL)
-				<< (channel->chan * 2),
-				fd->io_base + fd->regs.fdma_cmd_set);
+				<< (channel->chan_num * 2),
+				fdma->io_base + fdma->regs.fdma_cmd_set);
 		/* Fall through */
 	case FDMA_PAUSING:
 	case FDMA_STOPPING:
 		/* Hardware is pausing already, wait for interrupt */
-		chan->sw_state = FDMA_PAUSING;
-		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+		channel->sw_state = FDMA_PAUSING;
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 #if 0
 		/* In some cases this is called from a context which cannot
 		 * block, so disable the wait at the moment. */
-		wait_event(chan->cur_cfg->wait_queue,
-			   chan->sw_state == FDMA_PAUSED);
+		wait_event(channel->cur_cfg->wait_queue,
+				channel->sw_state == FDMA_PAUSED);
 #endif
 		break;
 	}
@@ -1018,47 +1011,48 @@ static int stb710x_fdma_pause(struct fdma_dev * fd,
 	return 0;
 }
 
-static int stb710x_fdma_request(struct dma_channel *channel)
+static int fdma_request(struct dma_channel *dma_chan)
 {
-	struct fdma_dev *fd = FDMA_DEV(channel);
+	struct fdma_channel *channel = dma_chan->priv_data;
+	struct fdma *fdma = channel->fdma;
 
-	if(fdma_check_firmware_state(fd)==0){
+	if (fdma_check_firmware_state(fdma) == 0)
 		return 0;
-	}
 
-	return ENOSYS;
+	return -ENOSYS;
 }
 
-static int stb710x_fdma_stop(struct fdma_dev * fd,struct dma_channel *channel)
+static int fdma_stop(struct fdma_channel *channel)
 {
-	struct channel_status *chan = FDMA_CHAN(channel);
-	unsigned long cmd_val = (MBOX_CMD_PAUSE_CHANNEL << (channel->chan*2));
-	unsigned long irqflags=0;
+	struct fdma *fdma = channel->fdma;
+	unsigned long cmd_val = MBOX_CMD_PAUSE_CHANNEL <<
+			(channel->chan_num * 2);
+	unsigned long irqflags = 0;
 
-	spin_lock_irqsave(&fd->channel_lock,irqflags);
-	switch (chan->sw_state) {
+	spin_lock_irqsave(&fdma->channels_lock, irqflags);
+	switch (channel->sw_state) {
 	case FDMA_IDLE:
 	case FDMA_CONFIGURED:
 	case FDMA_PAUSED:
 		/* Hardware is already idle, simply change state */
-		chan->sw_state = FDMA_IDLE;
-		writel(0,CMD_STAT_REG(channel->chan));
-		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+		channel->sw_state = FDMA_IDLE;
+		writel(0, CMD_STAT_REG(channel->chan_num));
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 		break;
 	case FDMA_RUNNING:
 		/* Hardware is running, send the command */
-		writel(cmd_val,(fd->io_base +fd->regs.fdma_cmd_set));
+		writel(cmd_val, fdma->io_base + fdma->regs.fdma_cmd_set);
 		/* Fall through */
 	case FDMA_PAUSING:
 	case FDMA_STOPPING:
 		/* Hardware is pausing already, wait for interrupt */
-		chan->sw_state = FDMA_STOPPING;
-		spin_unlock_irqrestore(&fd->channel_lock,irqflags);
+		channel->sw_state = FDMA_STOPPING;
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 #if 0
 		/* In some cases this is called from a context which cannot
 		 * block, so disable the wait at the moment. */
-		wait_event(chan->cur_cfg->wait_queue,
-			   chan->sw_state == FDMA_IDLE);
+		wait_event(channel->cur_cfg->wait_queue,
+				channel->sw_state == FDMA_IDLE);
 #endif
 		break;
 	}
@@ -1066,15 +1060,15 @@ static int stb710x_fdma_stop(struct fdma_dev * fd,struct dma_channel *channel)
 	return 0;
 }
 
-static int stb710x_fdma_free_params(struct stm_dma_params *params)
+static int fdma_free_params(struct stm_dma_params *params)
 {
-	struct fdma_dev * fd = params->params_ops_priv;
+	struct fdma *fdma = params->params_ops_priv;
 	struct stm_dma_params *this;
 
 	for (this = params; this; this = this->next) {
-		struct dma_xfer_descriptor *desc = (struct dma_xfer_descriptor*)this->priv;
+		struct fdma_xfer_descriptor *desc = this->priv;
 		if (desc) {
-			resize_nodelist_mem(fd, desc, 0, 0);
+			fdma_resize_nodelist_mem(fdma, desc, 0, 0);
 			kfree(desc);
 		}
 	}
@@ -1083,101 +1077,98 @@ static int stb710x_fdma_free_params(struct stm_dma_params *params)
 }
 
 static struct params_ops fdma_params_ops = {
-	.free_params	= stb710x_fdma_free_params
+	.free_params = fdma_free_params
 };
 
 /* Compile params part 1: generate template nodes */
-static int _compile1(struct fdma_dev * fd,struct stm_dma_params *params)
+static int fdma_compile1(struct fdma *fdma, struct stm_dma_params *params)
 {
 	struct stm_dma_params *this;
 
 	for (this = params; this; this = this->next) {
-		struct dma_xfer_descriptor *desc;
+		struct fdma_xfer_descriptor *desc = this->priv;
 
-		desc = (struct dma_xfer_descriptor*)this->priv;
 		if (desc != NULL)
 			continue;
 
-		desc = kzalloc(sizeof(struct dma_xfer_descriptor), params->context);
+		desc = kzalloc(sizeof(struct fdma_xfer_descriptor),
+				params->context);
 		if (desc == NULL)
 			return -ENOMEM;
 		this->priv = desc;
 
-		if (IS_TRANSFER_SG(this)){
-			if(MODE_SRC_SCATTER==this->mode)
-				desc->extrapolate_fn = extrapolate_sg_src;
-			else if(MODE_DST_SCATTER==this->mode)
-				desc->extrapolate_fn = extrapolate_sg_dst;
-			else return -EINVAL;
-		} else {
-			desc->extrapolate_fn = extrapolate_simple;
-		}
+		if (this->mode == MODE_SRC_SCATTER)
+			desc->extrapolate_fn = fdma_extrapolate_sg_src;
+		else if (this->mode == MODE_DST_SCATTER)
+			desc->extrapolate_fn = fdma_extrapolate_sg_dst;
+		else
+			desc->extrapolate_fn = fdma_extrapolate_simple;
 
-		if(this->mode == MODE_PACED){
-			setup_paced_node(this, &desc->template_llu);
-		} else {
-			setup_freerunning_node(this, &desc->template_llu);
-		}
+		if (this->mode == MODE_PACED)
+			fdma_setup_paced_node(this, &desc->template_llu);
+		else
+			fdma_setup_freerunning_node(this, &desc->template_llu);
 
 		/* For any 1D transfers, line_len = nbytes */
-		desc->extrapolate_line_len =
-			!((DIM_SRC(this->dim) == 2) || (DIM_DST(this->dim) == 2));
+		desc->extrapolate_line_len = !((DIM_SRC(this->dim) == 2) ||
+				(DIM_DST(this->dim) == 2));
 	}
 
 	return 0;
 }
 
 /* Compile params part 2: allocate node list */
-static int _compile2(struct fdma_dev * fd,struct stm_dma_params *params)
+static int fdma_compile2(struct fdma *fdma, struct stm_dma_params *params)
 {
 	struct stm_dma_params *this;
 	int numnodes = 0;
-	struct dma_xfer_descriptor *desc;
+	struct fdma_xfer_descriptor *desc;
 
 	for (this = params; this; this = this->next) {
-		if (IS_TRANSFER_SG(this))
+		if (this->mode == MODE_SRC_SCATTER ||
+				this->mode == MODE_DST_SCATTER)
 			numnodes += this->sglen;
 		else
 			numnodes++;
 	}
 
-	desc = (struct dma_xfer_descriptor*)params->priv;
+	desc = params->priv;
 	if (desc->alloced_nodes < numnodes) {
-		int res;
-		res = resize_nodelist_mem(fd, desc, numnodes, params->context);
-		if (res)
-			return res;
+		int err = fdma_resize_nodelist_mem(fdma, desc, numnodes,
+				params->context);
+
+		if (err)
+			return err;
 	}
 
 	return 0;
 }
 
 /* Compile params part 3: extrapolate */
-static int _compile3(struct fdma_dev * fd,struct stm_dma_params *params)
+static int fdma_compile3(struct fdma *fdma, struct stm_dma_params *params)
 {
 	struct stm_dma_params *this;
-	struct dma_xfer_descriptor *this_desc;
-	struct llu_node *first_node, *last_node, *node;
+	struct fdma_xfer_descriptor *this_desc;
+	struct fdma_llu_node *first_node, *last_node, *node;
 
 	this = params;
-	this_desc = (struct dma_xfer_descriptor*)this->priv;
+	this_desc = (struct fdma_xfer_descriptor *)this->priv;
 	first_node = this_desc->llu_nodes;
 
 	node = first_node;
 	while (1) {
-
 		last_node = this_desc->extrapolate_fn(this, this_desc, node);
 
 		this = this->next;
 		if (this == NULL)
 			break;
 
-		this_desc = (struct dma_xfer_descriptor*)this->priv;
+		this_desc = (struct fdma_xfer_descriptor *)this->priv;
 		node = last_node + 1;
 		last_node->virt_addr->next_item = node->dma_addr;
 	}
 
-	if(params->circular_llu)
+	if (params->circular_llu)
 		last_node->virt_addr->next_item = first_node->dma_addr;
 	else
 		last_node->virt_addr->next_item = 0;
@@ -1185,137 +1176,137 @@ static int _compile3(struct fdma_dev * fd,struct stm_dma_params *params)
 	return 0;
 }
 
-static int stb710x_fdma_compile_params(struct fdma_dev * fd,struct stm_dma_params *params)
+static int fdma_compile_params(struct fdma_channel *channel,
+		struct stm_dma_params *params)
 {
+	struct fdma *fdma = channel->fdma;
 	int res;
 
-	res = _compile1(fd, params);
+	res = fdma_compile1(fdma, params);
 	if (res)
 		return res;
 
-	res = _compile2(fd, params);
+	res = fdma_compile2(fdma, params);
 	if (res)
 		return res;
 
-	res = _compile3(fd, params);
+	res = fdma_compile3(fdma, params);
 	if (res == 0) {
 		params->params_ops = &fdma_params_ops;
-		params->params_ops_priv = fd;
+		params->params_ops_priv = fdma;
 	}
 
 	return res;
 }
 
-static void stb710x_fdma_free(struct dma_channel *channel)
+static void fdma_free(struct dma_channel *dma_chan)
 {
-	struct fdma_dev *fd = FDMA_DEV(channel);
-	struct channel_status *chan = FDMA_CHAN(channel);
-	unsigned long irq_flags=0;
+	struct fdma_channel *channel = dma_chan->priv_data;
+	struct fdma *fdma = channel->fdma;
+	unsigned long irq_flags = 0;
 
-	spin_lock_irqsave(&fd->channel_lock,irq_flags);
+	spin_lock_irqsave(&fdma->channels_lock, irq_flags);
 
-	if (chan->sw_state != FDMA_IDLE) {
-		spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
-		fdma_dbg(fd, "%s channel not idle\n",__FUNCTION__);
+	if (channel->sw_state != FDMA_IDLE) {
+		spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
+		fdma_dbg(fdma, "%s channel not idle\n", __FUNCTION__);
 		return;
 	}
 
-	BUG_ON(!(IS_CHANNEL_IDLE(fd,channel->chan)));
+	BUG_ON(fdma_get_engine_status(channel) != FDMA_CHANNEL_IDLE);
 
-	spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
+	spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
 }
 
 /* Note although this returns an int, the dma-api code throws this away. */
-static int stb710x_fdma_configure(	struct dma_channel *channel,
-				  	unsigned long flags)
+static int fdma_configure(struct dma_channel *dma_chan,
+		unsigned long flags)
 {
-	struct fdma_dev *fd = FDMA_DEV(channel);
-	struct channel_status *chan = FDMA_CHAN(channel);
-	struct stm_dma_params * params;
-	unsigned long irq_flags=0;
-
-	spin_lock_irqsave(&fd->channel_lock,irq_flags);
-	if (chan->sw_state != FDMA_IDLE) {
-		spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
-		fdma_dbg(fd, "%s channel not idle\n",__FUNCTION__);
+	struct fdma_channel *channel = dma_chan->priv_data;
+	struct fdma *fdma = channel->fdma;
+	struct stm_dma_params *params = (struct stm_dma_params *)flags;
+	unsigned long irq_flags = 0;
+
+	spin_lock_irqsave(&fdma->channels_lock, irq_flags);
+	if (channel->sw_state != FDMA_IDLE) {
+		spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
+		fdma_dbg(fdma, "%s channel not idle\n", __FUNCTION__);
 		return -EBUSY;
 	}
 
-	params = (struct stm_dma_params *)flags;
-	if(!((struct dma_xfer_descriptor*)(params->priv))->llu_nodes){
-		fdma_dbg(fd, "%s no nodelist alloced\n",__FUNCTION__);
-		spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
+	if (!((struct fdma_xfer_descriptor *)(params->priv))->llu_nodes) {
+		fdma_dbg(fdma, "%s no nodelist alloced\n", __FUNCTION__);
+		spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
 		return -ENOMEM;
 	}
 
-	/* Now we are associating the compiled transfer llu & params to the channel*/
-	chan->params = params;
-	tasklet_init(&chan->fdma_complete,
-		     params->comp_cb, (unsigned long)params->comp_cb_parm);
-	tasklet_init(&chan->fdma_error,
-		     params->err_cb, (unsigned long)params->err_cb_parm);
-	chan->sw_state = FDMA_CONFIGURED;
+	/* Now we are associating the compiled transfer llu & params to the
+	 * channel */
+	channel->params = params;
+	tasklet_init(&channel->fdma_complete, params->comp_cb,
+			(unsigned long)params->comp_cb_parm);
+	tasklet_init(&channel->fdma_error, params->err_cb,
+			(unsigned long)params->err_cb_parm);
+	channel->sw_state = FDMA_CONFIGURED;
 
-	spin_unlock_irqrestore(&fd->channel_lock,irq_flags);
+	spin_unlock_irqrestore(&fdma->channels_lock, irq_flags);
 
 	return 0;
 }
 
-static int stb710x_fdma_xfer(
-				struct dma_channel *channel,
-				unsigned long sar,
-			     	unsigned long dar,
-			     	size_t count,
-			     	unsigned int mode)
+static int fdma_xfer(struct dma_channel *dma_chan,
+		unsigned long sar, unsigned long dar,
+		size_t count, unsigned int mode)
 {
-	struct fdma_dev *fd = FDMA_DEV(channel);
-	struct channel_status *chan = FDMA_CHAN(channel);
-	struct dma_xfer_descriptor *desc;
-	unsigned long irqflags=0;
+	struct fdma_channel *channel = dma_chan->priv_data;
+	struct fdma *fdma = channel->fdma;
+	struct fdma_xfer_descriptor *desc;
+	unsigned long irqflags = 0;
 
-	/*we need to check that the compile has been completed*/
-	spin_lock_irqsave(&fd->channel_lock, irqflags);
+	/* we need to check that the compile has been completed */
+	spin_lock_irqsave(&fdma->channels_lock, irqflags);
 
-	if (chan->sw_state != FDMA_CONFIGURED) {
-		spin_unlock_irqrestore(&fd->channel_lock, irqflags);
+	if (channel->sw_state != FDMA_CONFIGURED) {
+		spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 		return -EINVAL;
 	}
 
-	desc = (struct dma_xfer_descriptor*)chan->params->priv;
+	desc = (struct fdma_xfer_descriptor *)channel->params->priv;
 
-	BUG_ON(!(IS_CHANNEL_IDLE(fd,channel->chan)));
+	BUG_ON(fdma_get_engine_status(channel) != FDMA_CHANNEL_IDLE);
 
-	fdma_start_channel(fd,channel->chan, desc->llu_nodes->dma_addr,
-			   desc->llu_nodes->virt_addr->size_bytes);
-	chan->sw_state = FDMA_RUNNING;
+	fdma_start_channel(channel, desc->llu_nodes->dma_addr,
+			desc->llu_nodes->virt_addr->size_bytes);
+	channel->sw_state = FDMA_RUNNING;
 
-	spin_unlock_irqrestore(&fd->channel_lock, irqflags);
+	spin_unlock_irqrestore(&fdma->channels_lock, irqflags);
 
 	return 0;
 }
 
-static int stb710x_fdma_extended_op(struct dma_channel *  ch,
-				    unsigned long opcode,
-				    void * parm)
+static int fdma_extended(struct dma_channel *dma_chan,
+		unsigned long opcode, void *ext_param)
 {
-	struct fdma_dev *fd = FDMA_DEV(ch);
-	switch(opcode){
+	struct fdma_channel *channel = dma_chan->priv_data;
+
+	switch (opcode) {
 		case STM_DMA_OP_FLUSH:
-			return stb710x_fdma_pause(fd,ch,1);
+			return fdma_pause(channel, 1);
 		case STM_DMA_OP_PAUSE:
-			return stb710x_fdma_pause(fd,ch,0);
+			return fdma_pause(channel, 0);
 		case STM_DMA_OP_UNPAUSE:
-			return  stb710x_fdma_unpause(fd,ch);
+			return fdma_unpause(channel);
 		case STM_DMA_OP_STOP:
-			return stb710x_fdma_stop(fd,ch);
+			return fdma_stop(channel);
 		case STM_DMA_OP_COMPILE:
-			return stb710x_fdma_compile_params(fd, (struct stm_dma_params *)parm);
+			return fdma_compile_params(channel, ext_param);
 		case STM_DMA_OP_STATUS:
-			return stb710x_get_engine_status(fd,ch->chan);
+			return fdma_get_engine_status(channel);
 		case STM_DMA_OP_REQ_CONFIG:
-			return (int)stb710x_configure_pace_channel(fd, ch, (struct stm_dma_req_config *)parm);
+			return (int)fdma_configure_pace_channel(channel,
+					ext_param);
 		case STM_DMA_OP_REQ_FREE:
-			fdma_req_free((struct stm_dma_req *)parm);
+			fdma_req_free(ext_param);
 			return 0;
 		default:
 			return -ENOSYS;
@@ -1328,123 +1319,117 @@ static int stb710x_fdma_extended_op(struct dma_channel *  ch,
  *---------------------------------------------------------------------*
  *---------------------------------------------------------------------*/
 
-static struct dma_ops stb710x_fdma_ops = {
-	.request		= stb710x_fdma_request,
-	.free			= stb710x_fdma_free,
-	.get_residue		= stb710x_fdma_get_residue,
-	.xfer			= stb710x_fdma_xfer,
-	.configure		= stb710x_fdma_configure,
-	.extend			= stb710x_fdma_extended_op,
+static struct dma_ops fdma_ops = {
+	.request	= fdma_request,
+	.free		= fdma_free,
+	.get_residue	= fdma_get_residue,
+	.xfer		= fdma_xfer,
+	.configure	= fdma_configure,
+	.extend		= fdma_extended,
 };
 
 static int __init fdma_driver_probe(struct platform_device *pdev)
 {
-	struct fdma_platform_device_data * plat_data;
-	struct fdma_dev *fd=NULL;
+	struct fdma_platform_device_data *plat_data;
+	struct fdma *fdma = NULL;
 	struct resource *res;
-	int i=0;
-	int err=0;
+	int chan_num;
+	int err = 0;
 
 	plat_data = pdev->dev.platform_data;
 
-	fd = kzalloc(sizeof(struct fdma_dev), GFP_KERNEL);
-	if (fd == NULL) {
+	fdma = kzalloc(sizeof(struct fdma), GFP_KERNEL);
+	if (fdma == NULL)
 		return -ENOMEM;
-	};
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	if (!res) {
+	if (!res)
 		return -ENODEV;
-	}
 
-	fd->phys_mem = request_mem_region(res->start, res->end - res->start + 1,
-					  pdev->name);
-	if (fd->phys_mem == NULL) {
+	fdma->phys_mem = request_mem_region(res->start,
+			res->end - res->start + 1, pdev->name);
+	if (fdma->phys_mem == NULL)
 		return -EBUSY;
-	};
 
-	fd->io_base = ioremap_nocache(res->start, res->end - res->start + 1);
-	if (fd->io_base == NULL) {
+	fdma->io_base = ioremap_nocache(res->start, res->end - res->start + 1);
+	if (fdma->io_base == NULL)
 		return -EINVAL;
-	}
 
-	fd->ch_min = plat_data->min_ch_num;
-	fd->ch_max = plat_data->max_ch_num;
-	fd->fdma_num = pdev->id;
-	fd->ch_status_mask =
-		((1ULL << ((fd->ch_max + 1) * 2)) - 1ULL) ^
-		((1    << (fd->ch_min * 2)) - 1);
+	fdma->ch_min = plat_data->min_ch_num;
+	fdma->ch_max = plat_data->max_ch_num;
+	fdma->fdma_num = pdev->id;
+	fdma->ch_status_mask = ((1ULL << ((fdma->ch_max + 1) * 2)) - 1ULL) ^
+			((1 << (fdma->ch_min * 2)) - 1);
 
-	memcpy(&fd->regs,(u32*)plat_data->registers_ptr,sizeof(struct fdma_regs));
-	fd->fw_name = plat_data->fw_device_name;
-	fd->fw = plat_data->fw;
+	memcpy(&fdma->regs, (u32 *)plat_data->registers_ptr,
+			sizeof(struct fdma_regs));
+	fdma->fw_name = plat_data->fw_device_name;
+	fdma->fw = plat_data->fw;
 
 	/* 7200: Req lines 0 and 31 are connected internally, not to the xbar */
-	fd->req_lines_inuse = (1<<31) | (1<<0);
+	fdma->req_lines_inuse = (1 << 31) | (1 << 0);
 
-	spin_lock_init(&(fd)->channel_lock);
-	init_waitqueue_head(&(fd)->fw_load_q);
+	spin_lock_init(&(fdma)->channels_lock);
+	init_waitqueue_head(&(fdma)->fw_load_q);
 
-	fd->dma_info.nr_channels = fd->ch_max - fd->ch_min + 1;
-	fd->dma_info.ops	= &stb710x_fdma_ops;
-	fd->dma_info.flags	= DMAC_CHANNELS_TEI_CAPABLE;
-	strlcpy(fd->name, STM_DMAC_ID, FDMA_NAME_LEN);
+	fdma->dma_info.nr_channels = fdma->ch_max - fdma->ch_min + 1;
+	fdma->dma_info.ops = &fdma_ops;
+	fdma->dma_info.flags = DMAC_CHANNELS_TEI_CAPABLE;
+	strlcpy(fdma->name, STM_DMAC_ID, FDMA_NAME_LEN);
 	if (pdev->id != -1) {
-		int len=strlen(fd->name);
-		snprintf(fd->name+len, FDMA_NAME_LEN-len, ".%d", pdev->id);
-	}
-	fd->dma_info.name = fd->name;
-
-	if(register_dmac(&fd->dma_info)!=0)
-		printk("%s Error Registering DMAC\n",__FUNCTION__);
-	/*must take account of CH 0*/
-
-	for (i = fd->ch_min; i <= fd->ch_max; i++) {
-		struct dma_channel *channel;
-		channel = get_dma_channel(i);
-		channel->priv_data = &fd->channel[i];
-		fd->channel[i].cur_cfg = channel;
-		fd->channel[i].fd = fd;
+		int len = strlen(fdma->name);
+		snprintf(fdma->name + len, FDMA_NAME_LEN - len, ".%d",
+				pdev->id);
 	}
+	fdma->dma_info.name = fdma->name;
+
+	if (register_dmac(&fdma->dma_info) != 0)
+		printk(KERN_ERR "%s Error Registering DMAC\n", __FUNCTION__);
 
-	err =request_irq(platform_get_irq(pdev, 0),
-			 fdma_irq,
-			 IRQF_DISABLED | IRQF_SHARED,
-			 fd->name,
-			 fd);
-	if(err <0)
-		panic(" Cant Register irq %d for FDMA engine err %d\n",
-					fd->irq_val,err);
+	for (chan_num = fdma->ch_min; chan_num <= fdma->ch_max; chan_num++) {
+		struct fdma_channel *channel = &fdma->channels[chan_num];
+		struct dma_channel *dma_chan;
+
+		channel->chan_num = chan_num;
+		channel->fdma = fdma;
+
+		dma_chan = get_dma_channel(chan_num - fdma->ch_min);
+		dma_chan->priv_data = channel;
+		channel->dma_chan = dma_chan;
+	}
 
+	err = request_irq(platform_get_irq(pdev, 0), fdma_irq,
+			 IRQF_DISABLED | IRQF_SHARED, fdma->name, fdma);
+	if (err < 0)
+		panic("Cant Register irq %d for FDMA engine err %d\n",
+				fdma->irq, err);
 
-	fdma_register_caps(fd);
+	fdma_register_caps(fdma);
 
-	fdma_check_firmware_state(fd);
+	fdma_check_firmware_state(fdma);
 
-	platform_set_drvdata(pdev, fd);
+	platform_set_drvdata(pdev, fdma);
 
 	return 0;
 }
 
 static int fdma_driver_remove(struct platform_device *pdev)
 {
-	struct fdma_dev *fd = platform_get_drvdata(pdev);
+	struct fdma *fdma = platform_get_drvdata(pdev);
 
-	fdma_disable_all_channels(fd);
-	iounmap(fd->io_base);
-	dma_pool_destroy(fd->llu_pool);
-	free_irq(fd->irq_val, fd);
-	unregister_dmac(&fd->dma_info);
-	release_resource(fd->phys_mem);
-	kfree(fd);
+	fdma_disable_all_channels(fdma);
+	iounmap(fdma->io_base);
+	dma_pool_destroy(fdma->llu_pool);
+	free_irq(fdma->irq, fdma);
+	unregister_dmac(&fdma->dma_info);
+	release_resource(fdma->phys_mem);
+	kfree(fdma);
 
 	return 0;
 }
 
 static struct platform_driver fdma_driver = {
-	.driver = {
-		.name = "stmfdma",
-	},
+	.driver.name = "stmfdma",
 	.probe = fdma_driver_probe,
 	.remove = fdma_driver_remove,
 };
diff --git a/drivers/stm/fdma.h b/drivers/stm/fdma.h
index c2fbdb6..3797016 100644
--- a/drivers/stm/fdma.h
+++ b/drivers/stm/fdma.h
@@ -7,14 +7,14 @@
  * License.  See linux/COPYING for more information.
  */
 
-#ifndef STB7100_FDMA_H
-#define STB7100_FDMA_H
+#ifndef __STM_FDMA_H
+#define __STM_FDMA_H
 
 #define CHAN_ALL_ENABLE 				3
 
 /**cmd stat vals*/
-#define SET_NODE_COMP_PAUSE		    		1 <<30
-#define SET_NODE_COMP_IRQ				1 <<31
+#define SET_NODE_COMP_PAUSE		    		(1 << 30)
+#define SET_NODE_COMP_IRQ				(1 << 31)
 #define NODE_ADDR_STATIC 				0x01
 #define NODE_ADDR_INCR	 				0x02
 
@@ -25,11 +25,9 @@
 #define CMDSTAT_FDMA_START_CHANNEL			1
 #define CMDSTAT_FDMA_RESTART_CHANNEL			0
 
-#define STB7100_FDMA_CHANS              		16
-#define STB7109_FDMA_CHANS              		STB7100_FDMA_CHANS
-#define STB7200_FDMA_CHANS				32
-#define STB7100_REQ_LINES				32
-#define STB7200_REQ_LINES				64
+#define FDMA_CHANS					16
+#define FDMA_7100_REQ_LINES				32
+#define FDMA_7200_REQ_LINES				64
 
 /*******************************/
 /*MBOX SETUP VALUES*/
@@ -39,27 +37,9 @@
 #define MBOX_CMD_START_CHANNEL       			1
 #define CLEAR_WORD					0XFFFFFFFF
 
-#define IS_PACED_CHANNEL_SET(flags)(flags & 0x1f)
-#define ASSERT_NODE_BUS_ADDR(addr)( (((PXSEG(addr) == P0SEG) && addr))?1:0)
-#define IS_CHANNEL_PAUSED(fd,ch)(stb710x_get_engine_status(fd,ch)== FDMA_CHANNEL_PAUSED ?1:0)
-#define IS_CHANNEL_RUNNING(fd,ch)(stb710x_get_engine_status(fd,ch)== FDMA_CHANNEL_RUNNING ?1:0)
-#define IS_CHANNEL_IDLE(fd,ch)(stb710x_get_engine_status(fd,ch)== FDMA_CHANNEL_IDLE ?1:0)
-#define IS_TRANSFER_SG(parms)((MODE_SRC_SCATTER==parms->mode)||(MODE_DST_SCATTER==parms->mode )?1:0)
-#define MBOX_STR_CMD(ch) (MBOX_CMD_START_CHANNEL << (ch*2))
-#define CMD_STAT_REG(ch)(fd->io_base + fd->regs.fdma_cmd_statn + (ch * CMD_STAT_OFFSET))
-
-#define IS_NODE_MALLOCED(priv)((priv.node!=0))
-
-
-#define IS_NODELIST_EQUAL(priv)((priv.sublist_nents == priv.alloced_nents))
-#define FDMA_CHAN(channel) ((struct channel_status*)(channel->priv_data))
-#define FDMA_DEV(channel) (FDMA_CHAN(channel)->fd)
-struct fdma_dev;
-
-typedef void (*pf)(void * data);
-
-#define CHANNEL_ERR_IRQ 		3
-#define CHANNEL_IRQ     		1
+#define CMD_STAT_REG(_chan_num) \
+		(fdma->io_base + fdma->regs.fdma_cmd_statn + \
+		(_chan_num * CMD_STAT_OFFSET))
 
 #define FDMA_CHANNEL_IDLE 		0
 #define FDMA_CHANNEL_RUNNING 		2
@@ -71,7 +51,7 @@ typedef void (*pf)(void * data);
 
 #define CHAN_NUM(chan) ((chan) - chip.channel)
 
-typedef struct fdma_llu_entry {
+struct fdma_llu_entry {
 	u32 next_item;
 	u32 control;
 	u32 size_bytes;
@@ -80,26 +60,26 @@ typedef struct fdma_llu_entry {
 	u32 line_len;
 	u32 sstride;
 	u32 dstride;
-}fdma_llu_entry;
+};
 
 
-struct llu_node{
-	struct fdma_llu_entry * virt_addr;
+struct fdma_llu_node {
+	struct fdma_llu_entry *virt_addr;
 	dma_addr_t dma_addr;
 };
 
 
-typedef struct dma_xfer_descriptor {
-	struct llu_node* (*extrapolate_fn)(struct stm_dma_params *xfer,
-					   struct dma_xfer_descriptor *desc,
-					   struct llu_node* nodes);
-	int	extrapolate_line_len;
+struct fdma_xfer_descriptor {
+	struct fdma_llu_node *(*extrapolate_fn)(struct stm_dma_params *xfer,
+			struct fdma_xfer_descriptor *desc,
+			struct fdma_llu_node *nodes);
+	int extrapolate_line_len;
 	struct fdma_llu_entry template_llu;
 
 	/* only used when this is the first parameter in a list */
-	struct 	llu_node *llu_nodes;
-	int 	alloced_nodes;
-}dma_xfer_descriptor;
+	struct fdma_llu_node *llu_nodes;
+	int alloced_nodes;
+};
 
 
 enum fdma_state {
@@ -111,10 +91,13 @@ enum fdma_state {
 	FDMA_PAUSED,
 };
 
-struct channel_status {
-	struct fdma_dev *fd;
+struct fdma;
+
+struct fdma_channel {
+	struct fdma *fdma;
+	int chan_num;
 	enum fdma_state sw_state;
-	struct dma_channel * cur_cfg;
+	struct dma_channel *dma_chan;
 	struct stm_dma_params *params;
 	struct tasklet_struct fdma_complete;
 	struct tasklet_struct fdma_error;
@@ -122,30 +105,30 @@ struct channel_status {
 
 #define FDMA_NAME_LEN 20
 
-struct fdma_dev {
-	char				name[FDMA_NAME_LEN];
-	struct dma_info 		dma_info;
-	struct channel_status		channel[STB7100_FDMA_CHANS];
-	spinlock_t 			channel_lock;
-	struct resource *		phys_mem;
-	void __iomem			*io_base;
-	u32				firmware_loaded;
-	u8				ch_min;
-	u8 				ch_max;
-	u8				irq_val;
-	u8				fdma_num;
-	u32				ch_status_mask;
-	struct dma_pool 		*llu_pool;
-	wait_queue_head_t		fw_load_q;
-
-	struct fdma_regs		regs;
-
-	char *				fw_name;
-	struct fdma_fw			fw;
-	int				comp_ch;
+struct fdma {
+	char name[FDMA_NAME_LEN];
+	struct dma_info dma_info;
+	struct fdma_channel channels[FDMA_CHANS];
+	spinlock_t channels_lock; /* protects channels array */
+	struct resource *phys_mem;
+	void __iomem *io_base;
+	u32 firmware_loaded;
+	u8 ch_min;
+	u8 ch_max;
+	u8 irq;
+	u8 fdma_num;
+	u32 ch_status_mask;
+	struct dma_pool *llu_pool;
+	wait_queue_head_t fw_load_q;
+
+	struct fdma_regs regs;
+
+	char *fw_name;
+	struct fdma_fw fw;
+	int comp_ch;
 
 	/* This is used with the xbar to allocate the next available req line */
-	unsigned long 			req_lines_inuse;
+	unsigned long req_lines_inuse;
 };
 
 typedef volatile unsigned long device_t;
@@ -163,7 +146,7 @@ typedef volatile unsigned long device_t;
 #endif
 
 struct stm_dma_req {
-	struct channel_status *chan;
+	struct fdma_channel *channel;
 	int local_req_line;
 };
 
-- 
1.5.6.3

